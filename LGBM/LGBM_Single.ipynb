{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0367e8",
   "metadata": {},
   "source": [
    "# ARIMA Single Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba9ee40",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c9a71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "# Save the log\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "# LGBM\n",
    "import lightgbm as lgbm\n",
    "\n",
    "# Metric \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11f48d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minus\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "# 한글\n",
    "plt.rc('font', family='NanumGothic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58e094",
   "metadata": {},
   "source": [
    "## Data Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6c8f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/JW_capstone.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76850788",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5082c250",
   "metadata": {},
   "source": [
    "### Split the train and test set\n",
    "- Input\n",
    "     data: dataframe with dates and Demand data\n",
    "     \n",
    "- output\n",
    "    - train: ~ 2012-06-30\n",
    "    \n",
    "    - test :  2022-07-01 ~ 2012-12-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f71ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train과 test로 데이터 split\n",
    "def split_data(product_df):\n",
    "    \n",
    "    train_df = product_df[product_df['Date']<'2022-07-01'].reset_index(drop=True)\n",
    "    test_df = product_df[product_df['Date']>='2022-07-01'].reset_index(drop=True)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef00b8c",
   "metadata": {},
   "source": [
    "## ARIMA\n",
    "- Rolling forecast 방식으로 input값으로 테스트 기간의 값이 들어가서, 1일 후를 예측한 것을 총 6개월 이어붙임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6689843",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = df[df['Product']==\"리바로정\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d16283e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m lgbm_model \u001b[38;5;241m=\u001b[39m lgbm\u001b[38;5;241m.\u001b[39mLGBMRegressor()\n\u001b[0;32m      4\u001b[0m lgbm_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m----> 5\u001b[0m         \u001b[43mx_train\u001b[49m,\n\u001b[0;32m      6\u001b[0m         y_train\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m preds \u001b[38;5;241m=\u001b[39m lgbm_gbr\u001b[38;5;241m.\u001b[39mpredict(x_valid)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_date \u001b[38;5;129;01min\u001b[39;00m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "train_df, test_df = split_data(product_df)\n",
    "predictions = []\n",
    "lgbm_model = lgbm.LGBMRegressor()\n",
    "lgbm_model.fit(\n",
    "        x_train,\n",
    "        y_train\n",
    ")\n",
    "preds = lgbm_gbr.predict(x_valid)\n",
    "\n",
    "for test_date in test_df['Date']:\n",
    "    print(test_date)\n",
    "    # test_date -= timedelta(days=1)\n",
    "    # Use data up to the day before the test date to train the model\n",
    "    train_until_test_df = product_df[product_df['Date'] < test_date]\n",
    "    \n",
    "    # fitting the model with best(p,d,q)\n",
    "    best_model_fit = lgbm_model.fit(train_until_test_df['y'])\n",
    "\n",
    "    # 1일 뒤의 값을 예측하고, 예측값에 새롭게 추가\n",
    "    prediction = best_model_fit.predict(n_periods=1).reset_index(drop=True)[0]\n",
    "    predictions.append(max(0, prediction))  # replace negative predictions with 0\n",
    "    \n",
    "# Create a DataFrame to hold the result\n",
    "res_df = test_df.copy()\n",
    "res_df['Pred'] = predictions\n",
    "res_df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c0eafcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling Forecasting\n",
    "def ARIMA_single(product_df):\n",
    "\n",
    "    train_df, test_df = split_data(product_df)\n",
    "\n",
    "    predictions = []\n",
    "    best_model = auto_arima(train_df['y'], \n",
    "                            start_p=1, start_q=1,\n",
    "                            max_p=5, max_q=5, \n",
    "                            max_d=2, trace=True,\n",
    "                            suppress_warnings=True)\n",
    "    \n",
    "    for test_date in test_df['Date']:\n",
    "        print(test_date)\n",
    "        # test_date -= timedelta(days=1)\n",
    "        # Use data up to the day before the test date to train the model\n",
    "        train_until_test_df = product_df[product_df['Date'] < test_date]\n",
    "        \n",
    "        # fitting the model with best(p,d,q)\n",
    "        best_model_fit = best_model.fit(train_until_test_df['y'])\n",
    "    \n",
    "        # 1일 뒤의 값을 예측하고, 예측값에 새롭게 추가\n",
    "        prediction = best_model_fit.predict(n_periods=1).reset_index(drop=True)[0]\n",
    "        predictions.append(max(0, prediction))  # replace negative predictions with 0\n",
    "\n",
    "    # Create a DataFrame to hold the result\n",
    "    res_df = test_df.copy()\n",
    "    res_df['Pred'] = predictions\n",
    "    res_df.set_index('Date', inplace=True)\n",
    "\n",
    "    # res_df: ['y'','Pred'] index='Date'\n",
    "    return best_model, res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "026406bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = df[df['Product']==\"리바로정\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9707b0da",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Converting from datetime64[ns] to int32 is not supported. Do obj.astype('int64').astype(dtype) instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# We assume that product_df has a 'Date' column and a 'y' column\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# If you have more features, you should add them here.\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m y_train \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Create LGBM Dataset\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\core\\generic.py:6324\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6317\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   6319\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m   6320\u001b[0m     ]\n\u001b[0;32m   6322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6323\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6324\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6327\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\core\\internals\\managers.py:451\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    449\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    355\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:511\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 511\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    513\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    515\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:242\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    239\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:184\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[1;32m--> 184\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:701\u001b[0m, in \u001b[0;36mDatetimeArray.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_period_dtype(dtype):\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_period(freq\u001b[38;5;241m=\u001b[39mdtype\u001b[38;5;241m.\u001b[39mfreq)\n\u001b[1;32m--> 701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDatetimeLikeArrayMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:472\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    470\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masi8\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mint64:\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    473\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    474\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDo obj.astype(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).astype(dtype) instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    475\u001b[0m     )\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m    478\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31mTypeError\u001b[0m: Converting from datetime64[ns] to int32 is not supported. Do obj.astype('int64').astype(dtype) instead"
     ]
    }
   ],
   "source": [
    "train_df, test_df = split_data(product_df)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# We assume that product_df has a 'Date' column and a 'y' column\n",
    "# If you have more features, you should add them here.\n",
    "X_train = train_df['Date'].astype(int).values.reshape(-1, 1)\n",
    "y_train = train_df['y'].values\n",
    "\n",
    "# Create LGBM Dataset\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "\n",
    "# Define hyperparameters for LightGBM\n",
    "# Note: You might want to tune these hyperparameters or use a hyperparameter tuning algorithm\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "}\n",
    "\n",
    "# Train LightGBM model\n",
    "# You might want to adjust num_boost_round and early_stopping_rounds\n",
    "model = lgb.train(params, lgb_train, num_boost_round=1000, valid_sets=[lgb_train], early_stopping_rounds=10, verbose_eval=False)\n",
    "\n",
    "for test_date in test_df['Date']:\n",
    "    print(test_date)\n",
    "    # Convert date to int and reshape for prediction\n",
    "    X_test = np.array([[test_date.astype(int)]])\n",
    "    prediction = model.predict(X_test)[0]\n",
    "    predictions.append(max(0, prediction))  # replace negative predictions with 0\n",
    "\n",
    "# Create a DataFrame to hold the result\n",
    "res_df = test_df.copy()\n",
    "res_df['Pred'] = predictions\n",
    "res_df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8892f69f",
   "metadata": {},
   "source": [
    "## Save & Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60a6dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(product_code, best_model):\n",
    "    today = date.today()\n",
    "    folder_path = 'Result/Single_ARIMA_Result/Model'\n",
    "    file_name = f'{product_code}_{today.month:02d}{today.day:02d}.pkl'\n",
    "    save_path = os.path.join(folder_path, file_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    # 객체를 pickle 파일로 저장\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a552f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델 pickle파일에서 불러오기\n",
    "def load_model(file_name):\n",
    "    file_path = f'Result/Single_ARIMA_Result/Model/{file_name}'\n",
    "    \n",
    "    with open(file_path, 'rb') as file:\n",
    "        model_dict= pickle.load(file)\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd64a0",
   "metadata": {},
   "source": [
    "## Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d8fe2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_pred_plot(product_code, res_df, metric_df):\n",
    "    today = date.today()\n",
    "    \"\"\"\n",
    "    Plot the actual vs predition and save the figure in the given directory\n",
    "    \"\"\"\n",
    "    save_path = os.path.join(\"Result\", \"Single_ARIMA_Result\", product_code)\n",
    "    save_name = f'{product_code}_all_result'\n",
    "    \n",
    "    title = f\"Pred Actual Plot - {product_code}\"\n",
    "    actual = res_df['y']\n",
    "    pred = res_df['Pred']\n",
    "\n",
    "    # Plot   \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.xlabel(\"Date\", fontsize=14)\n",
    "    plt.ylabel(\"Order Demand\", fontsize=14)\n",
    "    plt.plot(actual, label ='Actual', color='r', marker='o', ms=3)\n",
    "    plt.plot(pred, label='Prediction', color='b', marker='o', ms=3)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "        \n",
    "    # Plot 결과 저장\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    # save the figure\n",
    "    today_date = f'_{today.month:02d}{today.day:02d}'\n",
    "    plt.savefig(os.path.join(save_path, save_name+'.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # 전체 결과에 대한 Metric도 함께 저장\n",
    "    metric_df.to_csv(os.path.join(save_path, save_name+'.csv'), encoding=\"utf-8-sig\")\n",
    "    plt.close('all') # close all figures to free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd8454",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28dd74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / (actual+1)))\n",
    "\n",
    "# 정규화 된 지표\n",
    "def nrmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nrmse = mse / target_mean\n",
    "    return nrmse\n",
    "\n",
    "# 정규화 된 지표\n",
    "def nmae(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nmae = mae / target_mean\n",
    "    return nmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83451baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(product_code, res_df):\n",
    "\n",
    "    actual = res_df['y']\n",
    "    pred = res_df['Pred']\n",
    "\n",
    "    # 메트릭 계산\n",
    "    MAPE = mape(actual, pred) \n",
    "    RMSE = mean_squared_error(actual, pred)**0.5 \n",
    "    MAE = mean_absolute_error(actual,pred) \n",
    "    NRMSE = nrmse(actual,pred) \n",
    "    NMAE = nmae(actual,pred) \n",
    "    R2 = r2_score(actual, pred)\n",
    "\n",
    "    # 계산된 메트릭을 데이터프레임에 추가\n",
    "    metric_df = pd.DataFrame({'MAPE':[round(MAPE, 4)],\n",
    "                           'RMSE':[round(RMSE, 4)],\n",
    "                           'MAE':[round(MAE, 4)],\n",
    "                           'NRMSE':[round(NRMSE, 4)],\n",
    "                           'NMAE':[round(NMAE, 4)],\n",
    "                           'R2': [round(R2, 4)]},\n",
    "                            index= [product_code])\n",
    "\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073bc376",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e45cb6",
   "metadata": {},
   "source": [
    "## Check the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ce9ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_single_ARIMA(product_code):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    product_code = product_code # 예측하고자 하는 코드 입력\n",
    "    product_df = df[df['Product']== product_code].reset_index(drop=True)\n",
    "\n",
    "    # Prophet 단일 모델\n",
    "    best_model, res_df = ARIMA_single(product_df) \n",
    "    save_model(product_code, best_model)\n",
    "    # 모델 Metric과 Pred_Actual Plot 저장\n",
    "    metric_df= calculate_metrics(product_code, res_df)\n",
    "    actual_pred_plot(product_code, res_df, metric_df)\n",
    "    \n",
    "    # 실행시간 확인\n",
    "    elapsed_time_seconds = time.time() - start_time\n",
    "    elapsed_time_minutes = elapsed_time_seconds / 60\n",
    "    print(\"실행 시간: {:.2f} 분\".format(elapsed_time_minutes))\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5269ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2bffe",
   "metadata": {},
   "source": [
    "## Whole Process\n",
    "    - product_code에 str으로 예측하고자 하는 코드를 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "095eda0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "========== Product_0025 ==========\n",
      "==================================\n",
      "실행 시간: 0.03 분\n",
      "                  MAPE      RMSE       MAE   NRMSE\n",
      "Product_0025  291.0962  965.0509  641.5268  1.9693\n",
      "==================================\n",
      "========== Product_0739 ==========\n",
      "==================================\n",
      "실행 시간: 0.11 분\n",
      "                MAPE     RMSE      MAE   NRMSE\n",
      "Product_0739  0.2932  46.9636  19.2149  2.4441\n",
      "==================================\n",
      "========== Product_0901 ==========\n",
      "==================================\n",
      "실행 시간: 0.49 분\n",
      "                 MAPE     RMSE      MAE   NRMSE\n",
      "Product_0901  12.5931  89.6329  45.8805  2.2913\n",
      "==================================\n",
      "========== Product_1154 ==========\n",
      "==================================\n",
      "실행 시간: 0.02 분\n",
      "                  MAPE       RMSE        MAE   NRMSE\n",
      "Product_1154  944.7914  2806.3135  1845.0757  2.2603\n",
      "==================================\n",
      "========== Product_1248 ==========\n",
      "==================================\n",
      "실행 시간: 0.02 분\n",
      "                    MAPE         RMSE          MAE   NRMSE\n",
      "Product_1248  55738.2977  233395.9957  167441.9966  1.5898\n",
      "==================================\n",
      "========== Product_1295 ==========\n",
      "==================================\n",
      "실행 시간: 0.58 분\n",
      "                   MAPE        RMSE        MAE   NRMSE\n",
      "Product_1295  4108.0797  68438.9556  44018.159  0.9371\n",
      "==================================\n",
      "========== Product_1378 ==========\n",
      "==================================\n",
      "실행 시간: 0.11 분\n",
      "                    MAPE        RMSE         MAE   NRMSE\n",
      "Product_1378  16514.9994  49624.6385  40610.7466  1.0371\n",
      "==================================\n",
      "========== Product_2004 ==========\n",
      "==================================\n",
      "실행 시간: 0.02 분\n",
      "                  MAPE       RMSE       MAE   NRMSE\n",
      "Product_2004  514.0343  1319.0387  978.7391  1.8652\n"
     ]
    }
   ],
   "source": [
    "for code in df['Product'].unique():\n",
    "    print(\"==================================\")\n",
    "    print(f\"========== { code } ==========\")\n",
    "    print(\"==================================\")\n",
    "    execute_single_ARIMA(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd1d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_model('Product_0739_0503.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEMD_LSTM",
   "language": "python",
   "name": "eemd_lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
