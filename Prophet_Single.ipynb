{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0367e8",
   "metadata": {},
   "source": [
    "# Prophet Single Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9353f79f",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "    - Raw data: Historical Product Demand.csv\n",
    "\n",
    "    - Input data: Data on 8x augmentation of demand records by selecting 8 representative items\n",
    "\n",
    "    - Product code: 'Product_0025', 'Product_0739', 'Product_0901', 'Product_1154',\n",
    "                    'Product_1248', 'Product_1295', 'Product_1378', 'Product_2004'\n",
    "            \n",
    "\n",
    "    - Size of Data: 116392 rows × 4 columns\n",
    "\n",
    "    - Features: Date, Product_Code, Product_Category, Order_Demand\n",
    "\n",
    "    - Period: 2012-01-01 ~ 2017-01-09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba9ee40",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c9a71a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import itertools\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Save the log\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Prophet \n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "\n",
    "# Metric\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58e094",
   "metadata": {},
   "source": [
    "## Data Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da55b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data\\\\train.csv')\n",
    "df = df[(df['store']==1)]\n",
    "\n",
    "pd.to_datetime(df['date'].max()) - pd.to_datetime(df['date'].min())\n",
    "df = df.reset_index(drop=True)\n",
    "df.rename(columns={'date': 'Date', 'item':'Product_Code', 'sales':'Order_Demand'}, inplace=True)\n",
    "df = df[['Date', 'Product_Code', 'Order_Demand']]\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Product_Code'] = df['Product_Code'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c8f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Loading\n",
    "# df = pd.read_csv('Data\\HPD_0416.csv')\n",
    "# # convert the string to the datetype\n",
    "# df['Date'] = pd.to_datetime(df['Date'])\n",
    "# # 범위 통일\n",
    "# start_date = pd.to_datetime('2012-01-10')\n",
    "# end_date = pd.to_datetime('2016-12-21')\n",
    "\n",
    "# df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "# df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed38f8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14464 entries, 0 to 14463\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Date              14464 non-null  datetime64[ns]\n",
      " 1   Product_Code      14464 non-null  object        \n",
      " 2   Product_Category  14464 non-null  object        \n",
      " 3   Order_Demand      14464 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 452.1+ KB\n",
      "None\n",
      "-------------------------\n",
      "\n",
      "The Number of unique\n",
      "-------------------------\n",
      "Product code:\t 8\n",
      "Category:\t 5\n",
      "-------------------------\n",
      "The Product Code:\n",
      "\n",
      "1 Product_0025\n",
      "2 Product_0739\n",
      "3 Product_0901\n",
      "4 Product_1154\n",
      "5 Product_1248\n",
      "6 Product_1295\n",
      "7 Product_1378\n",
      "8 Product_2004\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print('-------------------------')\n",
    "print(\"\")\n",
    "print(\"The Number of unique\")\n",
    "print('-------------------------')\n",
    "print('Product code:\\t', df.Product_Code.nunique())\n",
    "print('Category:\\t', df.Product_Category.nunique())\n",
    "print('-------------------------')\n",
    "print(\"The Product Code:\")\n",
    "print(\"\")\n",
    "for i, code in enumerate(df['Product_Code'].unique()):\n",
    "    print(i+1, code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76850788",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5082c250",
   "metadata": {},
   "source": [
    "### Split the train and test set\n",
    "- Input\n",
    "     data: dataframe with dates and Demand data\n",
    "     \n",
    "- output\n",
    "    - train:  whole data - valid, test\n",
    "    - valid:  2 * time steps\n",
    "    - test :  2 * time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f71ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, forecast_period):\n",
    "    df = df.sort_values('ds')\n",
    "    \n",
    "    test_df = df[-forecast_period:]  # 뒤에서 forecast_period 개의 데이터\n",
    "    valid_df = df[-2*forecast_period:-forecast_period]  # 뒤에서 2*forecast_period 번째부터 forecast_period 번째까지의 데이터\n",
    "    train_df = df[:-2*forecast_period]  # 나머지 데이터\n",
    "    \n",
    "    return train_df, valid_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef00b8c",
   "metadata": {},
   "source": [
    "# Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef078e2",
   "metadata": {},
   "source": [
    "### 파라미터 최적화\n",
    "    - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f8a45ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def optimize_prophet(product_df, valid_df, optimize_trials, forecast_period):\n",
    "    # 파라미터 후보\n",
    "    param_grid = {  \n",
    "        'changepoint_prior_scale': [0.01, 0.1, 1, 10],\n",
    "        'seasonality_prior_scale': [0.01, 0.1, 1, 10, 100],\n",
    "        'seasonality_mode': ['additive', 'multiplicative'],\n",
    "        'changepoint_range': [0.8, 0.9, 1.0],\n",
    "        }\n",
    "    \n",
    "    # 파라미터 조합 생성\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    rmses = []  \n",
    "    cutoff = pd.to_datetime(valid_df['ds'].max())  \n",
    "\n",
    "    # 랜덤 샘플링으로 50개의 조합 선택\n",
    "    selected_params = random.sample(all_params, optimize_trials)\n",
    "    \n",
    "    # 파리미터 평가를 위해 validation_data로 cv진행\n",
    "    for params in selected_params:\n",
    "        m = Prophet(**params)\n",
    "        m.add_country_holidays(country_name='US')  # 미국 공휴일 추가\n",
    "        m.fit(product_df)\n",
    "        # validation 기간에 대해 예측\n",
    "        df_cv = cross_validation(m, cutoffs=[cutoff], horizon=str(forecast_period)+' days')  \n",
    "        # rolling_window: cut-off를 기준으로 몇 일의 성능을 계산할지 결정(1: 전체 기간동안의 성능)\n",
    "        df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "        rmses.append(df_p['rmse'].values[0])\n",
    "        \n",
    "    best_params = selected_params[np.argmin(rmses)]\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f62f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prophet_single(product_df, optimize_trials, forecast_period):  # optimize_trials: Search 횟수\n",
    "\n",
    "    train_df, valid_df, test_df = split_data(product_df, forecast_period)\n",
    "    \n",
    "    # 파라미터 최적화\n",
    "    best_params = optimize_prophet(product_df, valid_df, optimize_trials, forecast_period)\n",
    "    # 최적 파라미터를 사용한 모델 훈련\n",
    "    best_model = Prophet(**best_params)\n",
    "    best_model.add_country_holidays(country_name='US')\n",
    "    best_model.fit(train_df)\n",
    "    \n",
    "    # Prophet으로 예측\n",
    "    periods=(test_df['ds'].max() - train_df['ds'].max()).days\n",
    "    future = best_model.make_future_dataframe(periods=periods)\n",
    "    forecast = best_model.predict(future)\n",
    "    \n",
    "    #예측결과 저장\n",
    "    res_df = pd.merge(test_df, forecast[['ds','yhat']], on='ds')\n",
    "    res_df = res_df[['ds', 'y', 'yhat']]\n",
    "    res_df.rename(columns={'yhat': 'Pred'}, inplace=True)\n",
    "    \n",
    "    # 예측값이 음수인 것은 0으로 대치\n",
    "    res_df['Pred'] = res_df['Pred'].apply(lambda x: 0 if x < 0 else x)\n",
    "    \n",
    "    # 'y'와 'yhat' 열을 정규화\n",
    "    scaler = MinMaxScaler()\n",
    "    res_df[['y_norm', 'Pred_norm']] = scaler.fit_transform(res_df[['y', 'Pred']])\n",
    "    res_df.set_index('ds', inplace=True)\n",
    "            \n",
    "    # 모델과 예측값 딕셔너리 반환\n",
    "    return best_model, res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd64a0",
   "metadata": {},
   "source": [
    "## Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d8fe2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the actual vs predition and save the figure in the given directory\n",
    "\"\"\"\n",
    "def actual_pred_plot(product_code, res_df, metric_df, normalize):\n",
    "    today = date.today()\n",
    "    save_path = os.path.join(\"Result\", \"Single_Prophet_Result\", product_code)\n",
    "    save_name = f'{product_code}_all_result'\n",
    "    \n",
    "    title = f\"Pred Actual Plot - {product_code}\"\n",
    "    actual = res_df['y']\n",
    "    pred = res_df['Pred']\n",
    "    \n",
    "    if normalize: \n",
    "        title += \"(Normalized)\"\n",
    "        actual = res_df['y_norm']\n",
    "        pred = res_df['Pred_norm']\n",
    "        save_name += \"_normalized\"\n",
    "    # Plot   \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.xlabel(\"Time\", fontsize=14)\n",
    "    plt.ylabel(\"Order Demand\", fontsize=14)\n",
    "    plt.plot(actual, label ='Actual', marker='o', ms=3)\n",
    "    plt.plot(pred, label='Prediction', marker='o', ms=3)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "        \n",
    "    # Plot 결과 저장\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    # save the figure\n",
    "    today_date = f'_{today.month:02d}{today.day:02d}'\n",
    "    plt.savefig(os.path.join(save_path, save_name+'.png'))\n",
    "    #Metric도 함께 저장\n",
    "    metric_df.to_csv(os.path.join(save_path, save_name+'.csv'))\n",
    "        \n",
    "    plt.close('all') # close all figures to free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77be9b41",
   "metadata": {},
   "source": [
    "## Save & Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84d04474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(product_code, best_model):\n",
    "    today = date.today()\n",
    "    folder_path = 'Result/Single_Prophet_Result/Model'\n",
    "    file_name = f'{product_code}_{today.month:02d}{today.day:02d}.pkl'\n",
    "    save_path = os.path.join(folder_path, file_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    # 객체를 pickle 파일로 저장\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebf0ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델 pickle파일에서 불러오기\n",
    "def load_model(file_name):\n",
    "    file_path = f'Result/Single_Prophet_Result/Model/{file_name}'\n",
    "    \n",
    "    with open(file_path, 'rb') as file:\n",
    "        model_dict= pickle.load(file)\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd8454",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28dd74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Metric\n",
    "def mase(training_series, testing_series, prediction_series):\n",
    "    n = training_series.shape[0]\n",
    "    d = np.abs(np.diff(training_series)).sum() / (n-1)\n",
    "    \n",
    "    errors = np.abs(testing_series - prediction_series)\n",
    "    return errors.mean() / d\n",
    "\n",
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / (actual+1)))\n",
    "\n",
    "# 정규화 된 지표\n",
    "def nrmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nrmse = mse / target_mean\n",
    "    return nrmse\n",
    "\n",
    "# 정규화 된 지표\n",
    "def nmae(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nmae = mae / target_mean\n",
    "    return nmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83451baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(product_code, res_df, normalize):\n",
    "    # 정규화 옵션이 True인 경우 정규화된 데이터 사용, 그렇지 않으면 원래 데이터 사용\n",
    "    if normalize:\n",
    "        actual = res_df['y_norm']\n",
    "        pred = res_df['Pred_norm']\n",
    "    else:\n",
    "        actual = res_df['y']\n",
    "        pred = res_df['Pred']\n",
    "\n",
    "    # 메트릭 계산\n",
    "    # MASE = mase(np.array(train_series), np.array(actual), pred) \n",
    "    MAPE = mape(actual, pred) \n",
    "    RMSE = mean_squared_error(actual, pred)**0.5 \n",
    "    MAE = mean_absolute_error(actual,pred) \n",
    "    NRMSE = nrmse(actual,pred) \n",
    "    NMAE = nmae(actual,pred) \n",
    "    R2 = r2_score(actual, pred)\n",
    "    # RMSLE = mean_squared_log_error(actual, pred)**0.5 \n",
    "\n",
    "    # 계산된 메트릭을 데이터프레임에 추가\n",
    "    metric_df = pd.DataFrame({'MAPE':[round(MAPE, 4)],\n",
    "                           'RMSE':[round(RMSE, 4)],\n",
    "                           'MAE':[round(MAE, 4)],\n",
    "                           'NRMSE':[round(NRMSE, 4)],\n",
    "                           'NMAE':[round(NMAE, 4)],\n",
    "                           'R2':[round(R2, 4)]},\n",
    "                            index= [product_code])\n",
    "\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073bc376",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e45cb6",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ce9ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_single_Prophet(product_code, optimize_trials=30, forecast_period=90): # 최적화 횟수\n",
    "    start_time = time.time()\n",
    "    \n",
    "    product_code = product_code # 예측하고자 하는 코드 입력\n",
    "    product_df = df[df['Product_Code']== product_code].reset_index(drop=True)\n",
    "    product_df = product_df[['Date', 'Order_Demand']]\n",
    "    product_df.rename(columns={'Date': 'ds', 'Order_Demand': 'y'}, inplace=True)\n",
    "    # Prophet 단일 모델\n",
    "    best_model, res_df = Prophet_single(product_df, optimize_trials, forecast_period)\n",
    "    save_model(product_code, best_model)\n",
    "    # 모델 Metric과 Pred_Actual Plot 저장\n",
    "    metric_df_norm = calculate_metrics(product_code, res_df, True)\n",
    "    metric_df= calculate_metrics(product_code, res_df, False)\n",
    "    \n",
    "    actual_pred_plot(product_code, res_df, metric_df_norm, True)\n",
    "    actual_pred_plot(product_code, res_df, metric_df, False)\n",
    "    \n",
    "    # 실행시간 확인\n",
    "    elapsed_time_seconds = time.time() - start_time\n",
    "    elapsed_time_minutes = elapsed_time_seconds / 60\n",
    "    print(\"실행 시간: {:.2f} 분\".format(elapsed_time_minutes))\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5269ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2bffe",
   "metadata": {},
   "source": [
    "## Whole Process\n",
    "    - product_code에 str으로 예측하고자 하는 코드를 입력\n",
    "    - ['Product_0025', 'Product_0739', 'Product_0901', 'Product_1154',\n",
    "       'Product_1248', 'Product_1295', 'Product_1378', 'Product_2004']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d32c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = ['1', '2', '3', '4', '5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c4fcacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes = ['Product_0025', 'Product_0739', 'Product_0901', 'Product_1154',\n",
    "#          'Product_1248', 'Product_1295', 'Product_1378', 'Product_2004']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "095eda0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "========== 1 ==========\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:45:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:45:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ed59a135f74a83ba9b335e7ba8ee33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:45:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:45:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:45:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:45:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a718f4935d664d2088e2aa70a4c61ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:45:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:45:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "21:45:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:45:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c5b838e25d4212bcbe2d1fc7f305c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:45:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:45:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m========== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39mcode\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ==========\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mexecute_single_Prophet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m, in \u001b[0;36mexecute_single_Prophet\u001b[1;34m(product_code, optimize_trials, forecast_period)\u001b[0m\n\u001b[0;32m      7\u001b[0m product_df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrder_Demand\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Prophet 단일 모델\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m best_model, res_df \u001b[38;5;241m=\u001b[39m \u001b[43mProphet_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproduct_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_period\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m save_model(product_code, best_model)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 모델 Metric과 Pred_Actual Plot 저장\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m, in \u001b[0;36mProphet_single\u001b[1;34m(product_df, optimize_trials, forecast_period)\u001b[0m\n\u001b[0;32m      3\u001b[0m train_df, valid_df, test_df \u001b[38;5;241m=\u001b[39m split_data(product_df, forecast_period)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 파라미터 최적화\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_prophet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproduct_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_period\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 최적 파라미터를 사용한 모델 훈련\u001b[39;00m\n\u001b[0;32m      8\u001b[0m best_model \u001b[38;5;241m=\u001b[39m Prophet(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_params)\n",
      "Cell \u001b[1;32mIn[4], line 24\u001b[0m, in \u001b[0;36moptimize_prophet\u001b[1;34m(product_df, valid_df, optimize_trials, forecast_period)\u001b[0m\n\u001b[0;32m     22\u001b[0m m\u001b[38;5;241m.\u001b[39mfit(product_df)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# validation 기간에 대해 예측\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m df_cv \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoffs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mforecast_period\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m days\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# rolling_window: cut-off를 기준으로 몇 일의 성능을 계산할지 결정(1: 전체 기간동안의 성능)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m df_p \u001b[38;5;241m=\u001b[39m performance_metrics(df_cv, rolling_window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\prophet\\diagnostics.py:199\u001b[0m, in \u001b[0;36mcross_validation\u001b[1;34m(model, horizon, period, initial, parallel, cutoffs, disable_tqdm)\u001b[0m\n\u001b[0;32m    196\u001b[0m         predicts \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mgather(predicts)\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m     predicts \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    200\u001b[0m         single_cutoff_forecast(df, model, cutoff, horizon, predict_columns) \n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m cutoff \u001b[38;5;129;01min\u001b[39;00m (tqdm(cutoffs) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m disable_tqdm \u001b[38;5;28;01melse\u001b[39;00m cutoffs)\n\u001b[0;32m    202\u001b[0m     ]\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# Combine all predicted pd.DataFrame into one pd.DataFrame\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(predicts, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\prophet\\diagnostics.py:200\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    196\u001b[0m         predicts \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mgather(predicts)\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     predicts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 200\u001b[0m         \u001b[43msingle_cutoff_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_columns\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m cutoff \u001b[38;5;129;01min\u001b[39;00m (tqdm(cutoffs) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m disable_tqdm \u001b[38;5;28;01melse\u001b[39;00m cutoffs)\n\u001b[0;32m    202\u001b[0m     ]\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# Combine all predicted pd.DataFrame into one pd.DataFrame\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(predicts, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\prophet\\diagnostics.py:241\u001b[0m, in \u001b[0;36msingle_cutoff_forecast\u001b[1;34m(df, model, cutoff, horizon, predict_columns)\u001b[0m\n\u001b[0;32m    239\u001b[0m m\u001b[38;5;241m.\u001b[39mfit(history_c, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit_kwargs)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# Calculate yhat\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m index_predicted \u001b[38;5;241m=\u001b[39m (\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m cutoff \u001b[38;5;241m+\u001b[39m horizon)\n\u001b[0;32m    242\u001b[0m \u001b[38;5;66;03m# Get the columns for the future dataframe\u001b[39;00m\n\u001b[0;32m    243\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\core\\arraylike.py:56\u001b[0m, in \u001b[0;36mOpsMixin.__gt__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__gt__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__gt__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\core\\series.py:6092\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6089\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   6091\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 6092\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6094\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:279\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    271\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLengths must match to compare\u001b[39m\u001b[38;5;124m\"\u001b[39m, lvalues\u001b[38;5;241m.\u001b[39mshape, rvalues\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    272\u001b[0m         )\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    275\u001b[0m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    277\u001b[0m ):\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[1;32m--> 279\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_scalar(rvalues) \u001b[38;5;129;01mand\u001b[39;00m isna(rvalues):  \u001b[38;5;66;03m# TODO: but not pd.NA?\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m# numpy does not like comparisons vs None\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01mis\u001b[39;00m operator\u001b[38;5;241m.\u001b[39mne:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\core\\arraylike.py:56\u001b[0m, in \u001b[0;36mOpsMixin.__gt__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__gt__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__gt__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:977\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m    975\u001b[0m other_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unbox(other)\n\u001b[0;32m    976\u001b[0m \u001b[38;5;66;03m# GH#37462 comparison on i8 values is almost 2x faster than M8/m8\u001b[39;00m\n\u001b[1;32m--> 977\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ndarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mi8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_vals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mi8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m o_mask \u001b[38;5;241m=\u001b[39m isna(other)\n\u001b[0;32m    980\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_isnan \u001b[38;5;241m|\u001b[39m o_mask\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for code in codes:\n",
    "    print(\"==================================\")\n",
    "    print(f\"========== { code } ==========\")\n",
    "    print(\"==================================\")\n",
    "    execute_single_Prophet(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd6bfeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEMD_LSTM",
   "language": "python",
   "name": "eemd_lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
