{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0367e8",
   "metadata": {},
   "source": [
    "# LSTM Single Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9353f79f",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "    - Raw data: Historical Product Demand.csv\n",
    "\n",
    "    - Input data: Data on 8x augmentation of demand records by selecting 8 representative items\n",
    "\n",
    "    - Product code: 'Product_0025', 'Product_0739', 'Product_0901', 'Product_1154',\n",
    "                    'Product_1248', 'Product_1295', 'Product_1378', 'Product_2004'\n",
    "            \n",
    "\n",
    "    - Size of Data: 116392 rows × 4 columns\n",
    "\n",
    "    - Features: Date, Product_Code, Product_Category, Order_Demand\n",
    "\n",
    "    - Period: 2012-01-01 ~ 2017-01-09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba9ee40",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c9a71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "import warnings\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "\n",
    "#Save the log\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import tempfile\n",
    "\n",
    "# EEMD\n",
    "from PyEMD import EEMD\n",
    "\n",
    "# LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MSE\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Optimize\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "# Metric \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58e094",
   "metadata": {},
   "source": [
    "## Data Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f98bd020",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data\\\\JW_merged_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mJW_merged_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# pd.to_datetime(df['date'].max()) - pd.to_datetime(df['date'].min())\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# df = df.reset_index(drop=True)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# df.rename(columns={'date': 'Date', 'item':'Product_Code', 'sales':'Order_Demand'}, inplace=True)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# df['Date'] = pd.to_datetime(df['Date'])\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# df['Product_Code'] = df['Product_Code'].astype('str')\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data\\\\JW_merged_data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Data\\\\JW_merged_data.csv')\n",
    "df \n",
    "# pd.to_datetime(df['date'].max()) - pd.to_datetime(df['date'].min())\n",
    "# df = df.reset_index(drop=True)\n",
    "# df.rename(columns={'date': 'Date', 'item':'Product_Code', 'sales':'Order_Demand'}, inplace=True)\n",
    "# df['Date'] = pd.to_datetime(df['Date'])\n",
    "# df['Product_Code'] = df['Product_Code'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed38f8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 91300 entries, 0 to 91299\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Date          91300 non-null  datetime64[ns]\n",
      " 1   Product_Code  91300 non-null  object        \n",
      " 2   Order_Demand  91300 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(1)\n",
      "memory usage: 2.1+ MB\n",
      "None\n",
      "-------------------------\n",
      "\n",
      "The Number of unique\n",
      "-------------------------\n",
      "Product code:\t 50\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Product_Category'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct code:\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, df\u001b[38;5;241m.\u001b[39mProduct_Code\u001b[38;5;241m.\u001b[39mnunique())\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory:\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProduct_Category\u001b[49m\u001b[38;5;241m.\u001b[39mnunique())\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Product Code:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\pandas\\core\\generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5983\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5984\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5985\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5986\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5987\u001b[0m ):\n\u001b[0;32m   5988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Product_Category'"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print('-------------------------')\n",
    "print(\"\")\n",
    "print(\"The Number of unique\")\n",
    "print('-------------------------')\n",
    "print('Product code:\\t', df.Product_Code.nunique())\n",
    "print('Category:\\t', df.Product_Category.nunique())\n",
    "print('-------------------------')\n",
    "print(\"The Product Code:\")\n",
    "print(\"\")\n",
    "# for i, code in enumerate(df['Product_Code'].unique()):\n",
    "#     print(i+1, code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76850788",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4680cb42",
   "metadata": {},
   "source": [
    "### Split the train and test set\n",
    "- Input\n",
    "     data: dataframe with dates and Demand data\n",
    "     \n",
    "- output\n",
    "    - train:  whole data - valid, test\n",
    "    - valid:  2 * time steps\n",
    "    - test :  2 * time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "765de294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle the outlier\n",
    "def replace_outlier(product_df, train_end):\n",
    "\n",
    "    Q1 = product_df['y'].quantile(0.25)\n",
    "    Q3 = product_df['y'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    outlier_condition = (product_df['y'] < (Q1 - 1.5 * IQR)) | (product_df['y'] > (Q3 + 1.5 * IQR))\n",
    "    mean_y = product_df.loc[~outlier_condition, 'y'].mean()\n",
    "\n",
    "    product_df.loc[outlier_condition, 'y'] = mean_y\n",
    "    \n",
    "    return product_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dbe9b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(product_df, time_steps): \n",
    "\n",
    "    val_end = len(product_df)-2*time_steps\n",
    "    train_end = val_end - 2*time_steps\n",
    "    y = product_df.filter(['y']).values # y(수요량) 값\n",
    "    \n",
    "    # Minmax로 0~1 사이에 값이 오도록 정규화\n",
    "    sc = MinMaxScaler() # 객체 생성\n",
    "    y_scaled = sc.fit_transform(y) # 전체 y값 정규화\n",
    "    # Train Data\n",
    "    #y_train_scaled = y_scaled[:train_end,:]\n",
    "    X_train = [] \n",
    "    y_train = []\n",
    "    for i in range(time_steps, train_end-time_steps): \n",
    "        X_train.append(y_scaled[i-time_steps:i,0]) \n",
    "        y_train.append(y_scaled[i:i+time_steps,0])\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    # Reshape X_train for LSTM -> (batch_size, time_steps, features)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "    y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[1],1))\n",
    "    \n",
    "    # Validation Data\n",
    "    X_val = []\n",
    "    y_val = []\n",
    "    \n",
    "    X_val.append(y_scaled[train_end:train_end+time_steps, 0])\n",
    "    y_val.append(y_scaled[train_end+time_steps:val_end, 0])\n",
    "\n",
    "    X_val = np.array(X_val)\n",
    "    y_val = np.array(y_val)\n",
    "    # Reshape X_val for LSTM -> (batch_size, time_steps, features)\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1],1))\n",
    "    y_val = np.reshape(y_val, (y_val.shape[0], y_val.shape[1],1))\n",
    "    \n",
    "    # Test Data\n",
    "    X_test = []\n",
    "    X_test.append(y_scaled[val_end:val_end+time_steps,0])\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\n",
    "    \n",
    "    y_test = product_df.iloc[val_end+time_steps:,:]\n",
    "    y_test = y_test.copy()\n",
    "    y_test['y_norm'] = y_scaled[val_end+time_steps:].reshape(-1).copy()\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da9661",
   "metadata": {},
   "source": [
    "## Optimized LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee2f32fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    # 2개의 LSTM Layers\n",
    "    model.add(LSTM(units=hp.Int('units_1', min_value=32, max_value=512, step=64),\n",
    "                   activation=hp.Choice('activation_1', ['relu', 'tanh']),\n",
    "                   return_sequences=True, \n",
    "                   input_shape=(None,1)))\n",
    "    \n",
    "    model.add(LSTM(units=hp.Int('units_2', min_value=32, max_value=256, step=32),\n",
    "                   activation=hp.Choice('activation_2', ['relu', 'tanh']),\n",
    "                   return_sequences=True))\n",
    "    # Dense Layers 는 1~2개 \n",
    "    for i in range(hp.Int('num_layers', 1, 2)):\n",
    "        model.add(TimeDistributed(Dense(units=hp.Int('dense_units_' + str(i), min_value=16, max_value=64, step=16),\n",
    "                        activation=hp.Choice('dense_activation_'+ str(i), ['relu', 'tanh']))))\n",
    "        \n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mape','mae'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def optimize_model(X_train, y_train, X_val, y_val, X_test, sc, epochs, trials):\n",
    "    # 진행 상황 저장 할 필요없어서, 임시 경로 생성\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        tuner = RandomSearch(\n",
    "            build_model,\n",
    "            objective='val_loss',\n",
    "            max_trials= trials,\n",
    "            directory=temp_dir,\n",
    "            project_name='temp_project')\n",
    "\n",
    "    tuner.search_space_summary()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    # 최적의 조합 탐색\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=epochs,\n",
    "                 batch_size=32,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[early_stopping])\n",
    "\n",
    "    tuner.results_summary()\n",
    "\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "    # Test 데이터 예측\n",
    "    pred = best_model.predict(X_test) # 예측값 얻기\n",
    "    pred_norm = pred # 예측값을 저장하되, normalize된 값 저장\n",
    "    pred = sc.inverse_transform(pred.reshape(pred.shape[0], pred.shape[1]))\n",
    "    \n",
    "    best_model.summary()\n",
    "    # 모델 객체와 예측값 반환\n",
    "    return best_model, pred, pred_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1af524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_saved_model(X_test, path):\n",
    "    # 모델 파일 경로\n",
    "    model_path = path\n",
    "    \n",
    "    # 모델 로드\n",
    "    with open(model_path, 'rb') as file:\n",
    "        lstm_model = pickle.load(file)\n",
    "    lstm_model.summary()\n",
    "\n",
    "    pred = best_model.predict(X_test) # 예측값 얻기\n",
    "    pred_norm = pred # 예측값을 저장하되, normalize된 값 저장\n",
    "    pred = sc.inverse_transform(pred.reshape(pred.shape[0], pred.shape[1]))\n",
    "    \n",
    "    best_model.summary()\n",
    "    # 모델 객체와 예측값 반환\n",
    "    return best_model, pred, pred_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "502f9b87",
   "metadata": {},
   "outputs": [],
   "source": [
    " def LSTM_single(product_df, time_steps, epochs, trials):\n",
    "\n",
    "    # 학습 데이터와 테스트 데이터 분리\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, sc = split_data(product_df, time_steps)\n",
    "    \n",
    "    # LSTM 모델 학습 및 예측\n",
    "    best_model, pred, pred_norm = optimize_model(X_train, y_train, X_val, y_val, X_test, sc, epochs, trials)\n",
    "    # When you use a saved model\n",
    "    # best_model, pred, pred_norm = use_saved_model(X_test, path)\n",
    "    # 예측 결과 저장\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "    pred_df = pd.DataFrame({'Pred': pred.reshape(-1) ,'Pred_norm': pred_norm.reshape(-1)})\n",
    "    res_df = pd.concat([y_test, pred_df], axis=1)\n",
    "    res_df.set_index('Date', inplace=True)\n",
    "    res_df.loc[res_df['Pred']<0, 'Pred']=0\n",
    "    \n",
    "    # res_df: ['y', 'y_norm', 'Pred', 'Pred_norm'], index='Date'\n",
    "    # 모델과 result_df\n",
    "    return best_model, res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd64a0",
   "metadata": {},
   "source": [
    "## Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d8fe2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_pred_plot(product_code, res_df, metric_df, normalize):\n",
    "    today = date.today()\n",
    "    \"\"\"\n",
    "    Plot the actual vs predition and save the figure in the given directory\n",
    "    \"\"\"\n",
    "    \n",
    "    save_path = os.path.join(\"Result\", \"Single_LSTM_Result\", product_code)\n",
    "    save_name = f'{product_code}_all_result'\n",
    "    \n",
    "    title = f\"Pred Actual Plot - {product_code}\"\n",
    "    actual = res_df['y']\n",
    "    pred = res_df['Pred']\n",
    "    \n",
    "    if normalize: \n",
    "        title += \"(Normalized)\"\n",
    "        actual = res_df['y_norm']\n",
    "        pred = res_df['Pred_norm']\n",
    "        save_name += \"_normalized\"\n",
    "    # Plot   \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.xlabel(\"Time\", fontsize=14)\n",
    "    plt.ylabel(\"Order Demand\", fontsize=14)\n",
    "    plt.plot(actual, label ='Actual', alpha=0.6, marker='o', ms=3)\n",
    "    plt.plot(pred, label='Prediction', alpha=0.8, marker='o', ms=3)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "        \n",
    "    # Plot 결과 저장\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    # save the figure\n",
    "    today_date = f'_{today.month:02d}{today.day:02d}'\n",
    "    plt.savefig(os.path.join(save_path, save_name+'.png'))\n",
    "    # Metric도 함께 저장\n",
    "    metric_df.to_csv(os.path.join(save_path, save_name+'.csv'))\n",
    "        \n",
    "    plt.close('all') # close all figures to free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c10393",
   "metadata": {},
   "source": [
    "## Save and Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db0243bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(product_code, best_model):\n",
    "    today = date.today()\n",
    "    folder_path = 'Result/Single_LSTM_Result/Model'\n",
    "    file_name = f'{product_code}_{today.month:02d}{today.day:02d}.pkl'\n",
    "    save_path = os.path.join(folder_path, file_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    # 객체를 pickle 파일로 저장\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd8454",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28dd74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Metric\n",
    "def mase(training_series, testing_series, prediction_series):\n",
    "    n = training_series.shape[0]\n",
    "    d = np.abs(np.diff(training_series)).sum() / (n-1)\n",
    "    \n",
    "    errors = np.abs(testing_series - prediction_series)\n",
    "    return errors.mean() / d\n",
    "\n",
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / (actual+1)))\n",
    "\n",
    "# 정규화 된 지표\n",
    "def nrmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nrmse = mse / target_mean\n",
    "    return nrmse\n",
    "\n",
    "# 정규화 된 지표\n",
    "def nmae(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nmae = mae / target_mean\n",
    "    return nmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83451baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(product_code, res_df, normalize):\n",
    "    # 정규화 옵션이 True인 경우 정규화된 데이터 사용, 그렇지 않으면 원래 데이터 사용\n",
    "    if normalize:\n",
    "        actual = res_df['y_norm']\n",
    "        pred = res_df['Pred_norm']\n",
    "    else:\n",
    "        actual = res_df['y']\n",
    "        pred = res_df['Pred']\n",
    "\n",
    "    # 메트릭 계산\n",
    "    # MASE = mase(np.array(train_series), np.array(actual), pred) \n",
    "    MAPE = mape(actual, pred) \n",
    "    RMSE = mean_squared_error(actual, pred)**0.5 \n",
    "    MAE = mean_absolute_error(actual,pred) \n",
    "    NRMSE = nrmse(actual,pred) \n",
    "    NMAE = nmae(actual,pred)\n",
    "    R2 = r2_score(actual,pred) \n",
    "    # RMSLE = mean_squared_log_error(actual, pred)**0.5 \n",
    "\n",
    "    # 계산된 메트릭을 데이터프레임에 추가\n",
    "    metric_df = pd.DataFrame({'MAPE':[round(MAPE, 4)],\n",
    "                           'RMSE':[round(RMSE, 4)],\n",
    "                           'MAE':[round(MAE, 4)],\n",
    "                           'NRMSE':[round(NRMSE, 4)],\n",
    "                           'NMAE':[round(NMAE, 4)],\n",
    "                           'R2':[round(R2, 4)]},\n",
    "                            index= [product_code])\n",
    "\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073bc376",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e45cb6",
   "metadata": {},
   "source": [
    "## Check the Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2bffe",
   "metadata": {},
   "source": [
    "## Whole Process\n",
    "    - product_code에 str으로 예측하고자 하는 코드를 입력\n",
    "    - ['Product_0025', 'Product_0739', 'Product_0901', 'Product_1154',\n",
    "       'Product_1248', 'Product_1295', 'Product_1378', 'Product_2004']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ce9ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_single_LSTM(product_code, time_steps=90, epochs=100, optimize_trials=10):\n",
    "    start_time = time.time()\n",
    "    product_code = product_code # 예측하고자 하는 코드 입력\n",
    "    product_df = df[df['Product_Code']== product_code].reset_index(drop=True)\n",
    "    product_df = product_df[['Date', 'Order_Demand']]\n",
    "    product_df.rename(columns={'Order_Demand': 'y'}, inplace=True)\n",
    "\n",
    "    # LSTM 단일 모델\n",
    "    model, res_df = LSTM_single(product_df, time_steps, epochs, optimize_trials) #dictionary, time_steps, epochs\n",
    "    save_model(product_code, model)\n",
    "    # 모델 Metric과 Pred_Actual Plot 저장\n",
    "    metric_df_norm = calculate_metrics(product_code, res_df, True)\n",
    "    metric_df= calculate_metrics(product_code, res_df, False)\n",
    "    \n",
    "    actual_pred_plot(product_code, res_df, metric_df_norm, True)\n",
    "    actual_pred_plot(product_code, res_df, metric_df, False)\n",
    "    # 실행시간 확인\n",
    "    elapsed_time_seconds = time.time() - start_time\n",
    "    elapsed_time_minutes = elapsed_time_seconds / 60\n",
    "    print(\"실행 시간: {:.2f} 분\".format(elapsed_time_minutes))\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04203070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 25 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, None, 256)         264192    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, None, 64)          82176     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, None, 16)         1040      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, None, 16)         272       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, None, 1)          17        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 347,697\n",
      "Trainable params: 347,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "실행 시간: 0.05 분\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>NRMSE</th>\n",
       "      <th>NMAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3121</td>\n",
       "      <td>6.6391</td>\n",
       "      <td>5.2429</td>\n",
       "      <td>0.3256</td>\n",
       "      <td>0.2571</td>\n",
       "      <td>-0.3913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAPE    RMSE     MAE   NRMSE    NMAE      R2\n",
       "4  0.3121  6.6391  5.2429  0.3256  0.2571 -0.3913"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_single_LSTM('4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5269ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd262f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Complete [00h 02m 17s]\n",
      "val_loss: 0.022882860153913498\n",
      "\n",
      "Best val_loss So Far: 0.022460635751485825\n",
      "Total elapsed time: 00h 14m 16s\n",
      "\n",
      "Search: Running Trial #5\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "352               |480               |units_1\n",
      "tanh              |relu              |activation_1\n",
      "96                |160               |units_2\n",
      "relu              |tanh              |activation_2\n",
      "1                 |2                 |num_layers\n",
      "64                |32                |dense_units_0\n",
      "tanh              |tanh              |dense_activation_0\n",
      "0.001             |0.001             |learning_rate\n",
      "16                |48                |dense_units_1\n",
      "relu              |tanh              |dense_activation_1\n",
      "\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 17s 233ms/step - loss: 0.0343 - mape: 787969.1875 - mae: 0.1432 - val_loss: 0.0255 - val_mape: 32.8421 - val_mae: 0.1322\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 11s 211ms/step - loss: 0.0234 - mape: 855774.4375 - mae: 0.1216 - val_loss: 0.0238 - val_mape: 31.4597 - val_mae: 0.1271\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 10s 201ms/step - loss: 0.0227 - mape: 840046.3750 - mae: 0.1198 - val_loss: 0.0232 - val_mape: 31.8004 - val_mae: 0.1267\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 10s 201ms/step - loss: 0.0223 - mape: 839572.5000 - mae: 0.1188 - val_loss: 0.0230 - val_mape: 32.1309 - val_mae: 0.1267\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 10s 199ms/step - loss: 0.0223 - mape: 841146.5000 - mae: 0.1188 - val_loss: 0.0245 - val_mape: 35.5610 - val_mae: 0.1302\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 10s 198ms/step - loss: 0.0221 - mape: 824291.1875 - mae: 0.1184 - val_loss: 0.0229 - val_mape: 33.3142 - val_mae: 0.1272\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 10s 198ms/step - loss: 0.0220 - mape: 820090.8750 - mae: 0.1183 - val_loss: 0.0231 - val_mape: 33.6787 - val_mae: 0.1278\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 10s 200ms/step - loss: 0.0221 - mape: 813914.1250 - mae: 0.1184 - val_loss: 0.0232 - val_mape: 34.2742 - val_mae: 0.1279\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 10s 198ms/step - loss: 0.0219 - mape: 812101.2500 - mae: 0.1179 - val_loss: 0.0227 - val_mape: 33.1355 - val_mae: 0.1269\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 10s 198ms/step - loss: 0.0219 - mape: 807428.7500 - mae: 0.1180 - val_loss: 0.0225 - val_mape: 32.8798 - val_mae: 0.1259\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 10s 197ms/step - loss: 0.0220 - mape: 801641.1875 - mae: 0.1182 - val_loss: 0.0231 - val_mape: 34.2833 - val_mae: 0.1278\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 10s 194ms/step - loss: 0.0219 - mape: 801184.5000 - mae: 0.1179 - val_loss: 0.0231 - val_mape: 34.1962 - val_mae: 0.1268\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 10s 199ms/step - loss: 0.0217 - mape: 797689.3750 - mae: 0.1174 - val_loss: 0.0221 - val_mape: 32.2914 - val_mae: 0.1243\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 11s 202ms/step - loss: 0.0218 - mape: 807286.4375 - mae: 0.1176 - val_loss: 0.0230 - val_mape: 34.1152 - val_mae: 0.1268\n",
      "Epoch 15/100\n",
      "45/52 [========================>.....] - ETA: 1s - loss: 0.0217 - mape: 803426.0625 - mae: 0.1173"
     ]
    }
   ],
   "source": [
    "for code in ['4','5','6','7','9']:\n",
    "    print(\"==================================\")\n",
    "    print(f\"========== { code } ==========\")\n",
    "    print(\"==================================\")\n",
    "    execute_single_LSTM(code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEMD_LSTM",
   "language": "python",
   "name": "eemd_lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
