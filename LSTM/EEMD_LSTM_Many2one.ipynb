{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0367e8",
   "metadata": {},
   "source": [
    "# EEMD + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c9a71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, date\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "import warnings\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "\n",
    "#Save the log\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import tempfile\n",
    "\n",
    "# EEMD\n",
    "from PyEMD import EEMD\n",
    "\n",
    "# LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MSE\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Optimize\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "# Metric \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92eb040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minus\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "# 한글\n",
    "plt.rc('font', family='NanumGothic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b857798d",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bd48244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/JW_capstone.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed38f8d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(df.info())\n",
    "# print('-------------------------')\n",
    "# print(\"\")\n",
    "# print(\"The Number of unique\")\n",
    "# print('-------------------------')\n",
    "# print('Product code:\\t', df.Product_Code.nunique())\n",
    "# #print('Category:\\t', df.Product_Category.nunique())\n",
    "# print('-------------------------')\n",
    "# print(\"The Product Code:\")\n",
    "# print(\"\")\n",
    "# # for i, code in enumerate(df['Product_Code'].unique()):\n",
    "# #     print(i+1, code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76850788",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07916726",
   "metadata": {},
   "source": [
    "## EEMD\n",
    "    * 시계열 그래프를 ensembled IMF (앙상블 내재모드 함수)로 분해\n",
    "    * n 개의 eIMFs와  1개의 Residual 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb05a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eemd_fit(df):\n",
    "    # Define signal\n",
    "    t = np.array(df['Date']) # x-axis\n",
    "    s = np.array(df['y']) # y-axis\n",
    "\n",
    "    # EEMD 객체 생성\n",
    "    eemd = EEMD() # trials: EMD 횟수(default:100)\n",
    "    \n",
    "#     # 극값을 감지하는 방법으로 parabolic 방법을 선택\n",
    "#     emd = eemd.EMD\n",
    "#     emd.extrema_detection=\"parabol\"\n",
    "    \n",
    "    # eIMFs로 분해\n",
    "    eIMFs = eemd.eemd(s, t) # max_imf: IMF 제한 개수(-1: 없음)\n",
    "    nIMFs = eIMFs.shape[0] # eIMF의 개수\n",
    "    \n",
    "    # 분해된 eIMFs와 잔차를 변수에 할당\n",
    "    imfs, residue = eemd.get_imfs_and_residue()\n",
    "    \n",
    "    # 앙상블 IMFs 들의 DataFrame 생성\n",
    "    all_eIMFs_df = pd.DataFrame(eIMFs).transpose() \n",
    "    all_eIMFs_df[nIMFs] = residue # residue 열 마지막 열로 추가\n",
    "    all_eIMFs_df.insert(0, 'Date', df['Date']) # Date 열 추가\n",
    "    \n",
    "    # IMF & Residue 시각화\n",
    "    plt.figure(figsize=(12, nIMFs*2)) # Figure size 설정\n",
    "    for i in range(nIMFs):\n",
    "        plt.subplot(nIMFs+1, 1, i+1) # i번째 subplot\n",
    "        plt.plot(df['Date'], all_eIMFs_df[i], 'g')\n",
    "        plt.title('IMF '+str(i+1), fontsize=10)\n",
    "\n",
    "    # Residue plot\n",
    "    plt.subplot(nIMFs+1, 1, nIMFs+1)\n",
    "    plt.plot(df['Date'], all_eIMFs_df[nIMFs], 'r')\n",
    "    plt.title('Residue', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return all_eIMFs_df, nIMFs # eIMF+Residue들로 이루어진 df, eIMF의 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76e4a8c",
   "metadata": {},
   "source": [
    "### eIMFs 데이터프레임 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265e715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eIMF들을 추출하여, Date와 y로 이루어진 데이터프레임 추출하고 딕셔너리에 저장\n",
    "def extract_eIMFs(all_eIMFs_df, nIMFs):\n",
    "    all_eIMFs_dict = {}\n",
    "    # IMF개수+Residue(1) 만큼 반복\n",
    "    for i in range(nIMFs+1):\n",
    "        tmp_df = all_eIMFs_df[['Date', i]] # n번째 eIMF에 해당하는 날짜와 값 추출\n",
    "        tmp_df.columns=['Date', 'y'] # i -> y 로 열이름 변경\n",
    "        all_eIMFs_dict[f'eIMFs_{i}'] = tmp_df # n번째 eIMF 정보(마지막은 Residue) 딕셔너리에 저장\n",
    "                            # df.columns = ['Date', 'y']\n",
    "    return all_eIMFs_dict # {eIMFs_1: df1, eIMFs_2: df2, ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4680cb42",
   "metadata": {},
   "source": [
    "### Split the train and test set\n",
    "- Input\n",
    "     data: dataframe with dates and Demand data\n",
    "     \n",
    "- output\n",
    "    - train: ~ 2012-06-30\n",
    "    \n",
    "    - test :  2022-07-01 ~ 2012-12-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3be73251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(eIMF_df, time_steps): \n",
    "\n",
    "    train_end = len(eIMF_df[eIMF_df['Date']<'2022-07-01'])\n",
    "\n",
    "    y = eIMF_df.filter(['y']).values # y(수요량) 값\n",
    "    \n",
    "    # Minmax로 0~1 사이에 값이 오도록 정규화\n",
    "    sc = MinMaxScaler() # 객체 생성\n",
    "    \n",
    "    # Scaling the train Data \n",
    "    y_train_scaled = sc.fit_transform(y[:train_end, :])\n",
    "\n",
    "    X_train = [] \n",
    "    y_train = []\n",
    "    for i in range(time_steps, train_end-1): # pred_days days shifted\n",
    "        X_train.append(y_train_scaled[i-time_steps:i, 0]) # time steps 만큼 sliding window\n",
    "        y_train.append(y_train_scaled[i, 0]) # pred_days days shifted\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    # Reshape X_train for LSTM -> (batch_size, time_steps, features)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "    \n",
    "    # Test Data (SC set by train set)\n",
    "    y_test_scaled = sc.transform(y[train_end:, :])\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = eIMF_df.iloc[train_end+time_steps:] # pred_days days shifted\n",
    "    y_test['y_norm'] = y_test_scaled[time_steps:].reshape(-1).copy() # pred_days days shifted\n",
    "    \n",
    "    # test data 개수만큼 반복\n",
    "    for i in range(time_steps, len(y_test_scaled)): # pred_days days shifted\n",
    "        X_test.append(y_test_scaled[i-time_steps:i, 0])\n",
    "    \n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da9661",
   "metadata": {},
   "source": [
    "## Optimized LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eb7c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    # 2개의 LSTM Layers\n",
    "    model.add(LSTM(units=hp.Int('units_1', min_value=128, max_value=320, step=64),\n",
    "                   activation='tanh',\n",
    "                   return_sequences=True, \n",
    "                   input_shape=(None,1)))\n",
    "    \n",
    "    model.add(LSTM(units=hp.Int('units_2', min_value=64, max_value=256, step=32),\n",
    "                   activation='tanh',\n",
    "                   return_sequences=False))\n",
    "\n",
    "    model.add(Dense(units=hp.Int('dense_unit', min_value=16, max_value=128, step=16),\n",
    "                    activation='tanh'))\n",
    "        \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mae'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# 모델 학습 및 평가 함수\n",
    "def optimize_model(X_train, y_train, X_test, sc, epochs, trials):\n",
    "    # 진행 상황 저장 할 필요없어서, 임시 경로 생성\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        tuner = RandomSearch(\n",
    "            build_model,\n",
    "            objective='loss',\n",
    "            max_trials= trials,\n",
    "            directory=temp_dir,\n",
    "            project_name='temp_project')\n",
    "\n",
    "    tuner.search_space_summary()\n",
    "\n",
    "    # 최적의 조합 탐색\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=epochs,\n",
    "                 batch_size=8)\n",
    "\n",
    "    tuner.results_summary()\n",
    "\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "    # Test 데이터 예측\n",
    "    pred = best_model.predict(X_test) # 예측값 얻기\n",
    "    pred_norm = pred # 예측값을 저장하되, normalize된 값 저장\n",
    "    pred = sc.inverse_transform(pred) # denormalize된 예측값 저장\n",
    "    \n",
    "    best_model.summary()\n",
    "    # 모델 객체와 예측값 반환\n",
    "    return best_model, pred, pred_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b922e",
   "metadata": {},
   "source": [
    "### EEMD+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a404016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "EEMD의 결과로 분해된 ensembled IMF들에 대해\n",
    "각각 LSTM으로 예측하여 예측값을 얻은 후,\n",
    "마지막에 합산하여 전체 결과를 파악함\n",
    "'''\n",
    "def EEMD_LSTM(all_eIMFs_dict, time_steps, epochs, trials):\n",
    "\n",
    "    model_dict = {}\n",
    "    pred_dict = {}\n",
    "    print(epochs)\n",
    "    # 모든 eIMF에 대해 LSTM 모델 학습 및 예측 실행\n",
    "    for i in all_eIMFs_dict.keys():\n",
    "        print(f'--------Total: 0~{len(all_eIMFs_dict)-1} eIMFs, Now: {i} --------')\n",
    "        \n",
    "        # 현재 eIMF 데이터 가져오기\n",
    "        eIMF_df = all_eIMFs_dict[i]\n",
    "        \n",
    "        # 학습 데이터와 테스트 데이터 분리\n",
    "        X_train, y_train, X_test, y_test, sc = split_data(eIMF_df, time_steps)\n",
    "        \n",
    "        # LSTM 모델 학습 및 저장\n",
    "        best_model, pred, pred_norm = optimize_model(X_train, y_train, X_test, sc, epochs, trials)\n",
    "        \n",
    "        # imf 진행될수록  IMF 20씩 감소\n",
    "        epochs = round(epochs / 1.2) \n",
    "        \n",
    "        # When you use a saved model\n",
    "        # best_model, pred, pred_norm = use_saved_model(X_test, path)\n",
    "        model_dict[i] = best_model # 딕셔너리에 모델 정보 저장\n",
    "        \n",
    "        # 예측 결과 저장\n",
    "        y_test.reset_index(drop=True, inplace=True)\n",
    "        pred_df = pd.DataFrame({'Pred': pred.reshape(-1) ,'Pred_norm': pred_norm.reshape(-1)})\n",
    "        res_df = pd.concat([y_test, pred_df], axis=1)\n",
    "        \n",
    "        res_df.set_index('Date', inplace=True)\n",
    "        res_df.index = pd.to_datetime(res_df.index)\n",
    "        # res_df: ['y', 'y_norm', 'Pred', 'Pred_norm'], index='Date'\n",
    "        pred_dict[i] = res_df\n",
    "        \n",
    "    # 모델과 예측값 딕셔너리 반환\n",
    "    return model_dict, pred_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e883f",
   "metadata": {},
   "source": [
    "### Total Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40503729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_result_df(pred_dict):\n",
    "    all_df = pd.DataFrame()\n",
    "    for tmp_df in pred_dict.values():\n",
    "        all_df = pd.concat([all_df, tmp_df], axis=1)\n",
    "        \n",
    "    pred_df = all_df['Pred'].sum(axis=1)\n",
    "    actual_df = all_df['y'].sum(axis=1)\n",
    "    \n",
    "    all_result_df = pd.DataFrame({'Pred': pred_df, 'y': actual_df})\n",
    "    all_result_df.loc[all_result_df['Pred']<0, 'Pred']=0 # 음수 예측 값은 0으로 대치\n",
    "    \n",
    "    return all_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd64a0",
   "metadata": {},
   "source": [
    "## Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d8fe2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_pred_plot(product_code, pred_dict, all_result_df, metric_df):\n",
    "    today = date.today()\n",
    "    \"\"\"\n",
    "    Plot the actual vs predition and save the figure in the given directory\n",
    "    \"\"\"\n",
    "    # 전체 결과도 PLOT 하기 위해 딕셔너리에 추가\n",
    "    pred_dict['all_result'] = all_result_df\n",
    "    \n",
    "    save_path = os.path.join(\"Result\", \"EEMD+LSTM_Result\", product_code)\n",
    "        \n",
    "    for i, res_df in enumerate(pred_dict.values()):\n",
    "        img_n = len(pred_dict)\n",
    "        title = f\"Pred Actual Plot - ({i+1}/{len(pred_dict)-1})'s eIMF\"\n",
    "        \n",
    "        actual = res_df['y']\n",
    "        pred = res_df['Pred']\n",
    "        save_name = f'{product_code}_eIMF_{i+1}'\n",
    "        \n",
    "        if i == img_n-1: # All result\n",
    "            title = f\"{product_code}-All Result\"\n",
    "            save_name = f'{product_code}_all_result'\n",
    "\n",
    "        # Pred-Actual Plot\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.title(title, fontsize=20)\n",
    "        plt.xlabel(\"Date\", fontsize=14)\n",
    "        plt.ylabel(\"Order Demand\", fontsize=14)\n",
    "        plt.plot(res_df.index, actual, label ='Actual', color='r', marker='o', ms=3)\n",
    "        plt.plot(res_df.index, pred, label='Prediction',color='b', marker='o', ms=3)\n",
    "        \n",
    "        # x축의 주요 틱 위치를 매 월 첫날로 설정하고, 라벨을 해당 월로 표시\n",
    "        plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        \n",
    "        # Plot 결과 저장\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        # save the figure\n",
    "        today_date = f'_{today.month:02d}{today.day:02d}'\n",
    "        plt.savefig(os.path.join(save_path, save_name+'.png'))\n",
    "        plt.show()\n",
    "        \n",
    "    # Metric도 함께 저장\n",
    "    metric_df.to_csv(os.path.join(save_path, f'{product_code}_Metric.csv'), encoding=\"utf-8-sig\")\n",
    "    all_result_df.to_csv(os.path.join(save_path, f'{product_code}_total_result.csv'), encoding=\"utf-8-sig\")\n",
    "    del pred_dict['all_result']\n",
    "        \n",
    "    plt.close('all') # close all figures to free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f40e84d",
   "metadata": {},
   "source": [
    "## Save and Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "282ef103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(product_code, model_dict):\n",
    "    today = date.today()\n",
    "    folder_path = 'Result/EEMD+LSTM_Result/Model'\n",
    "    file_name = f'{product_code}_{today.month:02d}{today.day:02d}.pkl'\n",
    "    save_path = os.path.join(folder_path, file_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    # 객체를 pickle 파일로 저장\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(model_dict, f)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a8d031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_saved_model(X_test, path):\n",
    "    # 모델 파일 경로\n",
    "    model_path = path\n",
    "    \n",
    "    # 모델 로드\n",
    "    with open(model_path, 'rb') as file:\n",
    "        lstm_model = pickle.load(file)\n",
    "    lstm_model.summary()\n",
    "\n",
    "    pred = best_model.predict(X_test) # 예측값 얻기\n",
    "    pred_norm = pred # 예측값을 저장하되, normalize된 값 저장\n",
    "    pred = sc.inverse_transform(pred.reshape(pred.shape[0], pred.shape[1]))\n",
    "    \n",
    "    best_model.summary()\n",
    "    # 모델 객체와 예측값 반환\n",
    "    return best_model, pred, pred_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd8454",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28dd74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / (actual+1)))\n",
    "\n",
    "# 정규화 된 지표\n",
    "def nrmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nrmse = mse / target_mean\n",
    "    return nrmse\n",
    "\n",
    "# 정규화 된 지표\n",
    "def nmae(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nmae = mae / target_mean\n",
    "    return nmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83451baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred_df):\n",
    "    # 계산된 메트릭을 저장하기 위해 데이터프레임 초기화\n",
    "    metric_df = pd.DataFrame(columns=['MAPE', 'RMSE', 'MAE', 'NRMSE', 'NMAE', 'R2'])\n",
    "    \n",
    "    actual = pred_df['y']\n",
    "    pred = pred_df['Pred']\n",
    "\n",
    "    # 메트릭 계산\n",
    "    # MASE = mase(np.array(train_series), np.array(actual), pred) \n",
    "    MAPE = mape(actual, pred) \n",
    "    RMSE = mean_squared_error(actual, pred)**0.5 \n",
    "    MAE = mean_absolute_error(actual,pred) \n",
    "    NRMSE = nrmse(actual,pred) \n",
    "    NMAE = nmae(actual,pred) \n",
    "    R2 = r2_score(actual, pred)\n",
    "    # RMSLE = mean_squared_log_error(actual, pred)**0.5 \n",
    "\n",
    "    # 계산된 메트릭을 데이터프레임에 추가\n",
    "    tmp_df = pd.DataFrame({'MAPE':[round(MAPE, 4)],\n",
    "                           'RMSE':[round(RMSE, 4)],\n",
    "                           'MAE':[round(MAE, 4)],\n",
    "                           'NRMSE':[round(NRMSE, 4)],\n",
    "                           'NMAE':[round(NMAE, 4)],\n",
    "                           'R2': [round(R2, 4)]})\n",
    "\n",
    "    # 메트릭 데이터프레임에 결과 추가\n",
    "    metric_df = pd.concat([metric_df, tmp_df])\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073bc376",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e45cb6",
   "metadata": {},
   "source": [
    "## Check the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e560ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_metric_df(product_code, pred_dict, all_result_df):\n",
    "    today = date.today()\n",
    "\n",
    "    metric_df = pd.DataFrame(columns=['MAPE', 'RMSE', 'MAE', 'NRMSE', 'NMAE', 'R2'])\n",
    "    for i, pred_df in pred_dict.items():\n",
    "        imf_df = calculate_metrics(pred_df)\n",
    "        metric_df = pd.concat([metric_df, imf_df])\n",
    "    \n",
    "    imf_idx = pd.Index(['eIMF_'+str(i+1) for i in range(len(pred_dict))]) # changed result_dict to pred_dict\n",
    "    metric_df.index = imf_idx # Assign the created index to metric_df\n",
    "    \n",
    "    # 마지막 행은 전체 결과\n",
    "    metric_df = pd.concat([metric_df, calculate_metrics(all_result_df)], axis=0)\n",
    "    metric_df = metric_df.rename(index={metric_df.index[-1]: 'All'}) \n",
    "    \n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ce9ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_EEMD_LSTM(product_code, time_steps=10, epochs=50, optimize_trials=1):\n",
    "    start_time = time.time()\n",
    "    product_df = df[df['Product']== product_code].reset_index(drop=True)\n",
    "    \n",
    "    # EEMD 수행\n",
    "    all_eIMFs_df, nIMFs = eemd_fit(product_df)\n",
    "    # EEMD 결과에서 각 eIMFs' DF 추출\n",
    "    all_eIMFs_dict = extract_eIMFs(all_eIMFs_df, nIMFs)\n",
    "    # EEMD+LSTM 실행\n",
    "    model_dict, pred_dict = EEMD_LSTM(all_eIMFs_dict, time_steps, epochs, optimize_trials) #dictionary, time_steps, epochs\n",
    "    save_model(product_code, model_dict)\n",
    "    all_result_df = make_all_result_df(pred_dict)\n",
    "    \n",
    "    # Metric 성능 평가\n",
    "    metric_df = make_metric_df(product_code, pred_dict, all_result_df)\n",
    "    # Pred_Actual Plot\n",
    "    actual_pred_plot(product_code, pred_dict, all_result_df, metric_df)\n",
    "    \n",
    "    # 실행시간 확인\n",
    "    elapsed_time_seconds = time.time() - start_time\n",
    "    elapsed_time_minutes = elapsed_time_seconds / 60\n",
    "    print(\"실행 시간: {:.2f} 분\".format(elapsed_time_minutes))\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5269ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2bffe",
   "metadata": {},
   "source": [
    "## Whole Process\n",
    "    - product_code에 str으로 예측하고자 하는 코드를 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e25559e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m code \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m========== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39mcode\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ==========\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "for code in df['Product'].unique():\n",
    "    print(\"==================================\")\n",
    "    print(f\"========== { code } ==========\")\n",
    "    print(\"==================================\")\n",
    "    execute_EEMD_LSTM(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7352f10f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEMD_LSTM",
   "language": "python",
   "name": "eemd_lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
