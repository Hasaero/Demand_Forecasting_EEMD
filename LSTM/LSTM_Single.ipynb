{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0367e8",
   "metadata": {},
   "source": [
    "# LSTM Single Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba9ee40",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c9a71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, date\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Save the log\n",
    "import os\n",
    "import time\n",
    "import pickle \n",
    "import re\n",
    "\n",
    "# LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MSE\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "from keras_tuner import RandomSearch\n",
    "import tempfile\n",
    "\n",
    "# Metric \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca16dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minus\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "# 한글\n",
    "plt.rc('font', family='NanumGothic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58e094",
   "metadata": {},
   "source": [
    "## Data Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27f76ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/JW_capstone.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed38f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.info())\n",
    "# print('-------------------------')\n",
    "# print(\"\")\n",
    "# print(\"The Number of unique\")\n",
    "# print('-------------------------')\n",
    "# print('Product code:\\t', df.Product_Code.nunique())\n",
    "# print('Category:\\t', df.Product_Category.nunique())\n",
    "# print('-------------------------')\n",
    "# print(\"The Product Code:\")\n",
    "# print(\"\")\n",
    "# for i, code in enumerate(df['Product_Code'].unique()):\n",
    "#     print(i+1, code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76850788",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4680cb42",
   "metadata": {},
   "source": [
    "### Split the train and test set\n",
    "- Input\n",
    "     data: dataframe with dates and Demand data\n",
    "     \n",
    "- output\n",
    "    - train: ~ 2012-06-30\n",
    "    \n",
    "    - test :  2022-07-01 ~ 2012-12-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74c91201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(product_df, time_steps): \n",
    "\n",
    "    train_end = len(product_df[product_df['Date']<'2022-07-01'])\n",
    "\n",
    "    y = product_df.filter(['y']).values # y(수요량) 값\n",
    "    \n",
    "    # Minmax로 0~1 사이에 값이 오도록 정규화\n",
    "    sc = MinMaxScaler() # 객체 생성\n",
    "    \n",
    "    # Scaling the train Data \n",
    "    y_train_scaled = sc.fit_transform(y[:train_end, :])\n",
    "\n",
    "    X_train = [] \n",
    "    y_train = []\n",
    "    for i in range(time_steps, train_end-1): # pred_days days shifted\n",
    "        X_train.append(y_train_scaled[i-time_steps:i, 0]) # time steps 만큼 sliding window\n",
    "        y_train.append(y_train_scaled[i, 0]) # pred_days days shifted\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    # Reshape X_train for LSTM -> (batch_size, time_steps, features)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "    \n",
    "    # Test Data (SC set by train set)\n",
    "    y_test_scaled = sc.transform(y[train_end:, :])\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = product_df.iloc[train_end+time_steps:] # pred_days days shifted\n",
    "    y_test['y_norm'] = y_test_scaled[time_steps:].reshape(-1).copy() # pred_days days shifted\n",
    "    \n",
    "    # test data 개수만큼 반복\n",
    "    for i in range(time_steps, len(y_test_scaled)): # pred_days days shifted\n",
    "        X_test.append(y_test_scaled[i-time_steps:i, 0])\n",
    "    \n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da9661",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8576a",
   "metadata": {},
   "source": [
    "### Optimize Parameters using Keras Tuner\n",
    "    - (Random search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2395bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    # 2개의 LSTM Layers\n",
    "    model.add(LSTM(units=hp.Int('units_1', min_value=320, max_value=480, step=64),\n",
    "                   activation='tanh',\n",
    "                   return_sequences=True, \n",
    "                   input_shape=(None,1)))\n",
    "    \n",
    "    model.add(LSTM(units=hp.Int('units_2', min_value=128, max_value=320, step=32),\n",
    "                   activation='tanh',\n",
    "                   return_sequences=False))\n",
    "\n",
    "    model.add(Dense(units=hp.Int('dense_unit', min_value=16, max_value=128, step=16),\n",
    "                    activation='tanh'))\n",
    "        \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mae'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def optimize_model(X_train, y_train, X_test, sc, epochs, trials):\n",
    "    # 진행 상황 저장 할 필요없어서, 임시 경로 생성\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        tuner = RandomSearch(\n",
    "            build_model,\n",
    "            objective='loss',\n",
    "            max_trials= trials,\n",
    "            directory=temp_dir,\n",
    "            project_name='temp_project')\n",
    "\n",
    "    tuner.search_space_summary()\n",
    "\n",
    "    # 최적의 조합 탐색\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=epochs,\n",
    "                 batch_size=8)\n",
    "\n",
    "    tuner.results_summary()\n",
    "\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "    # Test 데이터 예측\n",
    "    pred = best_model.predict(X_test) # 예측값 얻기\n",
    "    pred_norm = pred # 예측값을 저장하되, normalize된 값 저장\n",
    "    pred = sc.inverse_transform(pred) # denormalize된 예측값 저장\n",
    "    \n",
    "    best_model.summary()\n",
    "    # 모델 객체와 예측값 반환\n",
    "    return best_model, pred, pred_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b922e",
   "metadata": {},
   "source": [
    "### LSTM Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a404016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_single(product_df, time_steps, epochs, trials):\n",
    "\n",
    "    # 학습 데이터와 테스트 데이터 분리\n",
    "    X_train, y_train, X_test, y_test, sc = split_data(product_df, time_steps)\n",
    "    \n",
    "    # LSTM 모델 학습 및 예측\n",
    "    best_model, pred, pred_norm = optimize_model(X_train, y_train, X_test, sc, epochs, trials=trials)\n",
    "    \n",
    "    # 예측 결과 저장\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "    pred_df = pd.DataFrame({'Pred': pred.reshape(-1) ,'Pred_norm': pred_norm.reshape(-1)})\n",
    "    res_df = pd.concat([y_test, pred_df], axis=1)\n",
    "    res_df.set_index('Date', inplace=True)\n",
    "    res_df.loc[res_df['Pred']<0, 'Pred']=0\n",
    "    # res_df: ['y', 'y_norm', 'Pred', 'Pred_norm'], index='Date'\n",
    "        \n",
    "    # 모델과 result_df\n",
    "    return best_model, res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd64a0",
   "metadata": {},
   "source": [
    "## Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d8fe2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_pred_plot(product_code, res_df, metric_df, normalize):\n",
    "    today = date.today()\n",
    "    \"\"\"\n",
    "    Plot the actual vs predition and save the figure in the given directory\n",
    "    \"\"\"\n",
    "    res_df.index = pd.to_datetime(res_df.index)\n",
    "    save_path = os.path.join(\"Result\", \"Single_LSTM_Result\", product_code)\n",
    "    save_name = f'{product_code}_all_result'\n",
    "    \n",
    "    title = f\"Pred Actual Plot - {product_code}\"\n",
    "    actual = res_df['y']\n",
    "    pred = res_df['Pred']\n",
    "    \n",
    "    if normalize: \n",
    "        title += \"(Normalized)\"\n",
    "        actual = res_df['y_norm']\n",
    "        pred = res_df['Pred_norm']\n",
    "        save_name += \"_normalized\"\n",
    "        \n",
    "    # Plot   \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.xlabel(\"Date\", fontsize=14)\n",
    "    plt.ylabel(\"Order Demand\", fontsize=14)\n",
    "\n",
    "    plt.plot(res_df.index, actual, label ='Actual', color='r', marker='o', ms=3)\n",
    "    plt.plot(res_df.index, pred, label='Prediction',color='b', marker='o', ms=3)\n",
    "    \n",
    "    # x축의 주요 틱 위치를 매 월 첫날로 설정하고, 라벨을 해당 월로 표시\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    \n",
    "    # Plot 결과 저장\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    # save the figure\n",
    "    today_date = f'_{today.month:02d}{today.day:02d}'\n",
    "    plt.savefig(os.path.join(save_path, save_name+today_date+'.png'))\n",
    "    plt.show()\n",
    "    # Metric도 함께 저장\n",
    "    metric_df.to_csv(os.path.join(save_path, save_name+today_date+'.csv'), encoding=\"utf-8-sig\")\n",
    "        \n",
    "    plt.close('all') # close all figures to free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c10393",
   "metadata": {},
   "source": [
    "## Save and Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db0243bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(product_code, best_model):\n",
    "    today = date.today()\n",
    "    folder_path = 'Result/Single_LSTM_Result/Model'\n",
    "    file_name = f'{product_code}_{today.month:02d}{today.day:02d}.pkl'\n",
    "    save_path = os.path.join(folder_path, file_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    # 객체를 pickle 파일로 저장\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e960cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file_path):\n",
    "    file_path = f'Result/Single_LSTM_Result/Model/{file_name}'\n",
    "    \n",
    "    with open(file_path, 'rb') as file:\n",
    "        model_dict= pickle.load(file)\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd8454",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28dd74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / (actual+1)))\n",
    "\n",
    "# 정규화 된 지표\n",
    "def nrmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nrmse = mse / target_mean\n",
    "    return nrmse\n",
    "\n",
    "# 정규화 된 지표\n",
    "def nmae(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nmae = mae / target_mean\n",
    "    return nmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83451baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(product_code, res_df, normalize):\n",
    "    # 정규화 옵션이 True인 경우 정규화된 데이터 사용, 그렇지 않으면 원래 데이터 사용\n",
    "    if normalize:\n",
    "        actual = res_df['y_norm']\n",
    "        pred = res_df['Pred_norm']\n",
    "    else:\n",
    "        actual = res_df['y']\n",
    "        pred = res_df['Pred']\n",
    "\n",
    "    # 메트릭 계산\n",
    "    MAPE = mape(actual, pred) \n",
    "    RMSE = mean_squared_error(actual, pred)**0.5 \n",
    "    MAE = mean_absolute_error(actual,pred) \n",
    "    NRMSE = nrmse(actual,pred) \n",
    "    NMAE = nmae(actual,pred)\n",
    "    R2 = r2_score(actual,pred) \n",
    "\n",
    "    # 계산된 메트릭을 데이터프레임에 추가\n",
    "    metric_df = pd.DataFrame({'MAPE':[round(MAPE, 4)],\n",
    "                           'RMSE':[round(RMSE, 4)],\n",
    "                           'MAE':[round(MAE, 4)],\n",
    "                           'NRMSE':[round(NRMSE, 4)],\n",
    "                           'NMAE':[round(NMAE, 4)],\n",
    "                           'R2':[round(R2, 4)]},\n",
    "                            index= [product_code])\n",
    "\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073bc376",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e45cb6",
   "metadata": {},
   "source": [
    "## Check the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ce9ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_single_LSTM(product_code, time_steps=10, epochs=50, trials=3):\n",
    "    start_time = time.time()\n",
    "\n",
    "    product_df = df[df['Product']== product_code].reset_index(drop=True)\n",
    "    product_df = product_df[['Date', 'y']]\n",
    "\n",
    "    # LSTM 단일 모델\n",
    "    model, res_df = LSTM_single(product_df, time_steps, epochs, trials) #dictionary, time_steps, epochs\n",
    "    print(res_df)\n",
    "    save_model(product_code, model)\n",
    "    # 모델 Metric과 Pred_Actual Plot 저장\n",
    "    #metric_df_norm = calculate_metrics(product_code, res_df, True)\n",
    "    metric_df= calculate_metrics(product_code, res_df, False)\n",
    "    \n",
    "    #actual_pred_plot(product_code, res_df, metric_df_norm, True)\n",
    "    actual_pred_plot(product_code, res_df, metric_df, False)\n",
    "    # 실행시간 확인\n",
    "    elapsed_time_seconds = time.time() - start_time\n",
    "    elapsed_time_minutes = elapsed_time_seconds / 60\n",
    "    print(\"실행 시간: {:.2f} 분\".format(elapsed_time_minutes))\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5269ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2bffe",
   "metadata": {},
   "source": [
    "## Whole Process\n",
    "    - product_code에 str으로 예측하고자 하는 코드를 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for product indf['Product'].unique():\n",
    "    print(\"==================================\")\n",
    "    print(f\"========== { product } ==========\")\n",
    "    print(\"==================================\")\n",
    "    execute_single_LSTM(product)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEMD_LSTM",
   "language": "python",
   "name": "eemd_lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
