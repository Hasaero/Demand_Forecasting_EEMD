{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0367e8",
   "metadata": {},
   "source": [
    "# LSTM Single Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba9ee40",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7c9a71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Date\n",
    "from datetime import datetime, date\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# Save the log\n",
    "import os\n",
    "import time\n",
    "import pickle \n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MSE\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Optimization\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "import tempfile\n",
    "\n",
    "# Metric \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eca16dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minus\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "# 한글\n",
    "plt.rc('font', family='NanumGothic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76850788",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4680cb42",
   "metadata": {},
   "source": [
    "### Split the train and test set\n",
    "- Input\n",
    "     data: dataframe with dates and Demand data\n",
    "     \n",
    "- output\n",
    "    - train: ~ 2012-06-30\n",
    "    \n",
    "    - test :  2022-07-01 ~ 2012-12-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f8238950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_feature_selection(df):\n",
    "    tmp_df = df.drop(columns=['Date','Product', '월', '일', '요일', '년월'])\n",
    "    # 데이터프레임에서 y값 열 추출\n",
    "    y = tmp_df.loc[:, 'y']\n",
    "    \n",
    "    # 데이터프레임에서 y값 열을 제외한 나머지 열을 X로 설정\n",
    "    X = tmp_df.drop(columns='y')\n",
    "    \n",
    "    # Lasso 회귀 모델 생성\n",
    "    lasso = Lasso(alpha=1)  # alpha 값을 조절하여 정규화 강도 조절 가능\n",
    "    \n",
    "    # 모델 훈련\n",
    "    lasso.fit(X, y)\n",
    "    \n",
    "    # 각 변수의 계수 출력\n",
    "    coefficients = pd.Series(lasso.coef_, index=X.columns)\n",
    "    print(\"각 변수의 계수:\")\n",
    "    print(coefficients)\n",
    "    \n",
    "    # 선택된 변수만 보여주기\n",
    "    selected_var = coefficients[coefficients != 0]\n",
    "    print(\"\\n선택된 변수:\")\n",
    "    print(selected_var)\n",
    "    \n",
    "    return selected_var.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "74c91201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(product_df, time_steps): \n",
    "    \n",
    "    train_end = len(product_df[product_df['Date']<'2022-07-01'])\n",
    "\n",
    "    selected_features = lasso_feature_selection(product_df)\n",
    "    selected_features += ['y'] # 종속변수 추가\n",
    "    # global var 설정 \n",
    "    global n_features\n",
    "    n_features = len(selected_features)\n",
    "    target_idx = selected_features.index('y')\n",
    "    \n",
    "    filtered_df = product_df.filter(selected_features)  # 다변량 features\n",
    "    sc = MinMaxScaler() \n",
    "    ## Train set \n",
    "    y_train_scaled = sc.fit_transform(filtered_df.iloc[:train_end, :])\n",
    "    \n",
    "    X_train = [] \n",
    "    y_train = []\n",
    "    for i in range(time_steps, train_end-1):\n",
    "        X_train.append(y_train_scaled[i-time_steps:i, :])  # 여러 feature들의 time steps 만큼의 데이터\n",
    "        y_train.append(y_train_scaled[i, target_idx])  # target 변수 (예: 'y')\n",
    "        \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], n_features))  # feature 개수를 반영\n",
    "    \n",
    "    ## Test set \n",
    "    y_test_scaled = sc.transform(filtered_df.iloc[train_end:, :])\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = product_df.iloc[train_end+time_steps:].copy()\n",
    "    y_test['y_norm'] = y_test_scaled[time_steps:, target_idx]  \n",
    "    \n",
    "    for i in range(time_steps, len(y_test_scaled)):\n",
    "        X_test.append(y_test_scaled[i-time_steps:i, :])\n",
    "    \n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], n_features))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, sc, n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da9661",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8576a",
   "metadata": {},
   "source": [
    "### Optimize Parameters using Keras Tuner\n",
    "    - (Random search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2395bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    # 2개의 LSTM Layers\n",
    "    model.add(LSTM(units=hp.Int('units_1', min_value=320, max_value=480, step=64),\n",
    "                   activation='tanh',\n",
    "                   return_sequences=True, \n",
    "                   input_shape=(None, n_features)))\n",
    "    \n",
    "    model.add(LSTM(units=hp.Int('units_2', min_value=128, max_value=320, step=32),\n",
    "                   activation='tanh',\n",
    "                   return_sequences=False))\n",
    "\n",
    "    model.add(Dense(units=hp.Int('dense_unit', min_value=16, max_value=128, step=16),\n",
    "                    activation='tanh'))\n",
    "        \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mae'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def optimize_model(X_train, y_train, X_test, sc, epochs, n_features, trials):\n",
    "    # 진행 상황 저장 할 필요없어서, 임시 경로 생성\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        tuner = RandomSearch(\n",
    "            build_model,\n",
    "            objective='loss',\n",
    "            max_trials= trials,\n",
    "            directory=temp_dir,\n",
    "            project_name='temp_project')\n",
    "\n",
    "    tuner.search_space_summary()\n",
    "\n",
    "    # 최적의 조합 탐색\n",
    "    tuner.search(X_train, \n",
    "                 y_train,\n",
    "                 epochs=epochs,\n",
    "                 batch_size=8)\n",
    "\n",
    "    tuner.results_summary()\n",
    "\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "    # Test 데이터 예측값\n",
    "    pred = best_model.predict(X_test) # 예측값 얻기\n",
    "    pred_norm = pred # 예측값을 저장하되, normalize된 값 저장\n",
    "    \n",
    "    pred_expanded = np.zeros((pred.shape[0], n_features))\n",
    "    pred_expanded[:,0] = pred.ravel()  # 첫 번째 feature에 pred 값을 채움\n",
    "    \n",
    "    # inverse_transform 적용\n",
    "    pred = sc.inverse_transform(pred_expanded)\n",
    "    pred = pred[:, 0]  # 원하는 첫 번째 feature만 선택\n",
    "\n",
    "    best_model.summary()\n",
    "    # 모델 객체와 예측값 반환\n",
    "    return best_model, pred, pred_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b922e",
   "metadata": {},
   "source": [
    "### LSTM Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a404016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_single(product_df, time_steps, epochs, trials):\n",
    "\n",
    "    # 학습 데이터와 테스트 데이터 분리\n",
    "    X_train, y_train, X_test, y_test, sc, n_features = split_data(product_df, time_steps)\n",
    "    \n",
    "    # LSTM 모델 학습 및 예측\n",
    "    best_model, pred, pred_norm = optimize_model(X_train, y_train, X_test, sc, epochs, n_features, trials=trials)\n",
    "    \n",
    "    # 예측 결과 저장\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "    pred_df = pd.DataFrame({'Pred': pred.reshape(-1) ,'Pred_norm': pred_norm.reshape(-1)})\n",
    "    res_df = pd.concat([y_test, pred_df], axis=1)\n",
    "    res_df.set_index('Date', inplace=True)\n",
    "    res_df.loc[res_df['Pred']<0, 'Pred']=0\n",
    "    # res_df: ['y', 'y_norm', 'Pred', 'Pred_norm'], index='Date'\n",
    "        \n",
    "    # 모델과 result_df\n",
    "    return best_model, res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd64a0",
   "metadata": {},
   "source": [
    "## Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "6d8fe2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_pred_plot(product_code, res_df, metric_df):\n",
    "    today = date.today()\n",
    "    \"\"\"\n",
    "    Plot the actual vs predition and save the figure in the given directory\n",
    "    \"\"\"\n",
    "    res_df.index = pd.to_datetime(res_df.index)\n",
    "    save_path = os.path.join(\"Result\", \"Single_LSTM_Result\", product_code)\n",
    "    save_name = f'{product_code}_all_result'\n",
    "    \n",
    "    title = f\"Pred Actual Plot - {product_code}\"\n",
    "    actual = res_df['y']\n",
    "    pred = res_df['Pred']\n",
    "\n",
    "    # Plot   \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.xlabel(\"Date\", fontsize=14)\n",
    "    plt.ylabel(\"Order Demand\", fontsize=14)\n",
    "\n",
    "    plt.plot(res_df.index, actual, label ='Actual', color='r', marker='o', ms=3)\n",
    "    plt.plot(res_df.index, pred, label='Prediction',color='b', marker='o', ms=3)\n",
    "    \n",
    "    # x축의 주요 틱 위치를 매 월 첫날로 설정하고, 라벨을 해당 월로 표시\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    \n",
    "    # Plot 결과 저장\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    # save the figure\n",
    "    today_date = f'_{today.month:02d}{today.day:02d}'\n",
    "    plt.savefig(os.path.join(save_path, save_name+today_date+'.png'))\n",
    "    plt.show()\n",
    "    # Metric도 함께 저장\n",
    "    metric_df.to_csv(os.path.join(save_path, save_name+today_date+'.csv'), encoding=\"utf-8-sig\")\n",
    "        \n",
    "    plt.close('all') # close all figures to free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c10393",
   "metadata": {},
   "source": [
    "## Save and Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "db0243bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(product_code, best_model):\n",
    "    today = date.today()\n",
    "    folder_path = 'Result/Single_LSTM_Result/Model'\n",
    "    file_name = f'{product_code}_{today.month:02d}{today.day:02d}.pkl'\n",
    "    save_path = os.path.join(folder_path, file_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    # 객체를 pickle 파일로 저장\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8e960cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file_path):\n",
    "    file_path = f'Result/Single_LSTM_Result/Model/{file_name}'\n",
    "    \n",
    "    with open(file_path, 'rb') as file:\n",
    "        model_dict= pickle.load(file)\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd8454",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "28dd74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / (actual+1)))\n",
    "\n",
    "# 정규화 된 지표\n",
    "def nrmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nrmse = mse / target_mean\n",
    "    return nrmse\n",
    "\n",
    "# 정규화 된 지표\n",
    "def nmae(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nmae = mae / target_mean\n",
    "    return nmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "83451baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(product_code, res_df):\n",
    "  \n",
    "    actual = res_df['y']\n",
    "    pred = res_df['Pred']\n",
    "\n",
    "    # 메트릭 계산\n",
    "    MAPE = mape(actual, pred) \n",
    "    RMSE = mean_squared_error(actual, pred)**0.5 \n",
    "    MAE = mean_absolute_error(actual,pred) \n",
    "    NRMSE = nrmse(actual,pred) \n",
    "    NMAE = nmae(actual,pred)\n",
    "    R2 = r2_score(actual,pred) \n",
    "\n",
    "    # 계산된 메트릭을 데이터프레임에 추가\n",
    "    metric_df = pd.DataFrame({'MAPE':[round(MAPE, 4)],\n",
    "                           'RMSE':[round(RMSE, 4)],\n",
    "                           'MAE':[round(MAE, 4)],\n",
    "                           'NRMSE':[round(NRMSE, 4)],\n",
    "                           'NMAE':[round(NMAE, 4)],\n",
    "                           'R2':[round(R2, 4)]},\n",
    "                            index= [product_code])\n",
    "\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073bc376",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e45cb6",
   "metadata": {},
   "source": [
    "## Check the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0096c305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "9ce9ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_single_LSTM(product_code, time_steps=10, epochs=30, trials=1):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    product_df = df[df['Product']== product_code].reset_index(drop=True)\n",
    "    \n",
    "    # LSTM 단일 모델\n",
    "    model, res_df = LSTM_single(product_df, time_steps, epochs, trials) #dictionary, time_steps, epochs\n",
    "  \n",
    "    save_model(product_code, model)\n",
    "    # 모델 Metric과 Pred_Actual Plot 저장\n",
    "    metric_df= calculate_metrics(product_code, res_df)\n",
    "    actual_pred_plot(product_code, res_df, metric_df)\n",
    "    \n",
    "    # 실행시간 확인\n",
    "    elapsed_time_seconds = time.time() - start_time\n",
    "    elapsed_time_minutes = elapsed_time_seconds / 60\n",
    "    print(\"실행 시간: {:.2f} 분\".format(elapsed_time_minutes))\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5269ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2bffe",
   "metadata": {},
   "source": [
    "## Whole Process\n",
    "    - product_code에 str으로 예측하고자 하는 코드를 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "27f76ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/JW/JW_capstone_data.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "eee37f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 변수의 계수:\n",
      "공휴일여부                  -47.646679\n",
      "소비자물가지수(2020＝100)_전국    -1.056890\n",
      "기업경기실사지수(실적)_제 조 업      -1.006330\n",
      "기업경기실사지수(전망)_제 조 업       0.528301\n",
      "경제심리지수_경제심리지수(순환변동치)    -0.618038\n",
      "경제심리지수_경제심리지수(원계열)       1.261020\n",
      "설비투자지수_총지수               0.139216\n",
      "수입물가지수(기본분류)_총지수        -0.000000\n",
      "수출물가지수(기본분류)_총지수         0.000000\n",
      "평균기온(°C)                -0.295487\n",
      "일강수량(mm)                 0.087123\n",
      "평균 풍속(m/s)               0.000000\n",
      "dtype: float64\n",
      "\n",
      "선택된 변수:\n",
      "공휴일여부                  -47.646679\n",
      "소비자물가지수(2020＝100)_전국    -1.056890\n",
      "기업경기실사지수(실적)_제 조 업      -1.006330\n",
      "기업경기실사지수(전망)_제 조 업       0.528301\n",
      "경제심리지수_경제심리지수(순환변동치)    -0.618038\n",
      "경제심리지수_경제심리지수(원계열)       1.261020\n",
      "설비투자지수_총지수               0.139216\n",
      "평균기온(°C)                -0.295487\n",
      "일강수량(mm)                 0.087123\n",
      "dtype: float64\n",
      "Search space summary\n",
      "Default search space size: 4\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 320, 'max_value': 480, 'step': 64, 'sampling': 'linear'}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 128, 'max_value': 320, 'step': 32, 'sampling': 'linear'}\n",
      "dense_unit (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 16, 'sampling': 'linear'}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "320               |320               |units_1\n",
      "224               |224               |units_2\n",
      "80                |80                |dense_unit\n",
      "0.01              |0.01              |learning_rate\n",
      "\n",
      "Epoch 1/30\n",
      "335/335 [==============================] - 11s 25ms/step - loss: 0.2037 - mae: 0.2242\n",
      "Epoch 2/30\n",
      "335/335 [==============================] - 9s 25ms/step - loss: 0.0504 - mae: 0.1707\n",
      "Epoch 3/30\n",
      "335/335 [==============================] - 9s 27ms/step - loss: 0.0483 - mae: 0.1658\n",
      "Epoch 4/30\n",
      "335/335 [==============================] - 10s 29ms/step - loss: 0.0474 - mae: 0.1638\n",
      "Epoch 5/30\n",
      "335/335 [==============================] - 9s 26ms/step - loss: 0.0477 - mae: 0.1638\n",
      "Epoch 6/30\n",
      "335/335 [==============================] - 9s 26ms/step - loss: 0.0467 - mae: 0.1615\n",
      "Epoch 7/30\n",
      "335/335 [==============================] - 9s 26ms/step - loss: 0.0459 - mae: 0.1604\n",
      "Epoch 8/30\n",
      "335/335 [==============================] - 9s 26ms/step - loss: 0.0485 - mae: 0.1657\n",
      "Epoch 9/30\n",
      "335/335 [==============================] - 9s 26ms/step - loss: 0.0458 - mae: 0.1584\n",
      "Epoch 10/30\n",
      "335/335 [==============================] - 9s 26ms/step - loss: 0.0441 - mae: 0.1543\n",
      "Epoch 11/30\n",
      "335/335 [==============================] - 9s 26ms/step - loss: 0.0434 - mae: 0.1526\n",
      "Epoch 12/30\n",
      "335/335 [==============================] - 9s 26ms/step - loss: 0.0436 - mae: 0.1546\n",
      "Epoch 13/30\n",
      "335/335 [==============================] - 10s 29ms/step - loss: 0.0427 - mae: 0.1511\n",
      "Epoch 14/30\n",
      "335/335 [==============================] - 10s 30ms/step - loss: 0.0422 - mae: 0.1497\n",
      "Epoch 15/30\n",
      "335/335 [==============================] - 9s 25ms/step - loss: 0.0408 - mae: 0.1455\n",
      "Epoch 16/30\n",
      "335/335 [==============================] - 9s 27ms/step - loss: 0.0403 - mae: 0.1443\n",
      "Epoch 17/30\n",
      "335/335 [==============================] - 10s 29ms/step - loss: 0.0410 - mae: 0.1452\n",
      "Epoch 18/30\n",
      "335/335 [==============================] - 10s 30ms/step - loss: 0.0404 - mae: 0.1423\n",
      "Epoch 19/30\n",
      " 43/335 [==>...........................] - ETA: 8s - loss: 0.0360 - mae: 0.1333"
     ]
    }
   ],
   "source": [
    "execute_single_LSTM('가나칸정')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "00f01b4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "========== 가나칸정 ==========\n",
      "==================================\n",
      "각 변수의 계수:\n",
      "공휴일여부                  -0.000000\n",
      "소비자물가지수(2020＝100)_전국   -0.032369\n",
      "기업경기실사지수(실적)_제 조 업     -0.142200\n",
      "기업경기실사지수(전망)_제 조 업      0.000000\n",
      "경제심리지수_경제심리지수(순환변동치)    0.000000\n",
      "경제심리지수_경제심리지수(원계열)      0.434766\n",
      "설비투자지수_총지수             -0.000000\n",
      "수입물가지수(기본분류)_총지수       -0.175626\n",
      "수출물가지수(기본분류)_총지수        0.000000\n",
      "평균기온(°C)               -0.180340\n",
      "일강수량(mm)                0.012408\n",
      "평균 풍속(m/s)              0.000000\n",
      "dtype: float64\n",
      "\n",
      "선택된 변수:\n",
      "소비자물가지수(2020＝100)_전국   -0.032369\n",
      "기업경기실사지수(실적)_제 조 업     -0.142200\n",
      "경제심리지수_경제심리지수(원계열)      0.434766\n",
      "수입물가지수(기본분류)_총지수       -0.175626\n",
      "평균기온(°C)               -0.180340\n",
      "일강수량(mm)                0.012408\n",
      "dtype: float64\n",
      "Search space summary\n",
      "Default search space size: 4\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 320, 'max_value': 480, 'step': 64, 'sampling': 'linear'}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 128, 'max_value': 320, 'step': 32, 'sampling': 'linear'}\n",
      "dense_unit (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 16, 'sampling': 'linear'}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "448               |448               |units_1\n",
      "224               |224               |units_2\n",
      "64                |64                |dense_unit\n",
      "0.001             |0.001             |learning_rate\n",
      "\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
      "Epoch 1/10\n",
      "335/335 [==============================] - 17s 41ms/step - loss: 0.0539 - mae: 0.1766\n",
      "Epoch 2/10\n",
      "335/335 [==============================] - 14s 42ms/step - loss: 0.0515 - mae: 0.1748\n",
      "Epoch 3/10\n",
      "334/335 [============================>.] - ETA: 0s - loss: 0.0500 - mae: 0.1709"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[210], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m========== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39mproduct\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ==========\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mexecute_single_LSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[207], line 8\u001b[0m, in \u001b[0;36mexecute_single_LSTM\u001b[1;34m(product_code, time_steps, epochs, trials)\u001b[0m\n\u001b[0;32m      5\u001b[0m product_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m product_code]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# LSTM 단일 모델\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model, res_df \u001b[38;5;241m=\u001b[39m \u001b[43mLSTM_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproduct_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#dictionary, time_steps, epochs\u001b[39;00m\n\u001b[0;32m     10\u001b[0m save_model(product_code, model)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 모델 Metric과 Pred_Actual Plot 저장\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[195], line 7\u001b[0m, in \u001b[0;36mLSTM_single\u001b[1;34m(product_df, time_steps, epochs, trials)\u001b[0m\n\u001b[0;32m      4\u001b[0m X_train, y_train, X_test, y_test, sc, n_features \u001b[38;5;241m=\u001b[39m split_data(product_df, time_steps)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# LSTM 모델 학습 및 예측\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m best_model, pred, pred_norm \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 예측 결과 저장\u001b[39;00m\n\u001b[0;32m     10\u001b[0m y_test\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[194], line 37\u001b[0m, in \u001b[0;36moptimize_model\u001b[1;34m(X_train, y_train, X_test, sc, epochs, n_features, trials)\u001b[0m\n\u001b[0;32m     34\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch_space_summary()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# 최적의 조합 탐색\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m             \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m tuner\u001b[38;5;241m.\u001b[39mresults_summary()\n\u001b[0;32m     44\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:230\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:270\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    271\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 235\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    238\u001b[0m     ):\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    243\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    244\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    250\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    251\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:287\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    286\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m--> 287\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    289\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:214\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m    213\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 214\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m tuner_utils\u001b[38;5;241m.\u001b[39mvalidate_trial_results(\n\u001b[0;32m    216\u001b[0m     results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperModel.fit()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m )\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py:144\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\keras\\engine\\training.py:1747\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1742\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1743\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1744\u001b[0m     }\n\u001b[0;32m   1745\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[1;32m-> 1747\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1748\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[0;32m   1749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\keras\\callbacks.py:453\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    451\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_logs(logs)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m--> 453\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\keras_tuner\\engine\\tuner_utils.py:172\u001b[0m, in \u001b[0;36mSaveBestEpoch.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mbetter_than(current_value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_value):\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_value \u001b[38;5;241m=\u001b[39m current_value\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\keras_tuner\\engine\\tuner_utils.py:179\u001b[0m, in \u001b[0;36mSaveBestEpoch._save_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;66;03m# Create temporary saved model files on non-chief workers.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m     write_filepath \u001b[38;5;241m=\u001b[39m file_utils\u001b[38;5;241m.\u001b[39mwrite_filepath(\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdistribute_strategy\n\u001b[0;32m    178\u001b[0m     )\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrite_filepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# Remove temporary saved model files on non-chief workers.\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     file_utils\u001b[38;5;241m.\u001b[39mremove_temp_dir_with_filepath(\n\u001b[0;32m    182\u001b[0m         write_filepath, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdistribute_strategy\n\u001b[0;32m    183\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\keras\\engine\\training.py:2898\u001b[0m, in \u001b[0;36mModel.save_weights\u001b[1;34m(self, filepath, overwrite, save_format, options)\u001b[0m\n\u001b[0;32m   2834\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[0;32m   2835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_weights\u001b[39m(\n\u001b[0;32m   2836\u001b[0m     \u001b[38;5;28mself\u001b[39m, filepath, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2837\u001b[0m ):\n\u001b[0;32m   2838\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Saves all layer weights.\u001b[39;00m\n\u001b[0;32m   2839\u001b[0m \n\u001b[0;32m   2840\u001b[0m \u001b[38;5;124;03m    Either saves in HDF5 or in TensorFlow format based on the `save_format`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2896\u001b[0m \u001b[38;5;124;03m            HDF5 format.\u001b[39;00m\n\u001b[0;32m   2897\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2898\u001b[0m     \u001b[43msaving_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2899\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2901\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2902\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2903\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2904\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\keras\\saving\\saving_api.py:230\u001b[0m, in \u001b[0;36msave_weights\u001b[1;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m     saving_lib\u001b[38;5;241m.\u001b[39msave_weights_only(model, filepath)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39msave_weights(\n\u001b[0;32m    231\u001b[0m         model, filepath, overwrite\u001b[38;5;241m=\u001b[39moverwrite, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    232\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\keras\\saving\\legacy\\save.py:371\u001b[0m, in \u001b[0;36msave_weights\u001b[1;34m(model, filepath, overwrite, save_format, options)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;66;03m# Call `get_session` to initialize any uninitialized variables.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m     backend\u001b[38;5;241m.\u001b[39mget_session()\n\u001b[1;32m--> 371\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# Record this checkpoint so it's visible from\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# tf.train.latest_checkpoint.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mupdate_checkpoint_state(\n\u001b[0;32m    376\u001b[0m     save_dir\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(filepath),\n\u001b[0;32m    377\u001b[0m     model_checkpoint_path\u001b[38;5;241m=\u001b[39mfilepath,\n\u001b[0;32m    378\u001b[0m     save_relative_paths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    379\u001b[0m     all_model_checkpoint_paths\u001b[38;5;241m=\u001b[39m[filepath],\n\u001b[0;32m    380\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:2256\u001b[0m, in \u001b[0;36mCheckpoint.write\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m   2254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file_prefix, os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[0;32m   2255\u001b[0m   file_prefix \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(file_prefix)\n\u001b[1;32m-> 2256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:2291\u001b[0m, in \u001b[0;36mCheckpoint._write\u001b[1;34m(self, file_prefix, options, write_done_callback)\u001b[0m\n\u001b[0;32m   2289\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   2290\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;129;01mor\u001b[39;00m checkpoint_options\u001b[38;5;241m.\u001b[39mCheckpointOptions()\n\u001b[1;32m-> 2291\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_saver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2292\u001b[0m output \u001b[38;5;241m=\u001b[39m _convert_file_name_tensor_to_string(output)\n\u001b[0;32m   2294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m write_done_callback:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:1304\u001b[0m, in \u001b[0;36mTrackableSaver.save\u001b[1;34m(self, file_prefix, checkpoint_number, session, options)\u001b[0m\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tensor_util\u001b[38;5;241m.\u001b[39mis_tensor(file_prefix):\n\u001b[0;32m   1302\u001b[0m   file_io\u001b[38;5;241m.\u001b[39mrecursive_create_dir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(file_prefix))\n\u001b[1;32m-> 1304\u001b[0m save_path, new_feed_additions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_cached_when_graph_building\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_prefix_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_graph_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_feed_additions:\n\u001b[0;32m   1308\u001b[0m   feed_dict\u001b[38;5;241m.\u001b[39mupdate(new_feed_additions)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:1242\u001b[0m, in \u001b[0;36mTrackableSaver._save_cached_when_graph_building\u001b[1;34m(self, file_prefix, object_graph_tensor, options)\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_save_object_graph \u001b[38;5;241m!=\u001b[39m graph_proto\n\u001b[0;32m   1235\u001b[0m     \u001b[38;5;66;03m# When executing eagerly, we need to re-create SaveableObjects each\u001b[39;00m\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;66;03m# time save() is called so they pick up new Tensors passed to their\u001b[39;00m\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;66;03m# constructors. That means the Saver needs to be copied with a new\u001b[39;00m\n\u001b[0;32m   1238\u001b[0m     \u001b[38;5;66;03m# var_list.\u001b[39;00m\n\u001b[0;32m   1239\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function()):\n\u001b[0;32m   1240\u001b[0m   saver \u001b[38;5;241m=\u001b[39m functional_saver\u001b[38;5;241m.\u001b[39mMultiDeviceSaver(serialized_tensors,\n\u001b[0;32m   1241\u001b[0m                                             registered_savers)\n\u001b[1;32m-> 1242\u001b[0m   save_op \u001b[38;5;241m=\u001b[39m \u001b[43msaver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1243\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/cpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1244\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies([save_op]):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\tensorflow\\python\\checkpoint\\functional_saver.py:407\u001b[0m, in \u001b[0;36mMultiDeviceSaver.save\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    405\u001b[0m   tf_function_save()\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 407\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msave_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\tensorflow\\python\\checkpoint\\functional_saver.py:381\u001b[0m, in \u001b[0;36mMultiDeviceSaver.save.<locals>.save_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    376\u001b[0m   saved_prefixes\u001b[38;5;241m.\u001b[39mappend(shard_prefix)\n\u001b[0;32m    377\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;66;03m# _SingleDeviceSaver will use the CPU device when necessary, but\u001b[39;00m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;66;03m# initial read operations should be placed on the SaveableObject's\u001b[39;00m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;66;03m# device.\u001b[39;00m\n\u001b[1;32m--> 381\u001b[0m     sharded_saves\u001b[38;5;241m.\u001b[39mappend(\u001b[43msaver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies(sharded_saves):\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;66;03m# Merge on the io_device if specified, otherwise co-locates the merge op\u001b[39;00m\n\u001b[0;32m    385\u001b[0m   \u001b[38;5;66;03m# with the last device used.\u001b[39;00m\n\u001b[0;32m    386\u001b[0m   merge_device \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    387\u001b[0m       options\u001b[38;5;241m.\u001b[39mexperimental_io_device \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    388\u001b[0m       saveable_object_util\u001b[38;5;241m.\u001b[39mset_cpu0(last_device))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\tensorflow\\python\\checkpoint\\functional_saver.py:84\u001b[0m, in \u001b[0;36m_SingleDeviceSaver.save\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m     82\u001b[0m save_device \u001b[38;5;241m=\u001b[39m save_device \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(save_device):\n\u001b[1;32m---> 84\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_specs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:1840\u001b[0m, in \u001b[0;36msave_v2\u001b[1;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[0;32m   1838\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1839\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1840\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msave_v2_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1841\u001b[0m \u001b[43m      \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_and_slices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1842\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[0;32m   1844\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:1861\u001b[0m, in \u001b[0;36msave_v2_eager_fallback\u001b[1;34m(prefix, tensor_names, shape_and_slices, tensors, name, ctx)\u001b[0m\n\u001b[0;32m   1859\u001b[0m _inputs_flat \u001b[38;5;241m=\u001b[39m [prefix, tensor_names, shape_and_slices] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(tensors)\n\u001b[0;32m   1860\u001b[0m _attrs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtypes\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_dtypes)\n\u001b[1;32m-> 1861\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSaveV2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1862\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1863\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1864\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for product in df['Product'].unique():\n",
    "    print(\"==================================\")\n",
    "    print(f\"========== { product } ==========\")\n",
    "    print(\"==================================\")\n",
    "    execute_single_LSTM(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177cedb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54231d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEMD_LSTM",
   "language": "python",
   "name": "eemd_lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
