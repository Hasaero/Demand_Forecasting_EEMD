{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0367e8",
   "metadata": {},
   "source": [
    "# EEMD + ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9353f79f",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "    - Raw data: Historical Product Demand.csv\n",
    "\n",
    "    - Input data: Data on 8x augmentation of demand records by selecting 8 representative items\n",
    "\n",
    "    - Product code: 'Product_0025', 'Product_0739', 'Product_0901', 'Product_1154',\n",
    "                    'Product_1248', 'Product_1295', 'Product_1378', 'Product_2004'\n",
    "            \n",
    "\n",
    "    - Size of Data: 116392 rows × 4 columns\n",
    "\n",
    "    - Features: Date, Product_Code, Product_Category, Order_Demand\n",
    "\n",
    "    - Period: 2012-01-01 ~ 2017-01-09\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba9ee40",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c9a71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "# Save the log\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "# EEMD\n",
    "from PyEMD import EEMD\n",
    "\n",
    "# ARIMA\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "# Metric \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58e094",
   "metadata": {},
   "source": [
    "## Data Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6c8f1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Product_Code</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Order_Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-05 00:00:00</td>\n",
       "      <td>Product_0025</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-05 03:00:00</td>\n",
       "      <td>Product_0025</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1633.403702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-05 06:00:00</td>\n",
       "      <td>Product_0025</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1628.665789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-05 09:00:00</td>\n",
       "      <td>Product_0025</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1587.586651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-05 12:00:00</td>\n",
       "      <td>Product_0025</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1513.949924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116387</th>\n",
       "      <td>2016-12-26 12:00:00</td>\n",
       "      <td>Product_2004</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1810.945746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116388</th>\n",
       "      <td>2016-12-26 15:00:00</td>\n",
       "      <td>Product_2004</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1626.979543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116389</th>\n",
       "      <td>2016-12-26 18:00:00</td>\n",
       "      <td>Product_2004</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1420.229634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116390</th>\n",
       "      <td>2016-12-26 21:00:00</td>\n",
       "      <td>Product_2004</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1206.795489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116391</th>\n",
       "      <td>2016-12-27 00:00:00</td>\n",
       "      <td>Product_2004</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116392 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date  Product_Code Product_Category  Order_Demand\n",
       "0      2012-01-05 00:00:00  Product_0025     Category_005   1600.000000\n",
       "1      2012-01-05 03:00:00  Product_0025     Category_005   1633.403702\n",
       "2      2012-01-05 06:00:00  Product_0025     Category_005   1628.665789\n",
       "3      2012-01-05 09:00:00  Product_0025     Category_005   1587.586651\n",
       "4      2012-01-05 12:00:00  Product_0025     Category_005   1513.949924\n",
       "...                    ...           ...              ...           ...\n",
       "116387 2016-12-26 12:00:00  Product_2004     Category_005   1810.945746\n",
       "116388 2016-12-26 15:00:00  Product_2004     Category_005   1626.979543\n",
       "116389 2016-12-26 18:00:00  Product_2004     Category_005   1420.229634\n",
       "116390 2016-12-26 21:00:00  Product_2004     Category_005   1206.795489\n",
       "116391 2016-12-27 00:00:00  Product_2004     Category_005   1000.000000\n",
       "\n",
       "[116392 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading\n",
    "df = pd.read_csv('Data\\HPD_Augmented_0416.csv')\n",
    "# Convert the string to the datetype\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed38f8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116392 entries, 0 to 116391\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   Date              116392 non-null  datetime64[ns]\n",
      " 1   Product_Code      116392 non-null  object        \n",
      " 2   Product_Category  116392 non-null  object        \n",
      " 3   Order_Demand      116392 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 3.6+ MB\n",
      "None\n",
      "-------------------------\n",
      "\n",
      "The Number of unique\n",
      "-------------------------\n",
      "Product code:\t 8\n",
      "Category:\t 5\n",
      "-------------------------\n",
      "The Product Code:\n",
      "\n",
      "1 Product_0025\n",
      "2 Product_0739\n",
      "3 Product_0901\n",
      "4 Product_1154\n",
      "5 Product_1248\n",
      "6 Product_1295\n",
      "7 Product_1378\n",
      "8 Product_2004\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print('-------------------------')\n",
    "print(\"\")\n",
    "print(\"The Number of unique\")\n",
    "print('-------------------------')\n",
    "print('Product code:\\t', df.Product_Code.nunique())\n",
    "print('Category:\\t', df.Product_Category.nunique())\n",
    "print('-------------------------')\n",
    "print(\"The Product Code:\")\n",
    "print(\"\")\n",
    "for i, code in enumerate(df['Product_Code'].unique()):\n",
    "    print(i+1, code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6d5a0f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4680cb42",
   "metadata": {},
   "source": [
    "## Data Split\n",
    "\n",
    "- Input\n",
    "     data: dataframe with dates and Demand data\n",
    "     \n",
    "- output\n",
    "    - train:  2012-01-01 ~ 2015-12/31 \n",
    "    - test :  2016-01-01 ~ 2017-01-06 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b41fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Split the train and test \n",
    "def split_data(df):\n",
    "    df['Date'] = pd.to_datetime(df['Date']).copy()\n",
    "    \n",
    "    train_df = df[(df['Date'] <'2016-01-01')].sort_values('Date', ascending=True)\n",
    "    test_df = df[(df['Date'] >= '2016-01-01')].sort_values('Date', ascending=True) \n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76850788",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07916726",
   "metadata": {},
   "source": [
    "## EEMD\n",
    "    * 시계열 그래프를 ensembled IMF (앙상블 내재모드 함수)로 분해\n",
    "    * n 개의 eIMFs와  1개의 Residual 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b907c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수요 그래프를 n개의 앙상블된 내재모드함수(IMF)로 분해\n",
    "# 그래프의 변동성이 클수록, IMF의 개수 증가\n",
    "def eemd_fit(df, trials, max_imf=-1):\n",
    "    \n",
    "    # Define signal\n",
    "    t = np.array(df['Date']) # 날짜\n",
    "    s = np.array(df['y']) # 수요량\n",
    "    \n",
    "    # EEMD 객체 생성\n",
    "    eemd = EEMD(trials=trials) # trials: EMD 횟수\n",
    "    \n",
    "    # 극값을 감지하는 방법으로 parabolic 방법을 선택\n",
    "    emd = eemd.EMD\n",
    "    emd.extrema_detection=\"parabol\"\n",
    "    \n",
    "    # eIMFs로 분해\n",
    "    eIMFs = eemd.eemd(s, t, max_imf=max_imf) # max_imf: IMF 제한 개수(-1: 없음)\n",
    "    nIMFs = eIMFs.shape[0] # eIMF의 개수\n",
    "    \n",
    "    # 분해된 eIMFs와 잔차를 변수에 할당\n",
    "    imfs, residue = eemd.get_imfs_and_residue()\n",
    "    \n",
    "    # 앙상블 IMFs 들의 DataFrame 생성\n",
    "    all_eIMFs_df = pd.DataFrame(eIMFs).transpose()\n",
    "    all_eIMFs_df[nIMFs] = residue # residue 열 마지막 열로 추가\n",
    "    all_eIMFs_df.insert(0, 'Date', df['Date']) # Date 열 추가\n",
    "    \n",
    "    return all_eIMFs_df, nIMFs # eIMF+Residue들로 이루어진 df, eIMF의 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76e4a8c",
   "metadata": {},
   "source": [
    "### eIMFs 데이터프레임 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "265e715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eIMF들을 추출하여, Date와 y로 이루어진 데이터프레임 추출하고 딕셔너리에 저장\n",
    "def extract_eIMFs(all_eIMFs_df, nIMFs):\n",
    "    all_eIMFs_dict = {}\n",
    "    # eIMF개수+Residue(1) 만큼 반복\n",
    "    for i in range(nIMFs+1):\n",
    "        tmp_df = all_eIMFs_df[['Date', i]] # n번째 eIMF에 해당하는 날짜와 값 추출\n",
    "        tmp_df.columns=['Date', 'y'] # i -> y 로 열이름 변경\n",
    "        all_eIMFs_dict[f'eIMFs_{i}'] = tmp_df # n번째 eIMF 정보(마지막은 Residue) 딕셔너리에 저장\n",
    "        \n",
    "                           # df: Date, y 2열로 이루어진 dataFrame\n",
    "    return all_eIMFs_dict # {eIMFs_1: df1, eIMFs_2: df2, ...} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6b94f0",
   "metadata": {},
   "source": [
    "### ARIMA combined EEMD \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dbe9b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "eIMFs의 DataFrame을 하나씩 반복하면서,\n",
    "auto_arima로 (p,d,q)의 최적값을 찾고,\n",
    "각 eIMFs들을 예측하고 예측 DataFrame을 Return\n",
    "'''\n",
    "def EEMD_ARIMA(all_eIMFs_dict):\n",
    "    model_dict = {}\n",
    "    pred_dict = {}\n",
    "    \n",
    "    for i in all_eIMFs_dict.keys():\n",
    "        print(f'--------Total: 0~{len(all_eIMFs_dict)-1} eIMFs, Now: {i} --------')\n",
    "        # eIMF_df 불러오기\n",
    "        eIMF_df = all_eIMFs_dict[i]\n",
    "        # Data split\n",
    "        train_df, test_df = split_data(eIMF_df)\n",
    "        # Search the propper (p,d,q)\n",
    "        best_model = auto_arima(train_df['y'], \n",
    "                                start_p=0, start_q=0,\n",
    "                                max_p=5, max_q=5, \n",
    "                                max_d=2, \n",
    "                                trace = False,\n",
    "                                suppress_warnings=True)\n",
    "        # fitting the model with best(p,d,q)\n",
    "        best_model_fit = best_model.fit(train_df['y'])\n",
    "        # Model save to the dictionary.\n",
    "        model_dict[i] = best_model_fit\n",
    "        # Prediction\n",
    "        predictions = best_model_fit.predict(n_periods=len(test_df))\n",
    "        # Make the Result DataFrame\n",
    "        res_df = test_df.copy()\n",
    "        res_df['Pred'] = predictions\n",
    "        \n",
    "        # 'y'와 'Pred' 열을 정규화\n",
    "        scaler = MinMaxScaler()\n",
    "        res_df[['y_norm', 'Pred_norm']] = scaler.fit_transform(res_df[['y', 'Pred']])\n",
    "        \n",
    "        res_df.set_index('Date', inplace=True)\n",
    "        # res_df: ['y'','Pred','y_norm','Pred_norm'] index='Date'\n",
    "        res_df = res_df.resample('D').first() # 증강되지 않은 데이터와만 비교\n",
    "        # dictionary에 result_df 저장\n",
    "        pred_dict[i] = res_df\n",
    "        \n",
    "    return model_dict, pred_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b94265",
   "metadata": {},
   "source": [
    "## Save and Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c24668b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(product_code, model_dict):\n",
    "    today = date.today()\n",
    "    folder_path = 'Result/EEMD+ARIMA_Result/Model'\n",
    "    file_name = f'{product_code}_{today.month:02d}{today.day:02d}.pkl'\n",
    "    save_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    # 객체를 pickle 파일로 저장\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(model_dict, f)\n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5de9ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델 pickle파일에서 불러오기\n",
    "def load_model(file_name):\n",
    "    file_path = f'Result/EEMD+ARIMA_Result/Model/{file_name}'\n",
    "    \n",
    "    with open(file_path, 'rb') as file:\n",
    "        model_dict= pickle.load(file)\n",
    "    \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8721a9",
   "metadata": {},
   "source": [
    "## Total Result\n",
    "\n",
    "    - 각각의 eIMFs들의 예측값을 합하여 전체의 예측값을 도출하였음.\n",
    "    - 전체 예측값이 음수가 나온 경우 0으로 대치함.\n",
    "    - EEMD의 수식은 아래에 근거하였음.\n",
    "    \n",
    "        IMFs(t)=ΣIMFs j(t)\n",
    "        \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40503729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_result_df(pred_dict, product_df):\n",
    "    # 전체 예측값에 비교 할 test_df를 추출하기 위함\n",
    "    train_df, test_df = split_data(product_df)\n",
    "    all_df = pd.DataFrame()\n",
    "    for tmp_df in pred_dict.values():\n",
    "        all_df = pd.concat([all_df, tmp_df], axis=1)\n",
    "    pred_df = all_df['Pred'].sum(axis=1) # eIMFs 예측값을 모두 더함\n",
    "    actual_df = test_df.set_index('Date').resample('D').first()['y'] # 증강되지 않은 부분만 indexing\n",
    "    # 전체 결과 데이터프레임 생성\n",
    "    all_result_df = pd.DataFrame({'Pred': pred_df, 'y': actual_df})\n",
    "    all_result_df.loc[all_result_df['Pred']<0, 'Pred']=0 # 음수 예측 값은 0으로 대치\n",
    "    # MinMaxScaler를 이용하여 정규화\n",
    "    # 날짜(Date) 열은 정규화하지 않으므로 제외\n",
    "    result_norm = all_result_df[['Pred', 'y']]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(result_norm)\n",
    "    \n",
    "    # 정규화된 데이터를 데이터 프레임에 반영합니다.\n",
    "    all_result_df['Pred_norm'] = normalized_data[:,0]\n",
    "    all_result_df['y_norm'] = normalized_data[:,1]\n",
    "    # all_res_df: ['y'','Pred','y_norm','Pred_norm'] index='Date'\n",
    "    return all_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd64a0",
   "metadata": {},
   "source": [
    "## Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d8fe2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the actual vs predition and save the figure in the given directory\n",
    "\"\"\"\n",
    "def actual_pred_plot(product_code, pred_dict, all_result_df, metric_df, normalize=False):\n",
    "    today = date.today()\n",
    "    # 전체 결과 비교를 위해 dictionary에 추가\n",
    "    pred_dict['all_result'] = all_result_df\n",
    "    \n",
    "    save_path = os.path.join(\"Result\", \"EEMD+ARIMA_Result\", product_code+f'_{today.month:02d}{today.day:02d}')\n",
    "    # Normalize된 결과는 다른 path에 저장\n",
    "    if normalize: save_path += \"_normalized\"\n",
    "    # 결과 df 하나씩 불러오기\n",
    "    for i, pred_df in enumerate(pred_dict.values()):\n",
    "        img_n = len(pred_dict)\n",
    "        title = f\"Pred Actual Plot - ({i+1}/{len(pred_dict)-1})'s eIMF\"\n",
    "        actual = pred_df['y']\n",
    "        pred = pred_df['Pred']\n",
    "        save_name = f'{product_code}_eIMF_{i+1}'\n",
    "        # All result -> 마지막 image\n",
    "        if i == img_n-1: \n",
    "            title = f\"{product_code}-All Result\"\n",
    "            save_name = f'{product_code}_all_result'\n",
    "        # 정규화 된 경우 actual, pred 값 달라짐\n",
    "        if normalize:\n",
    "            title += \"(Normalized)\"\n",
    "            actual = pred_df['y_norm']\n",
    "            pred = pred_df['Pred_norm']\n",
    "            \n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.title(title, fontsize=20)\n",
    "        plt.xlabel(\"Time\", fontsize=14)\n",
    "        plt.ylabel(\"Order Demand\", fontsize=14)\n",
    "        plt.plot(actual, label ='Actual', alpha=0.6)\n",
    "        plt.plot(pred, label='Prediction', alpha=0.8)\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        \n",
    "        # Plot 결과 저장\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        # save the figure\n",
    "        today_date = f'_{today.month:02d}{today.day:02d}'\n",
    "        plt.savefig(os.path.join(save_path, save_name+'.png'))\n",
    "    # metric도 각 path에 \n",
    "    metric_df.to_csv(os.path.join(save_path, f'{product_code}_Metric.csv'))\n",
    "    del pred_dict['all_result']\n",
    "        \n",
    "    plt.close('all') # close all figures to free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd8454",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28dd74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Metric\n",
    "def mase(training_series, testing_series, prediction_series):\n",
    "    n = training_series.shape[0]\n",
    "    d = np.abs(np.diff(training_series)).sum() / (n-1)\n",
    "    \n",
    "    errors = np.abs(testing_series - prediction_series)\n",
    "    return errors.mean() / d\n",
    "\n",
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / (actual+1)))\n",
    "\n",
    "# 정규화 된 지표\n",
    "def nrmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nrmse = mse / target_mean\n",
    "    return nrmse\n",
    "\n",
    "# 정규화 된 지표\n",
    "def nmae(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nmae = mae / target_mean\n",
    "    return nmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83451baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred_df, normalize):\n",
    "    # 계산된 메트릭을 저장하기 위해 데이터프레임 초기화\n",
    "    metric_df = pd.DataFrame(columns=['MAPE', 'RMSE', 'MAE', 'NRMSE', 'NMAE', 'R2'])\n",
    "\n",
    "    # 정규화 옵션이 True인 경우 정규화된 데이터 사용, \n",
    "    # 그렇지 않으면 원래 데이터 사용\n",
    "    if normalize:\n",
    "        actual = pred_df['y_norm']\n",
    "        pred = pred_df['Pred_norm']\n",
    "    else:\n",
    "        actual = pred_df['y']\n",
    "        pred = pred_df['Pred']\n",
    "\n",
    "    # 메트릭 계산\n",
    "    # MASE = mase(np.array(train_series), np.array(actual), pred) \n",
    "    MAPE = mape(actual, pred) \n",
    "    RMSE = mean_squared_error(actual, pred)**0.5 \n",
    "    MAE = mean_absolute_error(actual,pred) \n",
    "    NRMSE = nrmse(actual,pred) \n",
    "    NMAE = nmae(actual,pred) \n",
    "    R2 = r2_score(actual, pred)\n",
    "    # RMSLE = mean_squared_log_error(actual, pred)**0.5 \n",
    "\n",
    "    # 계산된 메트릭을 데이터프레임에 추가\n",
    "    tmp_df = pd.DataFrame({'MAPE':[round(MAPE, 4)],\n",
    "                           'RMSE':[round(RMSE, 4)],\n",
    "                           'MAE':[round(MAE, 4)],\n",
    "                           'NRMSE':[round(NRMSE, 4)],\n",
    "                           'NMAE':[round(NMAE, 4)],\n",
    "                           'R2': [round(R2, 4)]})\n",
    "\n",
    "    # 메트릭 데이터프레임에 결과 추가\n",
    "    metric_df = pd.concat([metric_df, tmp_df])\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073bc376",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e45cb6",
   "metadata": {},
   "source": [
    "## Check the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e560ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_metric_df(product_code, pred_dict, all_result_df, normalize):\n",
    "    today = date.today()\n",
    "\n",
    "    metric_df = pd.DataFrame(columns=['MAPE', 'RMSE', 'MAE', 'NRMSE', 'NMAE', 'R2'])\n",
    "    # eIMF 반복하면서 Metric 평가\n",
    "    for i, pred_df in pred_dict.items():\n",
    "        imf_df = calculate_metrics(pred_df, normalize=normalize)\n",
    "        metric_df = pd.concat([metric_df, imf_df])\n",
    "    \n",
    "    imf_idx = pd.Index(['eIMF_'+str(i+1) for i in range(len(pred_dict))]) # changed result_dict to pred_dict\n",
    "    metric_df.index = imf_idx # Assign the created index to metric_df\n",
    "    metric_df = pd.concat([metric_df, calculate_metrics(all_result_df, normalize=normalize)], axis=0)\n",
    "    metric_df = metric_df.rename(index={metric_df.index[-1]: 'All'}) # 마지막 행은 Total 결과\n",
    "    \n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ce9ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_EEMD_ARIMA(product_code, eemd_trials=100):\n",
    "    start_time = time.time()\n",
    "\n",
    "    product_code = product_code # 예측하고자 하는 코드 입력\n",
    "    product_df = df[df['Product_Code']== product_code].reset_index(drop=True)\n",
    "    product_df.rename(columns={'Order_Demand': 'y'}, inplace=True)\n",
    "    # EEMD 수행\n",
    "    all_eIMFs_df, nIMFs = eemd_fit(product_df, eemd_trials)\n",
    "    # EEMD 결과에서 각 eIMFs' DF 추출\n",
    "    all_eIMFs_dict = extract_eIMFs(all_eIMFs_df, nIMFs)\n",
    "    \n",
    "    # EEMD+ARIMA 실행\n",
    "    model_dict, pred_dict = EEMD_ARIMA(all_eIMFs_dict) #dictionary, time_steps, epochs\n",
    "    all_result_df = make_all_result_df(pred_dict, product_df)\n",
    "    # 모델 저장\n",
    "    save_model(product_code, model_dict)\n",
    "    metric_df_norm = make_metric_df(product_code, pred_dict, all_result_df, True)\n",
    "    metric_df = make_metric_df(product_code, pred_dict, all_result_df, False)\n",
    "    \n",
    "    actual_pred_plot(product_code, pred_dict, all_result_df, metric_df_norm, True)\n",
    "    actual_pred_plot(product_code, pred_dict, all_result_df, metric_df, False)\n",
    "    \n",
    "    elapsed_time_seconds = time.time() - start_time\n",
    "    elapsed_time_minutes = elapsed_time_seconds / 60\n",
    "    print(\"실행 시간: {:.2f} 분\".format(elapsed_time_minutes))\n",
    "    \n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5269ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2bffe",
   "metadata": {},
   "source": [
    "## Whole Process\n",
    "    - product_code에 str으로 예측하고자 하는 코드를 입력\n",
    "    - ['Product_0025', 'Product_0739', 'Product_0901', 'Product_1154',\n",
    "       'Product_1248', 'Product_1295', 'Product_1378', 'Product_2004']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "006eec1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "========== Product_1248 ==========\n",
      "==================================\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_0 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_1 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_2 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_3 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_4 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_5 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_6 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_7 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_8 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_9 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_10 --------\n",
      "실행 시간: 1.78 분\n",
      "==================================\n",
      "========== Product_1295 ==========\n",
      "==================================\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_0 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_1 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_2 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_3 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_4 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_5 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_6 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_7 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_8 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_9 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_10 --------\n",
      "실행 시간: 2.96 분\n",
      "==================================\n",
      "========== Product_1378 ==========\n",
      "==================================\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_0 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_1 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_2 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_3 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_4 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_5 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_6 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_7 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_8 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_9 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_10 --------\n",
      "실행 시간: 3.07 분\n",
      "==================================\n",
      "========== Product_2004 ==========\n",
      "==================================\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_0 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_1 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_2 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_3 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_4 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_5 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_6 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_7 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_8 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_9 --------\n",
      "--------Total: 0~10 eIMFs, Now: eIMFs_10 --------\n",
      "실행 시간: 1.76 분\n"
     ]
    }
   ],
   "source": [
    "for code in ['Product_1248', 'Product_1295', 'Product_1378', 'Product_2004']:\n",
    "    print(\"==================================\")\n",
    "    print(f\"========== { code } ==========\")\n",
    "    print(\"==================================\")\n",
    "    execute_EEMD_ARIMA(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65af7b",
   "metadata": {},
   "source": [
    "## Load the model\n",
    "    - 추후, 모델 결과를 다시 확인 할 일 있을 때, Model 파일 안에 있는 pickle 파일 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9d63723c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eIMFs_0': ARIMA(order=(0, 0, 2), scoring_args={}, seasonal_order=(2, 0, 0, 3),\n",
       "       suppress_warnings=True),\n",
       " 'eIMFs_1': ARIMA(order=(2, 0, 2), scoring_args={}, seasonal_order=(2, 0, 0, 3),\n",
       "       suppress_warnings=True),\n",
       " 'eIMFs_2': ARIMA(order=(2, 0, 2), scoring_args={}, seasonal_order=(2, 0, 1, 3),\n",
       "       suppress_warnings=True),\n",
       " 'eIMFs_3': ARIMA(order=(2, 0, 2), scoring_args={}, seasonal_order=(2, 0, 1, 3),\n",
       "       suppress_warnings=True, with_intercept=False),\n",
       " 'eIMFs_4': ARIMA(order=(2, 0, 2), scoring_args={}, seasonal_order=(1, 0, 1, 3),\n",
       "       suppress_warnings=True),\n",
       " 'eIMFs_5': ARIMA(order=(0, 0, 0), scoring_args={}, seasonal_order=(0, 0, 0, 3),\n",
       "       suppress_warnings=True, with_intercept=False),\n",
       " 'eIMFs_6': ARIMA(order=(0, 2, 0), scoring_args={}, seasonal_order=(2, 0, 1, 3),\n",
       "       suppress_warnings=True, with_intercept=False),\n",
       " 'eIMFs_7': ARIMA(order=(1, 2, 1), scoring_args={}, seasonal_order=(0, 0, 0, 3),\n",
       "       suppress_warnings=True, with_intercept=False),\n",
       " 'eIMFs_8': ARIMA(order=(0, 2, 0), scoring_args={}, seasonal_order=(0, 0, 0, 3),\n",
       "       suppress_warnings=True),\n",
       " 'eIMFs_9': ARIMA(order=(0, 0, 0), scoring_args={}, seasonal_order=(1, 0, 1, 3),\n",
       "       suppress_warnings=True, with_intercept=False)}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model('Product_0739_0503.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
