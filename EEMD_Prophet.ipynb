{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0367e8",
   "metadata": {},
   "source": [
    "# EEMD + Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9353f79f",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "    - Raw data: Historical Product Demand.csv\n",
    "\n",
    "    - Input data: Data on 8x augmentation of demand records by selecting 8 representative items\n",
    "\n",
    "    - Product code: 'Product_0025', 'Product_0739', 'Product_0901', 'Product_1154',\n",
    "                    'Product_1248', 'Product_1295', 'Product_1378', 'Product_2004'\n",
    "            \n",
    "\n",
    "    - Size of Data: 116392 rows × 4 columns\n",
    "\n",
    "    - Features: Date, Product_Code, Product_Category, Order_Demand\n",
    "\n",
    "    - Period: 2012-01-01 ~ 2017-01-09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba9ee40",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c9a71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import itertools\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Save the log\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Prophet \n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "\n",
    "# EEMD\n",
    "from PyEMD import EEMD\n",
    "\n",
    "# Metric\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58e094",
   "metadata": {},
   "source": [
    "## Data Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6c8f1d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "df = pd.read_csv('Data\\HPD_0416.csv')\n",
    "# convert the string to the datetype\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "# 범위 통일\n",
    "start_date = pd.to_datetime('2012-01-10')\n",
    "end_date = pd.to_datetime('2016-12-21')\n",
    "\n",
    "df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3788dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('Data\\\\train.csv')\n",
    "# df = df[(df['store']==1)]\n",
    "\n",
    "# pd.to_datetime(df['date'].max()) - pd.to_datetime(df['date'].min())\n",
    "# df = df.reset_index(drop=True)\n",
    "# df.rename(columns={'date': 'Date', 'item':'Product_Code', 'sales':'Order_Demand'}, inplace=True)\n",
    "# df = df[['Date', 'Product_Code', 'Order_Demand']]\n",
    "# df['Date'] = pd.to_datetime(df['Date'])\n",
    "# df['Product_Code'] = df['Product_Code'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed38f8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14464 entries, 0 to 14463\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Date              14464 non-null  datetime64[ns]\n",
      " 1   Product_Code      14464 non-null  object        \n",
      " 2   Product_Category  14464 non-null  object        \n",
      " 3   Order_Demand      14464 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 452.1+ KB\n",
      "None\n",
      "-------------------------\n",
      "\n",
      "The Number of unique\n",
      "-------------------------\n",
      "Product code:\t 8\n",
      "Category:\t 5\n",
      "-------------------------\n",
      "The Product Code:\n",
      "\n",
      "1 Product_0025\n",
      "2 Product_0739\n",
      "3 Product_0901\n",
      "4 Product_1154\n",
      "5 Product_1248\n",
      "6 Product_1295\n",
      "7 Product_1378\n",
      "8 Product_2004\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print('-------------------------')\n",
    "print(\"\")\n",
    "print(\"The Number of unique\")\n",
    "print('-------------------------')\n",
    "print('Product code:\\t', df.Product_Code.nunique())\n",
    "print('Category:\\t', df.Product_Category.nunique())\n",
    "print('-------------------------')\n",
    "print(\"The Product Code:\")\n",
    "print(\"\")\n",
    "for i, code in enumerate(df['Product_Code'].unique()):\n",
    "    print(i+1, code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76850788",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5082c250",
   "metadata": {},
   "source": [
    "## Split the data\n",
    "- Input\n",
    "     data: dataframe with dates and Demand data\n",
    "     \n",
    "- output\n",
    "    - train:  2012-01-01 ~ 2015-06/30 \n",
    "    - valid:  2015-07-01 ~ 2015-12-31\n",
    "    - test :  2016-01-01 ~ 2017-01-06 \n",
    "    \n",
    "    \n",
    "     \n",
    "- time_steps: # of the input time steps \n",
    "- for_periods: # of the output time steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "752aaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, forecast_period):\n",
    "    df = df.sort_values('ds')\n",
    "    \n",
    "    test_df = df[-forecast_period:]  # 뒤에서 forecast_period 개의 데이터\n",
    "    valid_df = df[-2*forecast_period:-forecast_period]  # 뒤에서 2*forecast_period 번째부터 forecast_period 번째까지의 데이터\n",
    "    train_df = df[:-2*forecast_period]  # 나머지 데이터\n",
    "    \n",
    "    return train_df, valid_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07916726",
   "metadata": {},
   "source": [
    "## EEMD\n",
    "    - 시계열 그래프를 ensembled IMF (앙상블 내재모드 함수)로 분해\n",
    "    - n 개의 eIMFs와  1개의 Residual 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b907c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eemd_fit(product_df, eemd_trials=100):\n",
    "    \n",
    "    # Define signal\n",
    "    t = np.array(product_df['ds'])\n",
    "    s = np.array(product_df['y'])\n",
    "    \n",
    "    # EEMD 객체 생성하기\n",
    "    eemd = EEMD(eemd_trials)\n",
    "    \n",
    "    # eIMFs로 분해\n",
    "    eIMFs = eemd.eemd(s, t) # max_imf: IMF 제한 개수(-1: 없음)\n",
    "    nIMFs = eIMFs.shape[0]\n",
    "    \n",
    "    # 분해된 eIMFs와 잔차 추출하기\n",
    "    imfs, residue = eemd.get_imfs_and_residue()\n",
    "    \n",
    "    # 앙상블 IMFs 들의 DataFrame 생성\n",
    "    all_eIMFs_df = pd.DataFrame(eIMFs).transpose()\n",
    "    all_eIMFs_df[nIMFs] = residue # residue 열 추가\n",
    "    all_eIMFs_df.insert(0, 'ds', product_df['ds']) # add 'ds' column for implementing prophet\n",
    "\n",
    "    return all_eIMFs_df, nIMFs # eIMF+Residue들로 이루어진 df, eIMF의 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76e4a8c",
   "metadata": {},
   "source": [
    "### eIMFs 데이터프레임 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "265e715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eIMF들을 추출하여, Date와 y로 이루어진 데이터프레임 추출하고 딕셔너리에 저장\n",
    "def extract_eIMFs(all_eIMFs_df, nIMFs):\n",
    "    all_eIMFs_dict = {}\n",
    "    # IMF개수+Residue(1) 만큼 반복\n",
    "    for i in range(nIMFs+1):\n",
    "        tmp_df = all_eIMFs_df[['ds', i]] # n번째 eIMF에 해당하는 날짜와 값 추출\n",
    "        tmp_df.columns=['ds', 'y'] # i -> y 로 열이름 변경\n",
    "        all_eIMFs_dict[f'eIMFs_{i}'] = tmp_df # n번째 eIMF 정보(마지막은 Residue) 딕셔너리에 저장\n",
    "                           # df: ds, y 2열로 이루어진 dataFrame\n",
    "    return all_eIMFs_dict # {eIMFs_1: df1, eIMFs_2: df2, ...} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec93c929",
   "metadata": {},
   "source": [
    "# EEMD+Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cfc834",
   "metadata": {},
   "source": [
    "### Optimize the hyper-parameters\n",
    "    - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "465d7436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_prophet(eIMF_df, valid_df, optimize_trials, forecast_period):\n",
    "    # 파라미터 후보\n",
    "    param_grid = {  \n",
    "        'changepoint_prior_scale': [0.01, 0.1, 1, 10],\n",
    "        'seasonality_prior_scale': [0.01, 0.1, 1, 10, 100],\n",
    "        'seasonality_mode': ['additive', 'multiplicative'],\n",
    "        'changepoint_range': [0.8, 0.9, 1.0],\n",
    "        }\n",
    "    \n",
    "    # 파라미터 조합 생성\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    rmses = []  \n",
    "    cutoff = pd.to_datetime(valid_df['ds'].max())  \n",
    "\n",
    "    # 랜덤 샘플링으로 50개의 조합 선택\n",
    "    selected_params = random.sample(all_params, optimize_trials)\n",
    "    \n",
    "    # 파리미터 평가를 위해 validation_data로 cv진행\n",
    "    for params in selected_params:\n",
    "        m = Prophet(**params)\n",
    "        m.add_country_holidays(country_name='US')  # 미국 공휴일 추가\n",
    "        m.fit(eIMF_df)\n",
    "        # validation 기간에 대해 예측\n",
    "        df_cv = cross_validation(m, cutoffs=[cutoff], horizon=str(forecast_period)+' days')  \n",
    "        # rolling_window: cut-off를 기준으로 몇 일의 성능을 계산할지 결정(1: 전체 기간동안의 성능)\n",
    "        df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "        rmses.append(df_p['rmse'].values[0])\n",
    "        \n",
    "    best_params = selected_params[np.argmin(rmses)]\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53cae742",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "eIMFs의 DataFrame을 하나씩 반복하면서,\n",
    "Random search를 통해 Prophet 파라미터의 최적값을 찾고,\n",
    "각 eIMFs들을 예측하고 예측 DataFrame을 Return\n",
    "'''\n",
    "def EEMD_Prophet(all_eIMFs_dict, forecast_period, optimize_trials): # optimize_trials: Search 횟수\n",
    "    model_dict = {}\n",
    "    pred_dict = {}\n",
    "    train_dict = {}\n",
    "    for i in all_eIMFs_dict.keys():\n",
    "        print(f'--------Total: 0~{len(all_eIMFs_dict)-1} eIMFs, Now: {i} --------')\n",
    "        \n",
    "        # 현재 eIMF 데이터 가져오기\n",
    "        eIMF_df = all_eIMFs_dict[i]\n",
    "        train_df, valid_df, test_df = split_data(eIMF_df, forecast_period)\n",
    "        train_dict[i] = train_df\n",
    "        # 파라미터 최적화\n",
    "        best_params = optimize_prophet(eIMF_df, valid_df, optimize_trials, forecast_period)\n",
    "        \n",
    "        # 최적 파라미터를 사용한 모델 훈련\n",
    "        best_model = Prophet(**best_params)\n",
    "        best_model.add_country_holidays(country_name='US')\n",
    "        best_model.fit(train_df)\n",
    "        # save the best model\n",
    "        model_dict[i] = best_model\n",
    "        # Prophet으로 예측\n",
    "        periods=(test_df['ds'].max() - train_df['ds'].max()).days\n",
    "        future = best_model.make_future_dataframe(periods=periods)\n",
    "        forecast = best_model.predict(future)\n",
    "        \n",
    "        # Result DataFrame 생성\n",
    "        res_df = pd.merge(test_df, forecast[['ds','yhat']], on='ds')\n",
    "        res_df = res_df[['ds', 'y', 'yhat']]\n",
    "        res_df.rename(columns={'yhat': 'Pred'}, inplace=True)\n",
    "        \n",
    "        # 'y'와 'yhat' 열을 정규화\n",
    "        scaler = MinMaxScaler()\n",
    "        res_df[['y_norm', 'Pred_norm']] = scaler.fit_transform(res_df[['y', 'Pred']])\n",
    "        res_df.set_index('ds', inplace=True)\n",
    "        \n",
    "        # 증강되지 않은 데이터와 비교 \n",
    "        pred_dict[i] = res_df # res_df: ['y'','Pred','y_norm','Pred_norm'] index='ds'\n",
    "        \n",
    "        # 모델과 예측값 딕셔너리 반환\n",
    "    return model_dict, pred_dict, train_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016e3355",
   "metadata": {},
   "source": [
    "## Total Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8b01419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_result_df(pred_dict):\n",
    "    all_df = pd.DataFrame()\n",
    "    for tmp_df in pred_dict.values():\n",
    "        all_df = pd.concat([all_df, tmp_df], axis=1)\n",
    "    pred_df = all_df['Pred'].sum(axis=1)\n",
    "    actual_df = all_df['y'].sum(axis=1)\n",
    "    \n",
    "    all_result_df = pd.DataFrame({'Pred': pred_df, 'y': actual_df})\n",
    "    all_result_df.loc[all_result_df['Pred']<0, 'Pred']=0 # 음수 예측 값은 0으로 대치\n",
    "    \n",
    "    # 날짜(Date) 열은 정규화하지 않으므로 제외\n",
    "    result_norm = all_result_df[['Pred', 'y']]\n",
    "    \n",
    "    # MinMaxScaler를 이용하여 정규화\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(result_norm)\n",
    "    \n",
    "    # 정규화된 데이터를 데이터 프레임에 추가\n",
    "    all_result_df['Pred_norm'] = normalized_data[:,0]\n",
    "    all_result_df['y_norm'] = normalized_data[:,1]\n",
    "    return all_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd64a0",
   "metadata": {},
   "source": [
    "# Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d8fe2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_pred_plot(product_code, pred_dict, all_result_df, metric_df, normalize=False):\n",
    "    today = date.today()\n",
    "    \"\"\"\n",
    "    Plot the actual vs predition and save the figure in the given directory\n",
    "    \"\"\"\n",
    "    pred_dict['all_result'] = all_result_df\n",
    "    \n",
    "    save_path = os.path.join(\"Result\", \"EEMD+Prophet_Result\", product_code+f'_{today.month:02d}{today.day:02d}')\n",
    "    if normalize: save_path += \"_normalized\"\n",
    "        \n",
    "    for i, pred_df in enumerate(pred_dict.values()):\n",
    "        img_n = len(pred_dict)\n",
    "        title = f\"Pred Actual Plot - ({i+1}/{len(pred_dict)-1})'s eIMF\"\n",
    "        actual = pred_df['y']\n",
    "        pred = pred_df['Pred']\n",
    "        save_name = f'{product_code}_eIMF_{i+1}'\n",
    "        if i == img_n-1: # All result\n",
    "            title = f\"{product_code}-All Result\"\n",
    "            save_name = f'{product_code}_all_result'\n",
    "        # 정규화 된 경우 actual, pred 값 달라짐\n",
    "        if normalize:\n",
    "            title += \"(Normalized)\"\n",
    "            actual = pred_df['y_norm']\n",
    "            pred = pred_df['Pred_norm']\n",
    "            \n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.title(title, fontsize=20)\n",
    "        plt.xlabel(\"Time\", fontsize=14)\n",
    "        plt.ylabel(\"Order Demand\", fontsize=14)\n",
    "        plt.plot(actual, label ='Actual', alpha=0.6)\n",
    "        plt.plot(pred, label='Prediction', alpha=0.8)\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        \n",
    "        # Plot 결과 저장\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        # save the figure\n",
    "        today_date = f'_{today.month:02d}{today.day:02d}'\n",
    "        plt.savefig(os.path.join(save_path, save_name+'.png'))\n",
    "    # Metric도 함께 저장\n",
    "    metric_df.to_csv(os.path.join(save_path, f'{product_code}_Metric.csv'))\n",
    "    all_result_df.to_csv(os.path.join(save_path, f'{product_code}_Total_result.csv'))\n",
    "    del pred_dict['all_result']\n",
    "        \n",
    "    plt.close('all') # close all figures to free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd8454",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28dd74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Metric\n",
    "def mase(actual, pred, train):\n",
    "    \"\"\"\n",
    "    actual: 실제 값이 저장된 1차원 배열\n",
    "    pred: 예측 값이 저장된 1차원 배열\n",
    "    train: 인-샘플 데이터(즉, 훈련 데이터)가 저장된 1차원 배열\n",
    "    \"\"\"\n",
    "    actual, pred, train = np.array(actual), np.array(pred), np.array(train)\n",
    "    n = len(actual)\n",
    "    d = np.abs(actual - pred)\n",
    "    d_naive = np.abs(train[1:] - train[:-1]).mean()  # train의 naive pred\n",
    "    return d.mean() / d_naive\n",
    "\n",
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / (actual+1)))\n",
    "\n",
    "# 정규화 된 지표\n",
    "def nrmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nrmse = mse / target_mean\n",
    "    return nrmse\n",
    "\n",
    "# 정규화 된 지표\n",
    "def nmae(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nmae = mae / target_mean\n",
    "    return nmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83451baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred_df, normalize):\n",
    "    # 계산된 메트릭을 저장하기 위해 데이터프레임 초기화\n",
    "    metric_df = pd.DataFrame(columns=['MAPE', 'RMSE', 'MAE', 'NRMSE', 'NMAE', 'R2'])\n",
    "\n",
    "    # 정규화 옵션이 True인 경우 정규화된 데이터 사용, 그렇지 않으면 원래 데이터 사용\n",
    "    if normalize:\n",
    "        actual = pred_df['y_norm']\n",
    "        pred = pred_df['Pred_norm']\n",
    "    else:\n",
    "        actual = pred_df['y']\n",
    "        pred = pred_df['Pred']\n",
    "\n",
    "    # 메트릭 계산\n",
    "    # MASE = mase(np.array(train_series), np.array(actual), pred) \n",
    "    MAPE = mape(actual, pred) \n",
    "    RMSE = mean_squared_error(actual, pred)**0.5 \n",
    "    MAE = mean_absolute_error(actual,pred) \n",
    "    NRMSE = nrmse(actual,pred) \n",
    "    NMAE = nmae(actual,pred) \n",
    "    R2 = r2_score(actual, pred)\n",
    "    # RMSLE = mean_squared_log_error(actual, pred)**0.5 \n",
    "\n",
    "    # 계산된 메트릭을 데이터프레임에 추가\n",
    "    tmp_df = pd.DataFrame({'MAPE':[round(MAPE, 2)],\n",
    "                           'RMSE':[round(RMSE, 2)],\n",
    "                           'MAE':[round(MAE, 2)],\n",
    "                           'NRMSE':[round(NRMSE, 2)],\n",
    "                           'NMAE':[round(NMAE, 4)],\n",
    "                           'R2':[round(R2, 4)]})\n",
    "\n",
    "    # 메트릭 데이터프레임에 결과 추가\n",
    "    metric_df = pd.concat([metric_df, tmp_df])\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e560ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_metric_df(product_code, pred_dict, all_result_df, normalize):\n",
    "    today = date.today()\n",
    "\n",
    "    metric_df = pd.DataFrame(columns=['MAPE', 'RMSE', 'MAE', 'NRMSE', 'NMAE', 'R2'])\n",
    "    for i, pred_df in pred_dict.items():\n",
    "        imf_df = calculate_metrics(pred_df, normalize=normalize)\n",
    "        metric_df = pd.concat([metric_df, imf_df])\n",
    "    \n",
    "    imf_idx = pd.Index(['eIMF_'+str(i+1) for i in range(len(pred_dict))]) # changed result_dict to pred_dict\n",
    "    metric_df.index = imf_idx # Assign the created index to metric_df\n",
    "    metric_df = pd.concat([metric_df, calculate_metrics(all_result_df, normalize=normalize)], axis=0)\n",
    "    metric_df = metric_df.rename(index={metric_df.index[-1]: 'All'}) # 마지막 행은 all\n",
    "    \n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073bc376",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848e0b41",
   "metadata": {},
   "source": [
    "## Save and Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8130db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(product_code, model_dict):\n",
    "    today = date.today()\n",
    "    folder_path = 'Result/EEMD+Prophet_Result/Model'\n",
    "    file_name = f'{product_code}_{today.month:02d}{today.day:02d}.pkl'\n",
    "    save_path = os.path.join(folder_path, file_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    # 객체를 pickle 파일로 저장\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(model_dict, f)\n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "626bb1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델 pickle파일에서 불러오기\n",
    "def load_model(file_name):\n",
    "    file_path = f'Result/EEMD+Prophet_Result/Model/{file_name}'\n",
    "    \n",
    "    with open(file_path, 'rb') as file:\n",
    "        model_dict= pickle.load(file)\n",
    "    \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eafe3d",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ce9ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_EEMD_Prophet(product_code, eemd_trials=100, optimize_trials=30, forecast_period=90):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    product_code = product_code # 예측하고자 하는 코드 입력\n",
    "    product_df = df[df['Product_Code']== product_code].reset_index(drop=True)\n",
    "    # Prophet을 위해 열이름 변경 -> ['ds', 'y']\n",
    "    product_df.rename(columns={'Date':'ds', 'Order_Demand':'y'}, inplace=True)\n",
    "    \n",
    "    # EEMD 수행\n",
    "    all_eIMFs_df, nIMFs = eemd_fit(product_df, eemd_trials)\n",
    "    # EEMD 결과에서 각 eIMFs' DF 추출\n",
    "    all_eIMFs_dict = extract_eIMFs(all_eIMFs_df, nIMFs)\n",
    "    # EEMD+Prophet실행\n",
    "    model_dict, pred_dict, train_dict = EEMD_Prophet(all_eIMFs_dict, forecast_period, optimize_trials) #optimize trials\n",
    "    all_result_df = make_all_result_df(pred_dict)\n",
    "    \n",
    "    # 모델 저장\n",
    "    save_model(product_code, model_dict)\n",
    "    # 결과 저장\n",
    "    metric_df_norm = make_metric_df(product_code, pred_dict, all_result_df, True)\n",
    "    metric_df      = make_metric_df(product_code, pred_dict, all_result_df, False)\n",
    "    # plot 저장\n",
    "    actual_pred_plot(product_code, pred_dict, all_result_df, metric_df_norm, True)\n",
    "    actual_pred_plot(product_code, pred_dict, all_result_df, metric_df, False)\n",
    "    \n",
    "    # 실행시간 확인\n",
    "    elapsed_time_seconds = time.time() - start_time\n",
    "    elapsed_time_minutes = elapsed_time_seconds / 60\n",
    "    print(\"실행 시간: {:.2f} 분\".format(elapsed_time_minutes))\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5269ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2bffe",
   "metadata": {},
   "source": [
    "## Whole Process\n",
    "    - product_code에 str으로 예측하고자 하는 코드를 입력\n",
    "    - ['Product_0025', 'Product_0739', 'Product_0901', 'Product_1154',\n",
    "       'Product_1248', 'Product_1295', 'Product_1378', 'Product_2004']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "095eda0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "========== Product_0025 ==========\n",
      "==================================\n",
      "--------Total: 0~11 eIMFs, Now: eIMFs_0 --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:05:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2c447bbcd247b6ace01d29fd1d1f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:05:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:05:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f70df5eebe4dc0b38a5b49bbb42d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:05:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:05:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fca5dfa871f4fe9819c2172fc1194fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:05:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:05:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5719c5ee2e0a4a4498b19541580baa1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:05:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:05:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207e725fcc2a4fe69392f1bc03f6b17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:05:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:05:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd069a7ca4f4c39b8b04887e5625661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65071282e4b543b4b0953a7fdc2a8551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4764ef3d0c2a42c3ba2f701e81f3f9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0082890a6e9549f6b1090cff82729280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d060ce2bde4988876bbe2aff9c1ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47fcafd83a3416393d6caa564b43e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89f5c705c3149558cd42962cda34c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c307189aaa04b6db1aa1018533ee25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4874a0f1db3849729408ff9119765627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725798cc54fc4210b7cd6ec28264f918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06ecbab1aa2411e95611cf5fe2e854a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370512e2ce9c416d8734f4c7cb03c1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92e3f25bc494f0f9570191be480e527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453e2ded55f74b77b51dcae3006820fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23cee45afb654c8b80c93ab41d5200f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1351ce71299f4dc2bd88d779239806c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b1cb4e24404502b30598a45901ff9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bc872dd414456a8355796314996684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc65853f80fc46cda43ad0529c65578e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bacd03abca946d4b92aed18cb906d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6158fce3de4522a02c892251567a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574f3c4d5b9e444185511693045ab75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1e9a1f4209419bb0001688a81e8a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ce29daf9ba45a4afc5e2c8ede17240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8182f860fb46168e162c7cd27b7231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Total: 0~11 eIMFs, Now: eIMFs_1 --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58236d191e084e1b8eb08be72082096b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4756c663654202829d1f99ad9dad14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:35 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m========== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39mcode\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ==========\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mexecute_EEMD_Prophet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[36], line 14\u001b[0m, in \u001b[0;36mexecute_EEMD_Prophet\u001b[1;34m(product_code, eemd_trials, optimize_trials, forecast_period)\u001b[0m\n\u001b[0;32m     12\u001b[0m all_eIMFs_dict \u001b[38;5;241m=\u001b[39m extract_eIMFs(all_eIMFs_df, nIMFs)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# EEMD+Prophet실행\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m model_dict, pred_dict, train_dict \u001b[38;5;241m=\u001b[39m \u001b[43mEEMD_Prophet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_eIMFs_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize_trials\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#optimize trials\u001b[39;00m\n\u001b[0;32m     15\u001b[0m all_result_df \u001b[38;5;241m=\u001b[39m make_all_result_df(pred_dict)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 모델 저장\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 18\u001b[0m, in \u001b[0;36mEEMD_Prophet\u001b[1;34m(all_eIMFs_dict, forecast_period, optimize_trials)\u001b[0m\n\u001b[0;32m     16\u001b[0m train_dict[i] \u001b[38;5;241m=\u001b[39m train_df\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 파라미터 최적화\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_prophet\u001b[49m\u001b[43m(\u001b[49m\u001b[43meIMF_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_period\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 최적 파라미터를 사용한 모델 훈련\u001b[39;00m\n\u001b[0;32m     21\u001b[0m best_model \u001b[38;5;241m=\u001b[39m Prophet(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_params)\n",
      "Cell \u001b[1;32mIn[27], line 22\u001b[0m, in \u001b[0;36moptimize_prophet\u001b[1;34m(eIMF_df, valid_df, optimize_trials, forecast_period)\u001b[0m\n\u001b[0;32m     20\u001b[0m m \u001b[38;5;241m=\u001b[39m Prophet(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m     21\u001b[0m m\u001b[38;5;241m.\u001b[39madd_country_holidays(country_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 미국 공휴일 추가\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43meIMF_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# validation 기간에 대해 예측\u001b[39;00m\n\u001b[0;32m     24\u001b[0m df_cv \u001b[38;5;241m=\u001b[39m cross_validation(m, cutoffs\u001b[38;5;241m=\u001b[39m[cutoff], horizon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(forecast_period)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m days\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\prophet\\forecaster.py:1181\u001b[0m, in \u001b[0;36mProphet.fit\u001b[1;34m(self, df, **kwargs)\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend\u001b[38;5;241m.\u001b[39msampling(stan_init, dat, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmcmc_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend\u001b[38;5;241m.\u001b[39mfit(stan_init, dat, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend\u001b[38;5;241m.\u001b[39mstan_fit\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;66;03m# If no changepoints were requested, replace delta with 0s\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\prophet\\models.py:90\u001b[0m, in \u001b[0;36mCmdStanPyBackend.fit\u001b[1;34m(self, stan_init, stan_data, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# Fall back on Newton\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewton_fallback \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNewton\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\cmdstanpy\\model.py:723\u001b[0m, in \u001b[0;36mCmdStanModel.optimize\u001b[1;34m(self, data, seed, inits, output_dir, sig_figs, save_profile, algorithm, init_alpha, tol_obj, tol_rel_obj, tol_grad, tol_rel_grad, tol_param, history_size, iter, save_iterations, require_converged, show_console, refresh, time_fmt, timeout)\u001b[0m\n\u001b[0;32m    721\u001b[0m     dummy_chain_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    722\u001b[0m     runset \u001b[38;5;241m=\u001b[39m RunSet(args\u001b[38;5;241m=\u001b[39margs, chains\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, time_fmt\u001b[38;5;241m=\u001b[39mtime_fmt)\n\u001b[1;32m--> 723\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_cmdstan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrunset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdummy_chain_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_console\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_console\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    729\u001b[0m runset\u001b[38;5;241m.\u001b[39mraise_for_timeouts()\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runset\u001b[38;5;241m.\u001b[39m_check_retcodes():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\EEMD+LSTM\\lib\\site-packages\\cmdstanpy\\model.py:1722\u001b[0m, in \u001b[0;36mCmdStanModel._run_cmdstan\u001b[1;34m(self, runset, idx, show_progress, show_console, progress_hook, timeout)\u001b[0m\n\u001b[0;32m   1720\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpoll() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1721\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1722\u001b[0m         line \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1723\u001b[0m         fd_out\u001b[38;5;241m.\u001b[39mwrite(line)\n\u001b[0;32m   1724\u001b[0m         line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for code in ['Product_0025', 'Product_0739', 'Product_0901', 'Product_1154',\n",
    "             'Product_1248', 'Product_1295', 'Product_1378', 'Product_2004']:\n",
    "    print(\"==================================\")\n",
    "    print(f\"========== { code } ==========\")\n",
    "    print(\"==================================\")\n",
    "    execute_EEMD_Prophet(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b27f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "#load_model('Product_0739_0503.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEMD_LSTM",
   "language": "python",
   "name": "eemd_lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
