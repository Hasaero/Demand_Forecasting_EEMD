{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0367e8",
   "metadata": {},
   "source": [
    "# EEMD + LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9353f79f",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "Input file: Historical Product Demand.csv\n",
    "\n",
    "Description: CSV data file containing product demand for encoded product id's\n",
    "\n",
    "Size of Data: (1048575, 5)\n",
    "\n",
    "Features: Product_Code, Warehouse, Product_Category, Date, Order_Demand\n",
    "\n",
    "Period: 2012-01-01 ~ 2017-01-09\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba9ee40",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c9a71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import warnings\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "\n",
    "# Save the log\n",
    "import os\n",
    "\n",
    "# EEMD\n",
    "from PyEMD import EEMD\n",
    "\n",
    "# LSTM\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MSE\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Metric \n",
    "# Metric\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58e094",
   "metadata": {},
   "source": [
    "## Data Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c8f1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Product_Code</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Order_Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-05 00:00:00</td>\n",
       "      <td>Product_0025</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-05 03:00:00</td>\n",
       "      <td>Product_0025</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1633.403702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-05 06:00:00</td>\n",
       "      <td>Product_0025</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1628.665789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-05 09:00:00</td>\n",
       "      <td>Product_0025</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1587.586651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-05 12:00:00</td>\n",
       "      <td>Product_0025</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1513.949924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116387</th>\n",
       "      <td>2016-12-26 12:00:00</td>\n",
       "      <td>Product_2004</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1810.945746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116388</th>\n",
       "      <td>2016-12-26 15:00:00</td>\n",
       "      <td>Product_2004</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1626.979543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116389</th>\n",
       "      <td>2016-12-26 18:00:00</td>\n",
       "      <td>Product_2004</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1420.229634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116390</th>\n",
       "      <td>2016-12-26 21:00:00</td>\n",
       "      <td>Product_2004</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1206.795489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116391</th>\n",
       "      <td>2016-12-27 00:00:00</td>\n",
       "      <td>Product_2004</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116392 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date  Product_Code Product_Category  Order_Demand\n",
       "0      2012-01-05 00:00:00  Product_0025     Category_005   1600.000000\n",
       "1      2012-01-05 03:00:00  Product_0025     Category_005   1633.403702\n",
       "2      2012-01-05 06:00:00  Product_0025     Category_005   1628.665789\n",
       "3      2012-01-05 09:00:00  Product_0025     Category_005   1587.586651\n",
       "4      2012-01-05 12:00:00  Product_0025     Category_005   1513.949924\n",
       "...                    ...           ...              ...           ...\n",
       "116387 2016-12-26 12:00:00  Product_2004     Category_005   1810.945746\n",
       "116388 2016-12-26 15:00:00  Product_2004     Category_005   1626.979543\n",
       "116389 2016-12-26 18:00:00  Product_2004     Category_005   1420.229634\n",
       "116390 2016-12-26 21:00:00  Product_2004     Category_005   1206.795489\n",
       "116391 2016-12-27 00:00:00  Product_2004     Category_005   1000.000000\n",
       "\n",
       "[116392 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading\n",
    "df = pd.read_csv('HPD_Augmented_0416.csv')\n",
    "# convert the string to the datetype\n",
    "df['Date'] = df['Date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed38f8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116392 entries, 0 to 116391\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   Date              116392 non-null  datetime64[ns]\n",
      " 1   Product_Code      116392 non-null  object        \n",
      " 2   Product_Category  116392 non-null  object        \n",
      " 3   Order_Demand      116392 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 3.6+ MB\n",
      "None\n",
      "-------------------------\n",
      "\n",
      "The Number of unique\n",
      "-------------------------\n",
      "Product code:\t 8\n",
      "Category:\t 5\n",
      "-------------------------\n",
      "The Product Code:\n",
      "\n",
      "1 Product_0025\n",
      "2 Product_0739\n",
      "3 Product_0901\n",
      "4 Product_1154\n",
      "5 Product_1248\n",
      "6 Product_1295\n",
      "7 Product_1378\n",
      "8 Product_2004\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print('-------------------------')\n",
    "print(\"\")\n",
    "print(\"The Number of unique\")\n",
    "print('-------------------------')\n",
    "print('Product code:\\t', df.Product_Code.nunique())\n",
    "print('Category:\\t', df.Product_Category.nunique())\n",
    "print('-------------------------')\n",
    "print(\"The Product Code:\")\n",
    "print(\"\")\n",
    "for i, code in enumerate(df['Product_Code'].unique()):\n",
    "    print(i+1, code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76850788",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07916726",
   "metadata": {},
   "source": [
    "## EEMD\n",
    "    * 시계열 그래프를 ensembled IMF (앙상블 내재모드 함수)로 분해\n",
    "    * n 개의 eIMFs와  1개의 Residual 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b907c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수요 그래프를 n개의 앙상블된 내재모드함수(IMF)로 분해\n",
    "# 그래프의 변동성이 클수록, IMF의 개수 증가\n",
    "def eemd_fit(df, trials=100, max_imf=-1):\n",
    "    \n",
    "    # Define signal\n",
    "    t = np.array(df['Date']) # 날짜\n",
    "    s = np.array(df['Order_Demand']) # 수요량\n",
    "    \n",
    "    # EEMD 객체 생성\n",
    "    eemd = EEMD(trials=trials) # trials: EMD 횟수\n",
    "    \n",
    "    # 극값을 감지하는 방법으로 parabolic 방법을 선택\n",
    "    emd = eemd.EMD\n",
    "    emd.extrema_detection=\"parabol\"\n",
    "    \n",
    "    # eIMFs로 분해\n",
    "    eIMFs = eemd.eemd(s, t, max_imf=max_imf) # max_imf: IMF 제한 개수(-1: 없음)\n",
    "    nIMFs = eIMFs.shape[0] # eIMF의 개수\n",
    "    \n",
    "    # 분해된 eIMFs와 잔차를 변수에 할당\n",
    "    imfs, residue = eemd.get_imfs_and_residue()\n",
    "    \n",
    "    # 앙상블 IMFs 들의 DataFrame 생성\n",
    "    all_eIMFs_df = pd.DataFrame(eIMFs).transpose()\n",
    "    all_eIMFs_df[nIMFs] = residue # residue 열 마지막 열로 추가\n",
    "    #all_eIMFs_df.set_index(df['Date'], inplace=True) # 날짜를 index로 setting\n",
    "    all_eIMFs_df.insert(0, 'Date', df['Date']) # Date 열 추가\n",
    "    \n",
    "    return all_eIMFs_df, nIMFs # eIMF+Residue들로 이루어진 df, eIMF(Residue포함)의 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76e4a8c",
   "metadata": {},
   "source": [
    "### eIMFs 데이터프레임 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "265e715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eIMF들을 추출하여, Date와 y로 이루어진 데이터프레임 추출하고 딕셔너리에 저장\n",
    "def extract_eIMFs(all_eIMFs_df, nIMFs):\n",
    "    all_eIMFs_dict = {}\n",
    "    # IMF개수+Residue(1) 만큼 반복\n",
    "    for i in range(nIMFs+1):\n",
    "        tmp_df = all_eIMFs_df[['Date', i]] # n번째 eIMF에 해당하는 날짜와 값 추출\n",
    "        tmp_df.columns=['Date', 'y'] # i -> y 로 열이름 변경\n",
    "        all_eIMFs_dict[f'eIMFs_{i}'] = tmp_df # n번째 eIMF 정보(마지막은 Residue) 딕셔너리에 저장\n",
    "        \n",
    "    return all_eIMFs_dict # {eIMFs_1: df1, eIMFs_2: df2, ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4680cb42",
   "metadata": {},
   "source": [
    "### Split the train and test set\n",
    "- Input\n",
    "     data: dataframe with dates and Demand data\n",
    "     \n",
    "- output\n",
    "    - train:  2012-01-01 ~ 2015-06/30 \n",
    "    - Valid:  2015-07-01 ~ 2015-12-31\n",
    "    - test :  2016-01-01 ~ 2017-01-06 \n",
    "    \n",
    "     \n",
    "- time_steps: # of the input time steps \n",
    "- for_periods: # of the output time steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dbe9b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_train_val_test(eIMF_df, time_steps): \n",
    "\n",
    "    ts_train_end = len(eIMF_df[eIMF_df['Date']<'2015-07-01']) # train 데이터 종료 인덱스\n",
    "    ts_val_end = len(eIMF_df[eIMF_df['Date']<'2016-01-01']) # validation 데이터 종료 인덱스\n",
    "    ts = eIMF_df.filter(['y']).values # y(수요량) 값\n",
    "    \n",
    "    # Minmax로 0~1 사이에 값이 오도록 정규화\n",
    "    sc = MinMaxScaler() # 객체 생성\n",
    "    ts_scaled = sc.fit_transform(ts) # 전체 y값 정규화\n",
    "    \n",
    "    # Train Data\n",
    "    ts_train_scaled = ts_scaled[:ts_train_end,:]\n",
    "\n",
    "    X_train = [] \n",
    "    y_train = []\n",
    "    for i in range(time_steps, ts_train_end): \n",
    "        X_train.append(ts_train_scaled[i-time_steps:i,0]) # time steps 만큼 sliding window\n",
    "        y_train.append(ts_train_scaled[i,0])\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    # Reshape X_train for LSTM -> (batch_size, time_steps, features)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "\n",
    "    # Validation Data\n",
    "    ts_val_scaled = ts_scaled[ts_train_end : ts_val_end, :]\n",
    "\n",
    "    X_val = []\n",
    "    y_val = []\n",
    "    for i in range(time_steps, len(ts_val_scaled)):\n",
    "        X_val.append(ts_val_scaled[i-time_steps : i, 0])\n",
    "        y_val.append(ts_val_scaled[i, 0])\n",
    "\n",
    "    X_val = np.array(X_val)\n",
    "    y_val = np.array(y_val)\n",
    "\n",
    "    # Reshape X_val for LSTM -> (batch_size, time_steps, features)\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1],1))\n",
    "    \n",
    "    # Test Data\n",
    "    ts_test_scaled = ts_scaled[ts_val_end:,:]\n",
    "\n",
    "    X_test = []\n",
    "    y_test = eIMF_df.iloc[ts_val_end+time_steps:,:]\n",
    "    y_test.loc[:, 'y_norm'] = ts_test_scaled[time_steps:].reshape(-1).copy()\n",
    "\n",
    "    for i in range(time_steps, len(ts_test_scaled)):\n",
    "        X_test.append(ts_test_scaled[i-time_steps : i, 0])\n",
    "    \n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da9661",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01113fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(X_train, y_train, X_val, y_val, X_test, sc, epochs=10):\n",
    "    # LSTM 모델 객체 생성\n",
    "    my_LSTM_model = Sequential() \n",
    "    \n",
    "    # 첫 번째 LSTM 레이어 구성\n",
    "    # 활성화 함수는 ReLU를 사용하며, return_sequences=True로 지정하여 다음 LSTM 레이어의 입력으로 사용할 수 있도록 함\n",
    "    my_LSTM_model.add(LSTM(512, activation='relu',return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "    \n",
    "    # 두 번째 LSTM 레이어 구성\n",
    "    # 활성화 함수는 ReLU를 사용하며, return_sequences=False로 지정하여 마지막 LSTM 레이어임을 나타냄\n",
    "    my_LSTM_model.add(LSTM(256, activation = 'relu',return_sequences=False))\n",
    "    \n",
    "    # Fully connected 레이어들 추가\n",
    "    # 마지막 레이어에서는 출력의 unit 개수를 1로 설정하여 1개의 값을 출력\n",
    "    my_LSTM_model.add(Dense(128))\n",
    "    my_LSTM_model.add(Dense(64))\n",
    "    my_LSTM_model.add(Dense(32))\n",
    "    my_LSTM_model.add(Dense(1))\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    my_LSTM_model.compile(optimizer = \"Adam\", # Adam optimizer 사용\n",
    "                         loss = 'mean_squared_error', # 손실 함수로는 평균 제곱 오차 사용\n",
    "                          metrics=['mape','mae']) # 성능 지표로는 MAPE와 MAE를 사용\n",
    "    #조기종료 조건\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    # 모델 Fitting\n",
    "    my_LSTM_model.fit(X_train, # 입력 데이터\n",
    "                      y_train, # 출력 데이터\n",
    "                      epochs = epochs, # epoch 수\n",
    "                      batch_size = 16, # batch size\n",
    "                      validation_data=(X_val, y_val),\n",
    "                      callbacks=[early_stopping],# validation에 따른 조기종료\n",
    "                      verbose = 1) # 학습 상태를 출력\n",
    "    \n",
    "    # Test 데이터 예측\n",
    "    LSTM_prediction = my_LSTM_model.predict(X_test) # 예측값 얻기\n",
    "    LSTM_prediction_normalized = LSTM_prediction # 예측값을 저장하되, normalize된 값 저장\n",
    "    LSTM_prediction = sc.inverse_transform(LSTM_prediction) # denormalize된 예측값 저장\n",
    "    \n",
    "    # 모델 객체와 예측값 반환\n",
    "    return my_LSTM_model, LSTM_prediction, LSTM_prediction_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b922e",
   "metadata": {},
   "source": [
    "### EEMD+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a404016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EEMD_LSTM(all_eIMFs_dict, time_steps, epochs):\n",
    "\n",
    "    model_dict = {}\n",
    "    pred_dict = {}\n",
    "    \n",
    "    # 모든 eIMF에 대해 LSTM 모델 학습 및 예측 실행\n",
    "    for i in all_eIMFs_dict.keys():\n",
    "        print(f'--------Total: 0~{len(all_eIMFs_dict)-1} eIMFs, Now: {i} --------')\n",
    "        \n",
    "        # 현재 eIMF 데이터 가져오기\n",
    "        eIMF_df = all_eIMFs_dict[i]\n",
    "        \n",
    "        # 학습 데이터와 테스트 데이터 분리\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test, sc = ts_train_val_test(eIMF_df, time_steps)\n",
    "        \n",
    "        # LSTM 모델 학습 및 저장\n",
    "        my_LSTM_model, LSTM_prediction, LSTM_prediction_normalized = LSTM_model(X_train, y_train, X_val, y_val, X_test, sc, epochs)\n",
    "        model_dict[i] = my_LSTM_model # 딕셔너리에 모델 정보 저장\n",
    "        \n",
    "        # 예측 결과 저장\n",
    "        y_test.reset_index(drop=True, inplace=True)\n",
    "        pred_df = pd.DataFrame({'Pred': LSTM_prediction.reshape(-1) ,'Pred_norm': LSTM_prediction_normalized.reshape(-1)})\n",
    "        res_df = pd.concat([y_test, pred_df], axis=1)\n",
    "        res_df.set_index('Date', inplace=True)\n",
    "        res_df = res_df.resample('D').first() # 증강된 데이터가 아닌, Actual값들과 비교\n",
    "        pred_dict[i] = res_df\n",
    "        \n",
    "    # 모델과 예측값 딕셔너리 반환\n",
    "    return model_dict, pred_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd64a0",
   "metadata": {},
   "source": [
    "## Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d8fe2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_pred_plot(product_code, pred_dict, all_result_df, metric_df, normalize=False):\n",
    "    today = date.today()\n",
    "    \"\"\"\n",
    "    Plot the actual vs predition and save the figure in the given directory\n",
    "    \"\"\"\n",
    "    pred_dict['all_result'] = all_result_df\n",
    "    \n",
    "    save_path = os.path.join(\"Result\", \"EEMD+LSTM_Result\", product_code+f'_{today.month:02d}{today.day:02d}')\n",
    "    if normalize: save_path += \"_normalized\"\n",
    "        \n",
    "    for i, pred_df in enumerate(pred_dict.values()):\n",
    "        img_n = len(pred_dict)\n",
    "        title = f\"Pred Actual Plot - ({i+1}/{len(pred_dict)-1})'s eIMF\"\n",
    "        actual = pred_df['y']\n",
    "        pred = pred_df['Pred']\n",
    "        save_name = f'{product_code}_eIMF_{i+1}'\n",
    "        if i == img_n-1: # All result\n",
    "            title = f\"{product_code}-All Result\"\n",
    "            save_name = f'{product_code}_all_result'\n",
    "        if normalize:\n",
    "            title += \"(Normalized)\"\n",
    "            actual = pred_df['y_norm']\n",
    "            pred = pred_df['Pred_norm']\n",
    "            \n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.title(title, fontsize=20)\n",
    "        plt.xlabel(\"Time\", fontsize=14)\n",
    "        plt.ylabel(\"Order Demand\", fontsize=14)\n",
    "        plt.plot(actual, label ='Actual', alpha=0.6)\n",
    "        plt.plot(pred, label='Prediction', alpha=0.8)\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        \n",
    "        # Plot 결과 저장\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        # save the figure\n",
    "        today_date = f'_{today.month:02d}{today.day:02d}'\n",
    "        plt.savefig(os.path.join(save_path, save_name+'.png'))\n",
    "    metric_df.to_csv(os.path.join(save_path, f'{product_code}_Metric.csv'))\n",
    "    del pred_dict['all_result']\n",
    "        \n",
    "    plt.close('all') # close all figures to free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd8454",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28dd74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Metric\n",
    "def mase(training_series, testing_series, prediction_series):\n",
    "    n = training_series.shape[0]\n",
    "    d = np.abs(np.diff(training_series)).sum() / (n-1)\n",
    "    \n",
    "    errors = np.abs(testing_series - prediction_series)\n",
    "    return errors.mean() / d\n",
    "\n",
    "# Model Metric\n",
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / (actual+1)))\n",
    "\n",
    "def nrmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nrmse = mse / target_mean\n",
    "    return nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83451baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred_df, normalize):\n",
    "    # 계산된 메트릭을 저장하기 위해 데이터프레임 초기화\n",
    "    metric_df = pd.DataFrame(columns=['MAPE', 'RMSE', 'MAE', 'NRMSE'])\n",
    "\n",
    "    # 정규화 옵션이 True인 경우 정규화된 데이터 사용, 그렇지 않으면 원래 데이터 사용\n",
    "    if normalize:\n",
    "        actual = pred_df['y_norm']\n",
    "        pred = pred_df['Pred_norm']\n",
    "    else:\n",
    "        actual = pred_df['y']\n",
    "        pred = pred_df['Pred']\n",
    "\n",
    "    # 메트릭 계산\n",
    "    # MASE = mase(np.array(train_series), np.array(actual), pred) \n",
    "    MAPE = mape(actual, pred) \n",
    "    RMSE = mean_squared_error(actual, pred)**0.5 \n",
    "    MAE = mean_absolute_error(actual,pred) \n",
    "    NRMSE = nrmse(actual,pred) \n",
    "    # RMSLE = mean_squared_log_error(actual, pred)**0.5 \n",
    "\n",
    "    # 계산된 메트릭을 데이터프레임에 추가\n",
    "    tmp_df = pd.DataFrame({'MAPE':[round(MAPE, 4)],\n",
    "                           'RMSE':[round(RMSE, 4)],\n",
    "                           'MAE':[round(MAE, 4)],\n",
    "                           'NRMSE':[round(NRMSE, 4)]})\n",
    "\n",
    "    # 메트릭 데이터프레임에 결과 추가\n",
    "    metric_df = pd.concat([metric_df, tmp_df])\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073bc376",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e45cb6",
   "metadata": {},
   "source": [
    "## Check the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e560ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_metric_df(product_code, pred_dict, all_result_df, normalize):\n",
    "    today = date.today()\n",
    "\n",
    "    metric_df = pd.DataFrame(columns=['MAPE', 'RMSE', 'MAE', 'NRMSE'])\n",
    "    for i, pred_df in pred_dict.items():\n",
    "        imf_df = calculate_metrics(pred_df, normalize=normalize)\n",
    "        metric_df = pd.concat([metric_df, imf_df])\n",
    "    \n",
    "    imf_idx = pd.Index(['eIMF_'+str(i+1) for i in range(len(pred_dict))]) # changed result_dict to pred_dict\n",
    "    metric_df.index = imf_idx # Assign the created index to metric_df\n",
    "    metric_df = pd.concat([metric_df, calculate_metrics(all_result_df, normalize=normalize)], axis=0)\n",
    "    metric_df = metric_df.rename(index={metric_df.index[-1]: 'All'}) # 마지막 행은 all\n",
    "    \n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40503729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_result_df(pred_dict):\n",
    "    all_df = pd.DataFrame()\n",
    "    for tmp_df in pred_dict.values():\n",
    "        all_df = pd.concat([all_df, tmp_df], axis=1)\n",
    "    pred_df = all_df['Pred'].sum(axis=1)\n",
    "    actual_df = all_df['y'].sum(axis=1)\n",
    "    \n",
    "    all_result_df = pd.DataFrame({'Pred': pred_df, 'y': actual_df})\n",
    "    all_result_df.loc[all_result_df['Pred']<0, 'Pred']=0 # 음수 예측 값은 0으로 대치\n",
    "    \n",
    "    # 날짜(Date) 열은 정규화하지 않으므로 제외\n",
    "    result_norm = all_result_df[['Pred', 'y']]\n",
    "    \n",
    "    # MinMaxScaler를 이용하여 정규화합니다.\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(result_norm)\n",
    "    \n",
    "    # 정규화된 데이터를 데이터 프레임에 반영합니다.\n",
    "    all_result_df['Pred_norm'] = normalized_data[:,0]\n",
    "    all_result_df['y_norm'] = normalized_data[:,1]\n",
    "    return all_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ce9ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_EEMD_LSTM(product_code, eemd_trials=100, time_steps=30, epochs=20):\n",
    "\n",
    "    product_code = product_code # 예측하고자 하는 코드 입력\n",
    "    product_df = df[df['Product_Code']== product_code].reset_index(drop=True)\n",
    "    \n",
    "    # EEMD 수행\n",
    "    all_eIMFs_df, nIMFs = eemd_fit(product_df, eemd_trials)\n",
    "    # EEMD 결과에서 각 eIMFs' DF 추출\n",
    "    all_eIMFs_dict = extract_eIMFs(all_eIMFs_df, nIMFs)\n",
    "    # EEMD+LSTM 실행\n",
    "    model_dict, pred_dict = EEMD_LSTM(all_eIMFs_dict, time_steps, epochs) #dictionary, time_steps, epochs\n",
    "    all_result_df = make_all_result_df(pred_dict)\n",
    "    \n",
    "    metric_df_norm = make_metric_df(product_code, pred_dict, all_result_df, True)\n",
    "    metric_df = make_metric_df(product_code, pred_dict, all_result_df, False)\n",
    "    \n",
    "    actual_pred_plot(product_code, pred_dict, all_result_df, metric_df_norm, True)\n",
    "    actual_pred_plot(product_code, pred_dict, all_result_df, metric_df, False)\n",
    "    \n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5269ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2bffe",
   "metadata": {},
   "source": [
    "## Whole Process\n",
    "    - product_code에 str으로 예측하고자 하는 코드를 입력\n",
    "    - ['Product_0025', 'Product_0739', 'Product_0901', 'Product_1154',\n",
    "       'Product_1248', 'Product_1295', 'Product_1378', 'Product_2004']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c25cfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Total: 0~13 eIMFs, Now: eIMFs_0 --------\n",
      "636/636 [==============================] - 15s 18ms/step - loss: 0.0219 - mape: 55738.9297 - mae: 0.1201 - val_loss: 0.0186 - val_mape: 31.3452 - val_mae: 0.1129\n",
      "91/91 [==============================] - 1s 3ms/step\n",
      "--------Total: 0~13 eIMFs, Now: eIMFs_1 --------\n",
      "636/636 [==============================] - 15s 20ms/step - loss: 0.0056 - mape: 36328.7539 - mae: 0.0523 - val_loss: 0.0052 - val_mape: 10.9599 - val_mae: 0.0592\n",
      "91/91 [==============================] - 1s 3ms/step\n",
      "--------Total: 0~13 eIMFs, Now: eIMFs_2 --------\n",
      "636/636 [==============================] - 14s 18ms/step - loss: 0.0042 - mape: 37764.0273 - mae: 0.0382 - val_loss: 9.4442e-04 - val_mape: 4.6988 - val_mae: 0.0237\n",
      "91/91 [==============================] - 1s 3ms/step\n",
      "--------Total: 0~13 eIMFs, Now: eIMFs_3 --------\n",
      "636/636 [==============================] - 13s 16ms/step - loss: 0.0037 - mape: 42702.0273 - mae: 0.0335 - val_loss: 6.9412e-04 - val_mape: 4.3318 - val_mae: 0.0201\n",
      "91/91 [==============================] - 1s 3ms/step\n",
      "--------Total: 0~13 eIMFs, Now: eIMFs_4 --------\n",
      "636/636 [==============================] - 13s 16ms/step - loss: 0.0032 - mape: 13642.5732 - mae: 0.0260 - val_loss: 1.4064e-04 - val_mape: 1.9696 - val_mae: 0.0094\n",
      "91/91 [==============================] - 1s 3ms/step\n",
      "--------Total: 0~13 eIMFs, Now: eIMFs_5 --------\n",
      "636/636 [==============================] - 17s 23ms/step - loss: 0.0032 - mape: 7517.1201 - mae: 0.0237 - val_loss: 2.0222e-04 - val_mape: 2.5534 - val_mae: 0.0109\n",
      "91/91 [==============================] - 1s 3ms/step\n",
      "--------Total: 0~13 eIMFs, Now: eIMFs_6 --------\n",
      "636/636 [==============================] - 12s 15ms/step - loss: 0.0045 - mape: 1435.2892 - mae: 0.0231 - val_loss: 5.4560e-05 - val_mape: 1.2161 - val_mae: 0.0063\n",
      "91/91 [==============================] - 1s 3ms/step\n",
      "--------Total: 0~13 eIMFs, Now: eIMFs_7 --------\n",
      "636/636 [==============================] - 12s 16ms/step - loss: 0.0035 - mape: 7.4571 - mae: 0.0176 - val_loss: 4.7176e-05 - val_mape: 15384.0391 - val_mae: 0.0056\n",
      "91/91 [==============================] - 1s 3ms/step\n",
      "--------Total: 0~13 eIMFs, Now: eIMFs_8 --------\n",
      "636/636 [==============================] - 13s 16ms/step - loss: 0.0042 - mape: 7060.4043 - mae: 0.0167 - val_loss: 3.5178e-06 - val_mape: 0.3898 - val_mae: 0.0014\n",
      "91/91 [==============================] - 1s 3ms/step\n",
      "--------Total: 0~13 eIMFs, Now: eIMFs_9 --------\n",
      "636/636 [==============================] - 12s 15ms/step - loss: 0.0044 - mape: 1413.2776 - mae: 0.0151 - val_loss: 2.3068e-07 - val_mape: 0.0922 - val_mae: 4.4616e-04\n",
      "91/91 [==============================] - 1s 3ms/step\n",
      "--------Total: 0~13 eIMFs, Now: eIMFs_10 --------\n",
      "636/636 [==============================] - 13s 15ms/step - loss: 0.0034 - mape: 943.7003 - mae: 0.0139 - val_loss: 5.1001e-06 - val_mape: 0.2103 - val_mae: 0.0020\n",
      "91/91 [==============================] - 1s 3ms/step\n",
      "--------Total: 0~13 eIMFs, Now: eIMFs_11 --------\n",
      "636/636 [==============================] - 12s 16ms/step - loss: 0.0076 - mape: 947.3118 - mae: 0.0201 - val_loss: 5.9793e-07 - val_mape: 0.0885 - val_mae: 7.5980e-04\n",
      "91/91 [==============================] - 1s 3ms/step\n",
      "--------Total: 0~13 eIMFs, Now: eIMFs_12 --------\n",
      "636/636 [==============================] - 12s 15ms/step - loss: 0.0054 - mape: 40.2381 - mae: 0.0172 - val_loss: 7.9058e-06 - val_mape: 0.2824 - val_mae: 0.0028\n",
      "91/91 [==============================] - 1s 3ms/step\n",
      "--------Total: 0~13 eIMFs, Now: eIMFs_13 --------\n",
      "636/636 [==============================] - 14s 17ms/step - loss: 0.0194 - mape: 51829.7773 - mae: 0.1092 - val_loss: 0.0177 - val_mape: 23.7022 - val_mae: 0.1061\n",
      "91/91 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "product_code = 'Product_2004' # 예측하고자 하는 코드 입력\n",
    "product_df = df[df['Product_Code']== product_code].reset_index(drop=True)\n",
    "\n",
    "# EEMD 수행\n",
    "all_eIMFs_df, nIMFs = eemd_fit(product_df, 1)\n",
    "# EEMD 결과에서 각 eIMFs' DF 추출\n",
    "all_eIMFs_dict = extract_eIMFs(all_eIMFs_df, nIMFs)\n",
    "# EEMD+LSTM 실행\n",
    "model_dict, pred_dict = EEMD_LSTM(all_eIMFs_dict, 1, 1) #dictionary, time_steps, epochs\n",
    "all_result_df = make_all_result_df(pred_dict)\n",
    "\n",
    "metric_df_norm = make_metric_df(product_code, pred_dict, all_result_df, True)\n",
    "metric_df = make_metric_df(product_code, pred_dict, all_result_df, False)\n",
    "\n",
    "actual_pred_plot(product_code, pred_dict, all_result_df, metric_df_norm, True)\n",
    "actual_pred_plot(product_code, pred_dict, all_result_df, metric_df, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc86fb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>NRMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eIMF_1</th>\n",
       "      <td>1.3230</td>\n",
       "      <td>471.3171</td>\n",
       "      <td>394.0095</td>\n",
       "      <td>-16.0708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_2</th>\n",
       "      <td>3.4228</td>\n",
       "      <td>350.2988</td>\n",
       "      <td>285.0902</td>\n",
       "      <td>-10.0685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_3</th>\n",
       "      <td>1.4678</td>\n",
       "      <td>155.0003</td>\n",
       "      <td>124.7250</td>\n",
       "      <td>-47.6181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_4</th>\n",
       "      <td>2.4410</td>\n",
       "      <td>144.0300</td>\n",
       "      <td>112.8649</td>\n",
       "      <td>-13.8879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_5</th>\n",
       "      <td>0.7851</td>\n",
       "      <td>108.7938</td>\n",
       "      <td>85.6479</td>\n",
       "      <td>-7.3370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_6</th>\n",
       "      <td>1.1568</td>\n",
       "      <td>50.5910</td>\n",
       "      <td>41.0250</td>\n",
       "      <td>-4.5935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_7</th>\n",
       "      <td>0.7098</td>\n",
       "      <td>18.5522</td>\n",
       "      <td>13.5753</td>\n",
       "      <td>0.7228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_8</th>\n",
       "      <td>0.1305</td>\n",
       "      <td>8.0692</td>\n",
       "      <td>6.6548</td>\n",
       "      <td>-0.6157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_9</th>\n",
       "      <td>0.1470</td>\n",
       "      <td>2.1782</td>\n",
       "      <td>1.7501</td>\n",
       "      <td>-0.1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_10</th>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.1874</td>\n",
       "      <td>-0.3101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_11</th>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>0.0943</td>\n",
       "      <td>-0.0049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_12</th>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>-0.0057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_13</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_14</th>\n",
       "      <td>6.4623</td>\n",
       "      <td>718.8184</td>\n",
       "      <td>577.9136</td>\n",
       "      <td>-135.8105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>65.2920</td>\n",
       "      <td>372.8032</td>\n",
       "      <td>211.3648</td>\n",
       "      <td>0.5272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MAPE      RMSE       MAE     NRMSE\n",
       "eIMF_1    1.3230  471.3171  394.0095  -16.0708\n",
       "eIMF_2    3.4228  350.2988  285.0902  -10.0685\n",
       "eIMF_3    1.4678  155.0003  124.7250  -47.6181\n",
       "eIMF_4    2.4410  144.0300  112.8649  -13.8879\n",
       "eIMF_5    0.7851  108.7938   85.6479   -7.3370\n",
       "eIMF_6    1.1568   50.5910   41.0250   -4.5935\n",
       "eIMF_7    0.7098   18.5522   13.5753    0.7228\n",
       "eIMF_8    0.1305    8.0692    6.6548   -0.6157\n",
       "eIMF_9    0.1470    2.1782    1.7501   -0.1266\n",
       "eIMF_10   0.0256    0.2309    0.1874   -0.3101\n",
       "eIMF_11   0.0256    0.1051    0.0943   -0.0049\n",
       "eIMF_12   0.0070    0.1429    0.1258   -0.0057\n",
       "eIMF_13   0.0000    0.0007    0.0006    0.0000\n",
       "eIMF_14   6.4623  718.8184  577.9136 -135.8105\n",
       "All      65.2920  372.8032  211.3648    0.5272"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d98b71d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y_norm</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Pred_norm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>445.506295</td>\n",
       "      <td>0.625223</td>\n",
       "      <td>122.989777</td>\n",
       "      <td>0.527447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>-325.590043</td>\n",
       "      <td>0.391453</td>\n",
       "      <td>148.028610</td>\n",
       "      <td>0.535038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>307.398305</td>\n",
       "      <td>0.583353</td>\n",
       "      <td>226.449707</td>\n",
       "      <td>0.558812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>-689.248128</td>\n",
       "      <td>0.281205</td>\n",
       "      <td>-165.192429</td>\n",
       "      <td>0.440080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>305.847365</td>\n",
       "      <td>0.582883</td>\n",
       "      <td>233.936157</td>\n",
       "      <td>0.561082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-23</th>\n",
       "      <td>-481.474600</td>\n",
       "      <td>0.344195</td>\n",
       "      <td>-60.335110</td>\n",
       "      <td>0.471869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-24</th>\n",
       "      <td>320.786076</td>\n",
       "      <td>0.587412</td>\n",
       "      <td>143.890594</td>\n",
       "      <td>0.533783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-25</th>\n",
       "      <td>218.254394</td>\n",
       "      <td>0.556328</td>\n",
       "      <td>247.288605</td>\n",
       "      <td>0.565130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-26</th>\n",
       "      <td>-574.245618</td>\n",
       "      <td>0.316070</td>\n",
       "      <td>-68.714745</td>\n",
       "      <td>0.469329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-27</th>\n",
       "      <td>-27.073774</td>\n",
       "      <td>0.481953</td>\n",
       "      <td>119.855057</td>\n",
       "      <td>0.526497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     y    y_norm        Pred  Pred_norm\n",
       "Date                                                   \n",
       "2016-01-01  445.506295  0.625223  122.989777   0.527447\n",
       "2016-01-02 -325.590043  0.391453  148.028610   0.535038\n",
       "2016-01-03  307.398305  0.583353  226.449707   0.558812\n",
       "2016-01-04 -689.248128  0.281205 -165.192429   0.440080\n",
       "2016-01-05  305.847365  0.582883  233.936157   0.561082\n",
       "...                ...       ...         ...        ...\n",
       "2016-12-23 -481.474600  0.344195  -60.335110   0.471869\n",
       "2016-12-24  320.786076  0.587412  143.890594   0.533783\n",
       "2016-12-25  218.254394  0.556328  247.288605   0.565130\n",
       "2016-12-26 -574.245618  0.316070  -68.714745   0.469329\n",
       "2016-12-27  -27.073774  0.481953  119.855057   0.526497\n",
       "\n",
       "[362 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict['eIMFs_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a6fff96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.323025421026068\n",
      "471.3171351373042\n",
      "394.0094603046367\n",
      "-16.070803094901144\n"
     ]
    }
   ],
   "source": [
    "actual = pred_dict['eIMFs_0']['y']\n",
    "pred = pred_dict['eIMFs_0']['Pred']\n",
    "print(mape(actual,pred))\n",
    "print(np.sqrt(mean_squared_error(actual,pred)))\n",
    "print(mean_absolute_error(actual,pred))\n",
    "print(nrmse(actual,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "095eda0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Total: 0~12 eIMFs, Now: eIMFs_0 --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function UniquePtr.__del__ at 0x00000236F55519D0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\7info\\anaconda3\\envs\\Capstone\\lib\\site-packages\\tensorflow\\python\\framework\\c_api_util.py\", line 74, in __del__\n",
      "    self.deleter(obj)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/637 [====>.........................] - ETA: 10s - loss: 0.0310 - mape: 36.6704 - mae: 0.1441"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      2\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mexecute_EEMD_LSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProduct_1378\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meemd_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m elapsed_time_seconds \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m      7\u001b[0m elapsed_time_minutes \u001b[38;5;241m=\u001b[39m elapsed_time_seconds \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n",
      "Cell \u001b[1;32mIn[42], line 11\u001b[0m, in \u001b[0;36mexecute_EEMD_LSTM\u001b[1;34m(product_code, eemd_trials, time_steps, epochs)\u001b[0m\n\u001b[0;32m      9\u001b[0m all_eIMFs_dict \u001b[38;5;241m=\u001b[39m extract_eIMFs(all_eIMFs_df, nIMFs)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# EEMD+LSTM 실행\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m model_dict, pred_dict \u001b[38;5;241m=\u001b[39m \u001b[43mEEMD_LSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_eIMFs_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#dictionary, time_steps, epochs\u001b[39;00m\n\u001b[0;32m     12\u001b[0m all_result_df \u001b[38;5;241m=\u001b[39m make_all_result_df(pred_dict)\n\u001b[0;32m     14\u001b[0m metric_df_norm \u001b[38;5;241m=\u001b[39m make_metric_df(product_code, pred_dict, all_result_df, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[36], line 17\u001b[0m, in \u001b[0;36mEEMD_LSTM\u001b[1;34m(all_eIMFs_dict, time_steps, epochs)\u001b[0m\n\u001b[0;32m     14\u001b[0m X_train, y_train, X_val, y_val, X_test, y_test, sc \u001b[38;5;241m=\u001b[39m ts_train_val_test(eIMF_df, time_steps)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# LSTM 모델 학습 및 저장\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m my_LSTM_model, LSTM_prediction, LSTM_prediction_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mLSTM_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m model_dict[i] \u001b[38;5;241m=\u001b[39m my_LSTM_model \u001b[38;5;66;03m# 딕셔너리에 모델 정보 저장\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 예측 결과 저장\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[35], line 28\u001b[0m, in \u001b[0;36mLSTM_model\u001b[1;34m(X_train, y_train, X_val, y_val, X_test, sc, epochs)\u001b[0m\n\u001b[0;32m     25\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 모델 Fitting\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mmy_LSTM_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 입력 데이터\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m \u001b[43m                  \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 출력 데이터\u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# epoch 수\u001b[39;49;00m\n\u001b[0;32m     31\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# batch size\u001b[39;49;00m\n\u001b[0;32m     32\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m# validation에 따른 조기종료\u001b[39;49;00m\n\u001b[0;32m     34\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 학습 상태를 출력\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Test 데이터 예측\u001b[39;00m\n\u001b[0;32m     37\u001b[0m LSTM_prediction \u001b[38;5;241m=\u001b[39m my_LSTM_model\u001b[38;5;241m.\u001b[39mpredict(X_test) \u001b[38;5;66;03m# 예측값 얻기\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Capstone\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Capstone\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Capstone\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Capstone\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Capstone\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Capstone\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Capstone\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Capstone\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Capstone\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "execute_EEMD_LSTM('Product_1378')\n",
    "\n",
    "elapsed_time_seconds = time.time() - start_time\n",
    "elapsed_time_minutes = elapsed_time_seconds / 60\n",
    "print(\"실행 시간: {:.2f} 분\".format(elapsed_time_minutes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
